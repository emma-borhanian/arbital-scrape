<!DOCTYPE html><html><head><meta charset="utf-8"><title>By Tag</title><link rel="stylesheet" type="text/css" href="common.css"><link rel="stylesheet" type="text/css" href="index-style.css"></head><body><header><nav><h1><a href="index.html">Arbital Scrape Index</a></h1><h1><a href="page/arbital_front_page.html">Arbital Front Page</a></h1><h1><a href="explore.html">Explore</a></h1><h1>By Tag</h1><h1><a href="by-creator.html">By Creator</a></h1><h1><a href="by-editor.html">By Editor</a></h1><h1><a href="by-likes.html">By Likes</a></h1><h1><a href="by-type-named.html">By Type (Named)</a></h1><ul><li><a href="by-type-named.html#wiki">wiki</a></li><li><a href="by-type-named.html#group">group</a></li><li><a href="by-type-named.html#comment">comment</a></li><li><a href="by-type-named.html#question">question</a></li><li><a href="by-type-named.html#no-type">no-type</a></li></ul><h1><a href="by-type-unnamed.html">By Type (Unnamed)</a></h1><ul><li><a href="by-type-unnamed.html#no-type">no-type</a></li></ul></nav></header><hr><main><h1>By Tag</h1><ul><li><a href="#axiom_of_choice_definition_mathematical"> Axiom of Choice: Definition (Formal)</a></li><li><a href="#a_class_meta_tag">A-Class</a></li><li><a href="#ai_alignment">AI alignment</a></li><li><a href="#value_alignment_open_problem">AI alignment open problem</a></li><li><a href="#Arbital_tag">Arbital &quot;tag&quot; relationship</a></li><li><a href="#arbital_summaries">Arbital page summaries</a></li><li><a href="#arbital_project_outline">Arbital project outline</a></li><li><a href="#6tl">Assuming significant overhead in monitoring recipients of a microloan, it's more efficient to let them keep the money.</a></li><li><a href="#Sovereign">Autonomous AGI</a></li><li><a href="#b_class_meta_tag">B-Class</a></li><li><a href="#bayes_reasoning">Bayesian reasoning</a></li><li><a href="#behaviorist">Behaviorist genie</a></li><li><a href="#bijective_function">Bijective function</a></li><li><a href="#c_class_meta_tag">C-Class</a></li><li><a href="#category_theory">Category theory</a></li><li><a href="#central_example">Central examples</a></li><li><a href="#complexity_of_value">Complexity of value</a></li><li><a href="#concept_meta_tag">Concept</a></li><li><a href="#context_disaster">Context disaster</a></li><li><a href="#corrigibility">Corrigibility</a></li><li><a href="#cyclic_group_intro_math_0">Cyclic Group Intro (Math 0)</a></li><li><a href="#decision_theory">Decision theory</a></li><li><a href="#definition_meta_tag">Definition</a></li><li><a href="#development_phase_unpredictable">Development phase unpredictable</a></li><li><a href="#disambiguation_meta_tag">Disambiguation</a></li><li><a href="#discussion_norms">Discussion norms</a></li><li><a href="#dwim">Do-What-I-Mean hierarchy</a></li><li><a href="#donor_coordination">Donor coordination</a></li><li><a href="#DuncanSabien">Duncan Sabien</a></li><li><a href="#edge_instantiation">Edge instantiation</a></li><li><a href="#ea">Effective altruism</a></li><li><a href="#empty_set">Empty set</a></li><li><a href="#example_problem">Example problem</a></li><li><a href="#executable_philosophy">Executable philosophy</a></li><li><a href="#exercise_meta_tag">Exercise </a></li><li><a href="#x_risk">Existential risk</a></li><li><a href="#external_resources_meta_tag">External resources</a></li><li><a href="#extraordinary_claims">Extraordinary claims</a></li><li><a href="#fallacy">Fallacies</a></li><li><a href="#formal_definition_meta_tag">Formal definition</a><ul><li><a href="#formal_definition_meta_tag-wiki">wiki</a></li><li><a href="#formal_definition_meta_tag-no-type">no-type</a></li></ul></li><li><a href="#function">Function</a></li><li><a href="#value_alignment_glossary">Glossary (Value Alignment Theory)</a></li><li><a href="#goodness_estimate_bias">Goodness estimate biaser</a></li><li><a href="#group_mathematics">Group</a></li><li><a href="#group_isomorphism">Group isomorphism</a></li><li><a href="#guarded_definition">Guarded definition</a></li><li><a href="#guide_meta_tag">Guide</a></li><li><a href="#high_speed_meta_tag">High-speed explanation</a></li><li><a href="#bayes_for_humans">Humans doing Bayes</a></li><li><a href="#humean_free_boundary">Humean degree of freedom</a></li><li><a href="#image_requested_meta_tag">Image requested</a></li><li><a href="#Isomorphism_intro_math_0">Isomorphism: Intro (Math 0)</a></li><li><a href="#6th">It's better to give $1000 to one person one time than to lend it out through microloans and then, as the money's repaid, keep relending it to other people indefinitely</a></li><li><a href="#requisite_meta_tag">Just a requisite</a></li><li><a href="#KANSI">Known-algorithm non-self-improving agent</a></li><li><a href="#list_meta_tag">List</a></li><li><a href="#pointing_finger">Look where I'm pointing, not at my finger</a></li><li><a href="#low_speed_meta_tag">Low-speed explanation</a></li><li><a href="#math0">Math 0</a></li><li><a href="#math1">Math 1</a></li><li><a href="#math2">Math 2</a></li><li><a href="#math3">Math 3</a></li><li><a href="#labs_meta">Meta (Arbital Labs)</a></li><li><a href="#arbital_meta_tag">Meta tags</a></li><li><a href="#3zj">Meta tags which request an edit to the page</a></li><li><a href="#meta_utility">Meta-utility function</a></li><li><a href="#foreseeable_difficulties">Methodology of foreseeable difficulties</a></li><li><a href="#microlending">Microlending</a></li><li><a href="#mindcrime">Mindcrime</a></li><li><a href="#morphism">Morphism</a></li><li><a href="#nearest_unblocked">Nearest unblocked strategy</a></li><li><a href="#needs_accessible_summary_meta_tag">Needs accessible summary</a></li><li><a href="#needs_brief_summary_meta_tag">Needs brief summary</a></li><li><a href="#needs_clickbait_meta_tag">Needs clickbait</a></li><li><a href="#needs_examples_meta_tag">Needs examples</a></li><li><a href="#needs_exercises_meta_tag">Needs exercises</a></li><li><a href="#needs_image_meta_tag">Needs image</a></li><li><a href="#needs_lenses_meta_tag">Needs lenses</a></li><li><a href="#needs_links_meta_tag">Needs links</a></li><li><a href="#needs_parent_meta_tag">Needs parent</a></li><li><a href="#split_by_mastery_meta_tag">Needs splitting by mastery</a></li><li><a href="#needs_summary_meta_tag">Needs summary</a><ul><li><a href="#needs_summary_meta_tag-wiki">wiki</a></li><li><a href="#needs_summary_meta_tag-no-type">no-type</a></li></ul></li><li><a href="#4bn">Needs work</a></li><li><a href="#niceness_defense">Niceness is the first line of defense</a></li><li><a href="#NickBostrom">Nick Bostrom</a></li><li><a href="#nonadversarial">Non-adversarial principle</a></li><li><a href="#nonstandard_terminology_meta_tag">Non-standard terminology</a></li><li><a href="#ontology_identification">Ontology identification problem</a></li><li><a href="#taskagi_open_problems">Open subproblems in aligning a Task-based AGI</a></li><li><a href="#opinion_meta_tag">Opinion page</a></li><li><a href="#out_of_date_meta_tag">Out of date</a><ul><li><a href="#out_of_date_meta_tag-wiki">wiki</a></li><li><a href="#out_of_date_meta_tag-no-type">no-type</a></li></ul></li><li><a href="#paperclip_maximizer">Paperclip maximizer</a></li><li><a href="#patch_resistant">Patch resistance</a></li><li><a href="#PaulChristiano">Paul Christiano</a></li><li><a href="#philosophy">Philosophy</a></li><li><a href="#placeholder_meta_tag">Placeholder</a></li><li><a href="#politics">Politics</a></li><li><a href="#proof_meta_tag">Proof</a></li><li><a href="#proposed_a_class">Proposed A-Class</a></li><li><a href="#proposed_b_class">Proposed B-Class</a></li><li><a href="#psychologizing">Psychologizing</a></li><li><a href="#rationality">Rationality</a><ul><li><a href="#rationality-wiki">wiki</a></li><li><a href="#rationality-no-type">no-type</a></li></ul></li><li><a href="#set_mathematics">Set</a></li><li><a href="#shutdown_problem">Shutdown problem</a></li><li><a href="#shutdown_utility_function">Shutdown utility function</a></li><li><a href="#start_meta_tag">Start</a><ul><li><a href="#start_meta_tag-wiki">wiki</a></li><li><a href="#start_meta_tag-no-type">no-type</a></li></ul></li><li><a href="#stub_meta_tag">Stub</a><ul><li><a href="#stub_meta_tag-wiki">wiki</a></li><li><a href="#stub_meta_tag-no-type">no-type</a></li></ul></li><li><a href="#arbital_style_guide">Style guidelines</a></li><li><a href="#subjective_probability">Subjective probability</a></li><li><a href="#task_identification">Task identification problem</a></li><li><a href="#task_agi">Task-directed AGI</a></li><li><a href="#composition_of_group_homomorphisms_is_homomorphism">The composition of two group homomorphisms is a homomorphism</a></li><li><a href="#thought_experiment">Thought experiment</a></li><li><a href="#type_theory">Type theory</a></li><li><a href="#unassessed_meta_tag">Unassessed</a></li><li><a href="#unforeseen_maximum">Unforeseen maximum</a></li><li><a href="#utility_indifference">Utility indifference</a></li><li><a href="#value_identification">Value identification problem</a></li><li><a href="#Vingean_uncertainty">Vingean uncertainty</a></li><li><a href="#6tk">With some fixed amount of money to start, a microloan charity could make loans indefinitely</a></li><li><a href="#work_in_progress_meta_tag">Work in progress</a><ul><li><a href="#work_in_progress_meta_tag-wiki">wiki</a></li><li><a href="#work_in_progress_meta_tag-comment">comment</a></li></ul></li></ul><hr><h2 id="axiom_of_choice_definition_mathematical"><a class="page-link" href="page/axiom_of_choice_definition_mathematical.html"> Axiom of Choice: Definition (Formal)</a></h2><ul class="page-list"><li><a class="page-link" href="page/axiom_of_choice_definition_intuitive.html">Axiom of Choice Definition (Intuitive)</a> <q>Definition of the Axiom of Choice, without using heavy mathematical notation.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li></ul><h2 id="a_class_meta_tag"><a class="page-link" href="page/a_class_meta_tag.html">A-Class</a></h2><ul class="page-list"><li><a class="page-link" href="page/bayes_rule_guide.html">Bayes' rule: Guide</a> <q>The Arbital guide to Bayes' rule</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="ai_alignment"><a class="page-link" href="page/ai_alignment.html">AI alignment</a></h2><ul class="page-list"><li><a class="page-link" href="page/paul_ai_control.html">Paul Christiano's AI control blog</a> <q>Speculations on the design of safe, efficient AI systems.</q> - <a class="page-link" href="page/PaulChristiano.html">Paul Christiano</a></li></ul><h2 id="value_alignment_open_problem"><a class="page-link" href="page/value_alignment_open_problem.html">AI alignment open problem</a></h2><ul class="page-list"><li><a class="page-link" href="page/avert_instrumental_pressure.html">Averting instrumental pressures</a> <q>Almost-any utility function for an AI, whether the target is diamonds or paperclips or eudaimonia, implies subgoals like rapidly self-improving and refusing to shut down.  Can we make that not happen?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/avert_self_improvement.html">Averting the convergent instrumental strategy of self-improvement</a> <q>We probably want the first AGI to *not* improve as fast as possible, but improving as fast as possible is a convergent strategy for accomplishing most things.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/conservative_concept.html">Conservative concept boundary</a> <q>Given N example burritos, draw a boundary around what is a 'burrito' that is relatively simple and allows as few positive instances as possible.  Helps make sure the next thing generated is a burrito.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/corrigibility.html">Corrigibility</a> <q>&quot;I can't let you do that, Dave.&quot;</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/diamond_maximizer.html">Diamond maximizer</a> <q>How would you build an agent that made as much diamond material as possible, given vast computing power but an otherwise rich and complicated environment?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/inductive_ambiguity.html">Identifying ambiguous inductions</a> <q>What do a &quot;red strawberry&quot;, a &quot;red apple&quot;, and a &quot;red cherry&quot; have in common that a &quot;yellow carrot&quot; doesn't?  Are they &quot;red fruits&quot; or &quot;red objects&quot;?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/pointing_finger.html">Look where I'm pointing, not at my finger</a> <q>When trying to communicate the concept &quot;glove&quot;, getting the AGI to focus on &quot;gloves&quot; rather than &quot;my user's decision to label something a glove&quot; or &quot;anything that depresses the glove-labeling button&quot;.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/low_impact.html">Low impact</a> <q>The open problem of having an AI carry out tasks in ways that cause minimum side effects and change as little of the rest of the universe as possible.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/soft_optimizer.html">Mild optimization</a> <q>An AGI which, if you ask it to paint one car pink, just paints one car pink and doesn't tile the universe with pink-painted cars, because it's not trying *that* hard to max out its car-painting score.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/nonadversarial.html">Non-adversarial principle</a> <q>At no point in constructing an Artificial General Intelligence should we construct a computation that tries to hurt us, and then try to stop it from hurting us.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/ontology_identification.html">Ontology identification problem</a> <q>How do we link an agent's utility function to its model of the world, when we don't know what that model will look like?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/taskagi_open_problems.html">Open subproblems in aligning a Task-based AGI</a> <q>Open research problems, especially ones we can model today, in building an AGI that can &quot;paint all cars pink&quot; without turning its future light cone into pink-painted cars.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/otherizer.html">Other-izing (wanted: new optimization idiom)</a> <q>Maximization isn't possible for bounded agents, and satisficing doesn't seem like enough.  What other kind of 'izing' might be good for realistic, bounded agents?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/updated_deference.html">Problem of fully updated deference</a> <q>Why moral uncertainty doesn't stop an AI from defending its off-switch.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/4l.html">Safe impact measure</a> <q>What can we measure to make sure an agent is acting in a safe manner?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/shutdown_problem.html">Shutdown problem</a> <q>How to build an AGI that lets you shut it down, despite the obvious fact that this will interfere with whatever the AGI's goals are.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="Arbital_tag"><a class="page-link" href="page/Arbital_tag.html">Arbital &quot;tag&quot; relationship</a></h2><ul class="page-list"><li><a class="page-link" href="page/arbital_meta_tag.html">Meta tags</a> <q>What are meta tags and when to use them?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="arbital_summaries"><a class="page-link" href="page/arbital_summaries.html">Arbital page summaries</a></h2><ul class="page-list"><li><a class="page-link" href="page/3r0.html">Arbital page summaries Markdown syntax</a> <q>How to create page summaries using Arbital's Markdown syntax.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li></ul><h2 id="arbital_project_outline"><a class="page-link" href="page/arbital_project_outline.html">Arbital project outline</a></h2><ul class="page-list"><li><a class="page-link" href="page/numbers_proposal.html">Project proposal: Intro to numbers</a> <q>Should Arbital's first &quot;project&quot; be a guide to numbers?</q> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li></ul><h2 id="6tl"><a class="page-link" href="page/6tl.html">Assuming significant overhead in monitoring recipients of a microloan, it's more efficient to let them keep the money.</a></h2><ul class="page-list"><li><a class="page-link" href="page/6tg.html">Mic-Ra-finance and the illusion of control</a> <q>This post discusses the following claims:

* [claim([6th])]
* [claim([6tk])]
* [claim([6tl])]</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li></ul><h2 id="Sovereign"><a class="page-link" href="page/Sovereign.html">Autonomous AGI</a></h2><ul class="page-list"><li><a class="page-link" href="page/cev.html">Coherent extrapolated volition (alignment target)</a> <q>A proposed direction for an extremely well-aligned autonomous superintelligence - do what humans would want, if we knew what the AI knew, thought that fast, and understood ourselves.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="b_class_meta_tag"><a class="page-link" href="page/b_class_meta_tag.html">B-Class</a></h2><ul class="page-list"><li><a class="page-link" href="page/rationality_of_voting.html">'Rationality' of voting in elections</a> <q>&quot;A single vote is very unlikely to swing the election, so your vote is unlikely to have an effect&quot; versus &quot;Many people similar to you are making a similar decision about whether to vote.&quot;</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/pd_tournament_99ldt_1cdt.html">99LDT x 1CDT oneshot PD tournament as arguable counterexample to LDT doing better than CDT</a> <q>Arguendo, if 99 LDT agents and 1 CDT agent are facing off in a one-shot Prisoner's Dilemma tournament, the CDT agent does better on a problem that CDT considers 'fair'.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/a_whirlwind_tour.html">A whirlwind tour</a> <q>A rapid tour of Eric's thoughts on the accelerator project.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/absentminded_driver.html">Absent-Minded Driver dilemma</a> <q>A road contains two identical intersections.  An absent-minded driver wants to turn right at the second intersection.  &quot;With what probability should the driver turn right?&quot; argue decision theorists.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/accelerator_project.html">Accelerator Project</a> <q>The Accelerator Project aims to create a low-cost environment which facilitates rapid personal growt…</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/Arbital.html">Arbital</a> <q>Arbital is the place for crowdsourced, intuitive math explanations.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/Arbital_lens.html">Arbital lens</a> <q>A lens is a page that presents another page's content from a different angle.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/1sm.html">Arbital: Google Maps for knowledge</a> <q>Take your understanding from where it is to where it wants to be.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/learning_from_wikipedia.html">Arbital: learning from Wikipedia</a> <q>How is Arbital different from Wikipedia?</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/associative_operation.html">Associative operation</a> <q>An **associative operation** $\bullet : X \times X \to X$ is a binary operation such that for all $x…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/associativity_examples.html">Associativity: Examples</a> <q>Yes: [Addition], [multiplication], string concatenation. No: [subtraction], [division], a Function …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/associativity_intuition.html">Associativity: Intuition</a> <q>Associative functions can be interpreted as families of functions that reduce lists down to a singl…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bayes_rule.html">Bayes' rule</a> <q>Bayes' rule is the core theorem of probability theory saying how to revise our beliefs when we make a new observation.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/5f3.html">Bayes' rule: Beginner's guide</a> <q>Beginner's guide to learning about Bayes' rule.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/bayes_rule_functional.html">Bayes' rule: Functional form</a> <q>Bayes' rule for to continuous variables.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_log_odds.html">Bayes' rule: Log-odds form</a> <q>A simple transformation of Bayes' rule reveals tools for measuring degree of belief, and strength of evidence.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_rule_odds.html">Bayes' rule: Odds form</a> <q>The simplest and most easily understandable form of Bayes' rule uses relative odds.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_rule_probability.html">Bayes' rule: Probability form</a> <q>The original formulation of Bayes' rule.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bayes_science_virtues.html">Bayesian view of scientific virtues</a> <q>Why is it that science relies on bold, precise, and falsifiable predictions? Because of Bayes' rule, of course.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_rule_elimination.html">Belief revision as probability elimination</a> <q>Update your beliefs by throwing away large chunks of probability mass.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bit.html">Bit</a> <q>The term &quot;bit&quot; refers to different concepts in different fields. The common theme across all the us…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/intro_utility_coherence.html">Coherent decisions imply consistent utilities</a> <q>Why do we all use the 'expected utility' formalism?  Because any behavior that can't be viewed from that perspective, must be qualitatively self-defeating (in various mathy ways).</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/commutativity_intuition.html">Commutativity: Intuition</a> <q>We can think of commutativity either as an artifact of notation, or as a symmetry in the output of a…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/arbital_contributing.html">Contributing to Arbital</a> <q>Want to help Arbital become awesome?</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/cyclic_group_intro_math_0.html">Cyclic Group Intro (Math 0)</a> <q>A finite cyclic group is a little bit like a clock.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/death_in_damascus.html">Death in Damascus</a> <q>Death tells you that It is coming for you tomorrow.  You can stay in Damascus or flee to Aleppo.  Whichever decision you actually make is the wrong one.  This gives some decision theories trouble.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/derivative_calculus.html">Derivative</a> <q>How things change</q> - <a class="page-link" href="page/MichaelCohen.html">Michael Cohen</a></li><li><a class="page-link" href="page/diseasitis.html">Diseasitis</a> <q>20% of patients have Diseasitis. 90% of sick patients and 30% of healthy patients turn a tongue depressor black. You turn a tongue depressor black. What's the chance you have Diseasitis?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/digit_exchange_rates.html">Exchange rates between digits</a> <q>In terms of data storage, if a coin is worth $1, a digit wheel is worth more than $3.32, but less than $3.33. Why?</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bayes_extraordinary_claims.html">Extraordinary claims require extraordinary evidence</a> <q>The people who adamantly claim they were abducted by aliens do provide some evidence for aliens. They just don't provide quantitatively enough evidence.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_guide_end.html">Finishing your Bayesian path on Arbital</a> <q>The page that comes at the end of reading the Arbital Guide to Bayes' rule</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/fractional_digits.html">Fractional digits</a> <q>When $b$ and $x$ are integers, $\log_b(x)$ has a few good interpretations. It's roughly the length o…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bayes_frequency_diagram_diseasitis.html">Frequency diagrams: A first look at Bayes</a> <q>The most straightforward visualization of Bayes' rule.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/group_mathematics.html">Group</a> <q>The algebraic structure that captures symmetry, relationships between transformations, and part of what multiplication and addition have in common.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bayes_rule_fast_intro.html">High-speed intro to Bayes's rule</a> <q>A high-speed introduction to Bayes's Rule on one page, for the impatient and mathematically adept.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_want_foundations.html">Interest in mathematical foundations in Bayesianism</a> <q>&quot;Want&quot; this requisite if you prefer to see extra information about the mathematical foundations in Bayesianism.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_rule_odds_intro.html">Introduction to Bayes' rule: Odds form</a> <q>Bayes' rule is simple, if you think in terms of relative odds.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/log_guide.html">Introductory guide to logarithms</a> <q>Welcome to the Arbital introduction to logarithms! In modern education, logarithms are often mention…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/Isomorphism_intro_math_0.html">Isomorphism: Intro (Math 0)</a> <q>Things which are basically the same, except for some stuff you don't care about.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/math_join.html">Join and meet</a> <q>Let $\langle P, \leq \rangle$ be a poset, and let $S \subseteq P$. The **join** of $S$ in $P$, deno…</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="page/logspace.html">Life in logspace</a> <q>The log lattice hints at the reason that engineers, scientists, and AI researchers find logarithms s…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log_as_length.html">Log as generalized length</a> <q>To estimate the log (base 10) of a number, count how many digits it has.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log_as_comm_cost.html">Log as the change in the cost of communicating</a> <q>When interpreting logarithms as a generalization of the notion of &quot;length&quot; and as digit exchange rat…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/mathematical_induction.html">Mathematical induction</a> <q>Proving a statement about all positive integers by knocking them down like dominoes.</q> - <a class="page-link" href="page/DouglasWeathers.html">Douglas Weathers</a></li><li><a class="page-link" href="page/bayes_odds_to_probability.html">Odds form to probability form</a> <q>The odds form of Bayes' rule works for any two hypotheses $H_i$ and $H_j,$ and looks like this:

$$\…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/poset.html">Partially ordered set</a> <q>A set endowed with a relation that is reflexive, transitive, and antisymmetric.</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="page/bayes_rule_details.html">Path: Multiple angles on Bayes's Rule</a> <q>A learning-path placeholder page for learning multiple angles on Bayes's Rule.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/probability_distribution_motivated_definition.html">Probability distribution: Motivated definition</a> <q>People keep writing things like P(sick)=0.3. What does this mean, on a technical level?</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bayes_probability_notation_math1.html">Probability notation for Bayes' rule: Intro (Math 1)</a> <q>How to read, and identify, the probabilities in Bayesian problems.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/universal_property_outline.html">Project outline: Intro to the Universal Property</a> <q>Outline detailing all the work required for a proposed Arbital Project</q> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li><li><a class="page-link" href="page/bayes_rule_proof.html">Proof of Bayes' rule</a> <q>Proofs of Bayes' rule, with graphics</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_rule_probability_proof.html">Proof of Bayes' rule: Probability form</a> <q>Let $\mathbf H$ be a [random\_variable variable] in $\mathbb P$ for the true hypothesis, and let $H_…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/proof_of_rice_theorem.html">Proof of Rice's theorem</a> <q>A standalone proof of Rice's theorem, including one surprising lemma.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/log_properties.html">Properties of the logarithm</a> <q>- $\log_b(x \cdot y) = \log_b(x) + \log_b(y)$ for any $b$, this is the defining characteristic of …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/rice_theorem.html">Rice's Theorem</a> <q>Rice's Theorem tells us that if we want to determine pretty much anything about the behaviour of an arbitrary computer program, we can't in general do better than just running it.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/flee_from_surprise.html">Shift towards the hypothesis of least surprise</a> <q>When you see new evidence, ask: which hypothesis is *least surprised?*</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/strictly_confused.html">Strictly confused</a> <q>A hypothesis is strictly confused by the raw data, if the hypothesis did much worse in predicting it than the hypothesis itself expected.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/log_tutorial_end.html">The End (of the basic log tutorial)</a> <q>That concludes our introductory tutorial on logarithms! You have made it to the end.

Throughout thi…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log_characteristic.html">The characteristic of the logarithm</a> <q>Any time you find an output that adds whenever the input multiplies, you're probably looking at a (…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log_lattice.html">The log lattice</a> <q>Log as the change in the cost of communicating and other pages give physical interpretations of what…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/missing_step_between_Zero_and_Hero.html">The missing step between Zero and Hero</a> <q>Creating a space for high potential people grow and improve the world at scale.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/uncountability_intuitive.html">Uncountability: Intuitive Intro</a> <q>Are all sizes of infinity the same?  What does &quot;the same&quot; even mean here?</q> - <a class="page-link" href="page/JasonGross.html">Jason Gross</a></li><li><a class="page-link" href="page/empty_set_universal_property.html">Universal property of the empty set</a> <q>The empty set can be characterised by how it interacts with other sets, rather than by any explicit property of the empty set itself.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/product_universal_property.html">Universal property of the product</a> <q>The product can be defined in a very general way, applicable to the natural numbers, to sets, to algebraic structures, and so on.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/utility_function.html">Utility function</a> <q>The only coherent way of wanting things is to assign consistent relative scores to outcomes.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_waterfall_diagram.html">Waterfall diagram</a> <q>Visualizing Bayes' rule as the mixing of probability streams.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_waterfall_diseasitis.html">Waterfall diagrams and relative odds</a> <q>A way to visualize Bayes' rule that yields an easier way to solve some problems</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/arbital_front_page.html">Welcome to Arbital</a> <q>Front page explaining what Arbital is all about.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/log_definition.html">What is a logarithm?</a> <q>Logarithms are a group of functions that take a number as input and produce another number. There i…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="bayes_reasoning"><a class="page-link" href="page/bayes_reasoning.html">Bayesian reasoning</a></h2><ul class="page-list"><li><a class="page-link" href="page/likelihood_vs_pvalue.html">Likelihood functions, p-values, and the replication crisis</a> <q>What's the whole Bayesian-vs.-frequentist debate about?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="behaviorist"><a class="page-link" href="page/behaviorist.html">Behaviorist genie</a></h2><ul class="page-list"><li><a class="page-link" href="page/probable_environment_hacking.html">Distant superintelligences can coerce the most probable environment of your AI</a> <q>Distant superintelligences may be able to hack your local AI, if your AI's preference framework depends on its most probable environment.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/distant_SIs.html">Modeling distant superintelligences</a> <q>The several large problems that might occur if an AI starts to think about alien superintelligences.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="bijective_function"><a class="page-link" href="page/bijective_function.html">Bijective function</a></h2><ul class="page-list"><li><a class="page-link" href="page/Isomorphism_intro_math_0.html">Isomorphism: Intro (Math 0)</a> <q>Things which are basically the same, except for some stuff you don't care about.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li></ul><h2 id="c_class_meta_tag"><a class="page-link" href="page/c_class_meta_tag.html">C-Class</a></h2><ul class="page-list"><li><a class="page-link" href="page/arbital_markdown.html">Arbital Markdown</a> <q>All about Arbital's extended Markdown syntax.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arbital_project.html">Arbital projects</a> <q>Arbital projects are small-scale drives to fill in areas of content.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arbital_scope.html">Arbital scope</a> <q>What kind of content is Arbital looking for?</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arbital_user_groups.html">Arbital user groups</a> <q>Users can attain different powers and responsibilities on Arbital.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/1sn.html">Arbital: fixing online discussion</a> <q>How can Arbital do better than existing discussion platforms?</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arithmetical_hierarchy.html">Arithmetical hierarchy</a> <q>The arithmetical hierarchy is a way of classifying logical statements by the number of clauses saying &quot;for every object&quot; and &quot;there exists an object&quot;.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/1mj.html">Arithmetical hierarchy: If you don't read logic</a> <q>The arithmetical hierarchy is a way of stratifying statements by how many &quot;for every number&quot; and &quot;th…</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/author_guide_to_arbital.html">Author's guide to Arbital</a> <q>How to write intuitive, flexible content on Arbital.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/axiom.html">Axiom</a> <q>An **axiom** of a [theory\_mathematics theory] $T$ is a [well\_formed well-formed] [sentence\_mathem…</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/bayes_rule_definition.html">Bayes' rule: Definition</a> <q>Bayes' rule is the mathematics of probability theory governing how to update your beliefs in the lig…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bayes_rule_proportional.html">Bayes' rule: Proportional form</a> <q>The fastest way to say something both convincing and true about belief-updating.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_rule_multiple.html">Bayes' rule: Vector form</a> <q>For when you want to apply Bayes' rule to lots of evidence and lots of variables, all in one go. (This is more or less how spam filters work.)</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/data_bit.html">Bit (of data)</a> <q>A bit of data is the amount of data required to single out one message from a set of two. Equivalen…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bezout_theorem.html">Bézout's theorem</a> <q>Bézout's theorem is an important link between highest common factors and the integer solutions of a certain equation.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/category_theory.html">Category theory</a> <q>How mathematical objects are related to others in the same category.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/mathematics_ceiling.html">Ceiling</a> <q>The ceiling of a real number $x,$ denoted $\lceil x \rceil$ or sometimes $\operatorname{ceil}(x),$ i…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/conditional_probability.html">Conditional probability</a> <q>The notation for writing &quot;The probability that someone has green eyes, if we know that they have red hair.&quot;</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/conditional_probability_refresher.html">Conditional probability: Refresher</a> <q>Is P(yellow | banana) the probability that a banana is yellow, or the probability that a yellow thing is a banana?</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/set_disjoint_union.html">Disjoint union of sets</a> <q>One of the most basic ways we have of joining two sets together.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/division_of_rational_numbers_math_0.html">Division of rational numbers (Math 0)</a> <q>&quot;Division&quot; is the idea of &quot;dividing something up among some people so that we can give equal amounts to each person&quot;.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/edge_instantiation.html">Edge instantiation</a> <q>When you ask the AI to make people happy, and it tiles the universe with the smallest objects that can be happy.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/elementary_algebra.html">Elementary Algebra</a> <q>How do we describe relations between different things? How can we figure out new true things from tr…</q> - <a class="page-link" href="page/AdeleLopez.html">Adele Lopez</a></li><li><a class="page-link" href="page/cromwells_rule.html">Empirical probabilities are not exactly 0 or 1</a> <q>&quot;Cromwell's Rule&quot; says that probabilities of exactly 0 or 1 should never be applied to empirical propositions - there's always some probability, however tiny, of being mistaken.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/expected_value.html">Expected value</a> <q>Trying to assign value to an uncertain state? The weighted average of outcomes is probably the tool you need.</q> - <a class="page-link" href="page/MichaelCohen.html">Michael Cohen</a></li><li><a class="page-link" href="page/explicit_bayes_counters_worry.html">Explicit Bayes as a counter for 'worrying'</a> <q>Explicitly walking through Bayes's Rule can summarize your knowledge and thereby stop you from bouncing around pieces of it.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/extraordinary_claims.html">Extraordinary claims</a> <q>What makes something an 'extraordinary claim' that requires extraordinary evidence?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/5wv.html">Factorial</a> <q>The *factorial* of a number $n$ is how we describe &quot;how many different ways we can arrange $n$ obje…</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/featured_math.html">Featured math content</a> <q>Some Arbital pages we think are great!</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/bayes_frequency_diagram.html">Frequency diagram</a> <q>Visualizing Bayes' rule by manipulating frequencies in large populations</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/cognitive_alignment.html">Generalized principle of cognitive alignment</a> <q>When we're asking how we want the AI to think about an alignment problem, one source of inspiration is trying to have the AI mirror our own thoughts about that problem.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/goodharts_curse.html">Goodhart's Curse</a> <q>The Optimizer's Curse meets Goodhart's Law.  For example, if our values are V, and an AI's utility function U is a proxy for V, optimizing for high U seeks out 'errors'--that is, high values of U - V.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/group_isomorphism.html">Group isomorphism</a> <q>&quot;Isomorphism&quot; is the proper notion of &quot;sameness&quot; or &quot;equality&quot; among groups.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/integers_intro_math0.html">Integers: Intro (Math 0)</a> <q>The integers are the whole numbers extended into the negatives.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/interruptibility.html">Interruptibility</a> <q>A subproblem of corrigibility under the machine learning paradigm: when the agent is interrupted, it must not learn to prevent future interruptions.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/isomorphism.html">Isomorphism</a> <q>A morphism between two objects which describes how they are &quot;essentially equivalent&quot; for the purposes of the theory under consideration.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/lambda_calculus.html">Lambda calculus</a> <q>A minimal, inefficient, and hard-to-read, but still interesting and useful, programming language.</q> - <a class="page-link" href="page/DylanHendrickson.html">Dylan Hendrickson</a></li><li><a class="page-link" href="page/laplace_rule_of_succession.html">Laplace's Rule of Succession</a> <q>Suppose you flip a coin with an unknown bias 30 times, and see 4 heads and 26 tails.  The Rule of Succession says the next flip has a 5/32 chance of showing heads.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/likelihood_function.html">Likelihood function</a> <q>Let's say you have a piece of evidence $e$ and a set of hypotheses $\mathcal H.$ Each $H_i \in \math…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/limited_agi.html">Limited AGI</a> <q>Task-based AGIs don't need unlimited cognitive and material powers to carry out their Tasks; which means their powers can potentially be limited.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/modal_combat.html">Modal combat</a> <q>Modal combat</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/exclusive_exhaustive.html">Mutually exclusive and exhaustive</a> <q>The condition needed for probabilities to sum to 1</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/odds_intro.html">Odds: Introduction</a> <q>What's the difference between probabilities and odds? Why is a 20% probability of success equivalent to 1 : 4 odds favoring success?</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/odds_technical.html">Odds: Technical explanation</a> <q>Formal definitions, alternate representations, and uses of odds and odds ratios (like a 1 : 2 chance of drawing a red ball vs. green ball from a barrel).</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/set_theory_operation.html">Operations in Set theory</a> <q>An operation in set theory is a Function of two sets, that returns a set.

Common set operations inc…</q> - <a class="page-link" href="page/MYass.html">M Yass</a></li><li><a class="page-link" href="page/operator_mathematics.html">Operator</a> <q>An operation $f$ on a set $S$ is a function that takes some values from $S$ and produces a new value…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bayes_ordinary_claims.html">Ordinary claims require ordinary evidence</a> <q>Extraordinary claims require extraordinary evidence, but ordinary claims *don't*.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/parfits_hitchhiker.html">Parfit's Hitchhiker</a> <q>You are dying in the desert.  A truck-driver who is very good at reading faces finds you, and offers to drive you into the city if you promise to pay $1,000 on arrival.  You are a selfish rationalist.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/posterior_probability.html">Posterior probability</a> <q>What we believe, after seeing the evidence and doing a Bayesian update.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/probability.html">Probability</a> <q>The degree to which someone believes something, measured on a scale from 0 to 1, allowing us to do math to it.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/proportion.html">Proportion</a> <q>A representation of a value as a fraction or multiple of another value.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/rationals_form_a_field_math_0.html">Rational arithmetic all works together</a> <q>The various operations of arithmetic all play nicely together in a certain specific way.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/real_numbers_uncountable.html">Real numbers are uncountable</a> <q>The real numbers are uncountable.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/set_mathematics.html">Set</a> <q>An unordered collection of distinct objects.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/1hh.html">Solomonoff induction: Intro Dialogue (Math 2)</a> <q>An introduction to Solomonoff induction for the unfamiliar reader who isn't bad at math</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/arbital_style_guide.html">Style guidelines</a> <q>Various stylistic conventions people should follow on Arbital</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/subjective_probability.html">Subjective probability</a> <q>Probability is in the mind, not in the environment.  If you don't know whether a coin came up heads or tails, that's a fact about you, not a fact about the coin.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/the_plan_experiment.html">The plan experiment</a> <q>Root page for describing the reason and the process for planning how to approach and navigate through AGI development.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/transparent_newcombs_problem.html">Transparent Newcomb's Problem</a> <q>Omega has left behind a transparent Box A containing $1000, and a transparent Box B containing $1,000,000 or nothing.  Box B is full iff Omega thinks you one-box on seeing a full Box B.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/turing_machine.html">Turing machine</a> <q>A Turing Machine is a simple mathematical model of computation that is powerful enough to describe any computation a computer can do.</q> - <a class="page-link" href="page/EricLeese.html">Eric Leese</a></li><li><a class="page-link" href="page/ultimatum_game.html">Ultimatum Game</a> <q>A Proposer decides how to split $10 between themselves and the Responder.  The Responder can take what is offered, or refuse, in which case both parties get nothing.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/uncountable.html">Uncountability</a> <q>Some infinities are bigger than others. Uncountable infinities are larger than countable infinities.</q> - <a class="page-link" href="page/JasonGross.html">Jason Gross</a></li><li><a class="page-link" href="page/uncountability_math_3.html">Uncountability (Math 3)</a> <q>Formal definition of uncountability, and foundational considerations.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/2w1.html">Uncountability: Intro (Math 1)</a> <q>Not all infinities are created equal.  The infinity of real numbers is infinitely larger than the infinity of counting numbers.</q> - <a class="page-link" href="page/JasonGross.html">Jason Gross</a></li><li><a class="page-link" href="page/disjoint_union_universal_property.html">Universal property of the disjoint union</a> <q>Just as the empty set may be described by a universal property, so too may the disjoint union of sets.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/whole_number.html">Whole number</a> <q>A term that can refer to three different sets of &quot;numbers that are not fractions&quot;.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li></ul><h2 id="category_theory"><a class="page-link" href="page/category_theory.html">Category theory</a></h2><ul class="page-list"><li><a class="page-link" href="page/isomorphism.html">Isomorphism</a> <q>A morphism between two objects which describes how they are &quot;essentially equivalent&quot; for the purposes of the theory under consideration.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/morphism.html">Morphism</a> <q>A morphism is the abstract representation of a relation between mathematical objects.

Usually, it i…</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li></ul><h2 id="central_example"><a class="page-link" href="page/central_example.html">Central examples</a></h2><ul class="page-list"><li><a class="page-link" href="page/value_alignment_central_examples.html">Central examples</a> <q>List of central examples in Value Alignment Theory domain.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="complexity_of_value"><a class="page-link" href="page/complexity_of_value.html">Complexity of value</a></h2><ul class="page-list"><li><a class="page-link" href="page/value_laden.html">Value-laden</a> <q>Cure cancer, but avoid any bad side effects?  Categorizing &quot;bad side effects&quot; requires knowing what's &quot;bad&quot;.  If an agent needs to load complex human goals to evaluate something, it's &quot;value-laden&quot;.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="concept_meta_tag"><a class="page-link" href="page/concept_meta_tag.html">Concept</a></h2><ul class="page-list"><li><a class="page-link" href="page/countability.html">Countability</a> <q>Some infinities are bigger than others.  Countable infinities are the smallest infinities.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/crony_belief.html">Crony belief</a> <q>**Crony belief** is a concept originally introduced in Kevin Simler's post, &quot;Crony Beliefs&quot;. It's us…</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/donor_lottery.html">Donor lottery</a> <q>An arrangement where a group of people pool their money and pick one person to give it away.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/logical_dt.html">Logical decision theories</a> <q>Root page for topics on logical decision theory, with multiple intros for different audiences.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/odds.html">Odds</a> <q>Odds express a relative probability.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/outside_view.html">Outside view</a> <q>Taking the **outside view** (another name for reference class forecasting) means using an estimate b…</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/uncountable.html">Uncountability</a> <q>Some infinities are bigger than others. Uncountable infinities are larger than countable infinities.</q> - <a class="page-link" href="page/JasonGross.html">Jason Gross</a></li></ul><h2 id="context_disaster"><a class="page-link" href="page/context_disaster.html">Context disaster</a></h2><ul class="page-list"><li><a class="page-link" href="page/correlated_coverage.html">Correlated coverage</a> <q>In which parts of AI alignment can we hope that getting many things right, will mean the AI gets everything right?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/low_impact.html">Low impact</a> <q>The open problem of having an AI carry out tasks in ways that cause minimum side effects and change as little of the rest of the universe as possible.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="corrigibility"><a class="page-link" href="page/corrigibility.html">Corrigibility</a></h2><ul class="page-list"><li><a class="page-link" href="page/convergent_strategies.html">Convergent instrumental strategies</a> <q>Paperclip maximizers can make more paperclips by improving their cognitive abilities or controlling more resources.  What other strategies would almost-any AI try to use?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="cyclic_group_intro_math_0"><a class="page-link" href="page/cyclic_group_intro_math_0.html">Cyclic Group Intro (Math 0)</a></h2><ul class="page-list"><li><a class="page-link" href="page/modular_arithmetic.html">Modular arithmetic</a> <q>Addition as traveling around a circle, instead of along a line.</q> - <a class="page-link" href="page/MalcolmMcCrimmon.html">Malcolm McCrimmon</a></li></ul><h2 id="decision_theory"><a class="page-link" href="page/decision_theory.html">Decision theory</a></h2><ul class="page-list"><li><a class="page-link" href="page/Indirect_decision_theory.html">Indirect decision theory</a> <q>In which I argue that understanding decision theory can be delegated to AI.

### Indirect normativit…</q> - <a class="page-link" href="page/PaulChristiano.html">Paul Christiano</a></li></ul><h2 id="definition_meta_tag"><a class="page-link" href="page/definition_meta_tag.html">Definition</a></h2><ul class="page-list"><li><a class="page-link" href="page/ai_concept.html">'Concept'</a> <q>In the context of Artificial Intelligence, a 'concept' is a category, something that identifies thingies as being inside or outside the concept.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/Kolmogorov_complexity.html">Algorithmic complexity</a> <q>When you compress the information, what you are left with determines the complexity.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/alternating_group.html">Alternating group</a> <q>The alternating group is the only normal subgroup of the symmetric group (on five or more generators).</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/function_arity.html">Arity (of a function)</a> <q>The arity of a function is the number of parameters that it takes. For example, the function $f(a, b…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bijective_function.html">Bijective function</a> <q>A bijective function is a function with an inverse.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/closure_mathematics.html">Closure</a> <q>A set $S$ is _closed_ under an operation $f$ if, whenever $f$ is fed elements of $S$, it produces an…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/function_codomain.html">Codomain (of a function)</a> <q>The codomain $\operatorname{cod}(f)$ of a function $f : X \to Y$ is $Y$, the set of possible outputs…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/development_phase_unpredictable.html">Development phase unpredictable</a> <q>Several proposed problems in advanced safety are alleged to be difficult because they depend on some…</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/dihedral_group.html">Dihedral group</a> <q>The dihedral groups are natural examples of groups, arising from the symmetries of regular polygons.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/function_domain.html">Domain (of a function)</a> <q>The domain $\operatorname{dom}(f)$ of a function $f : X \to Y$ is $X$, the set of valid inputs for t…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/function_image.html">Image (of a function)</a> <q>The image $\operatorname{im}(f)$ of a function $f : X \to Y$ is the set of all possible outputs of $…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/injective_function.html">Injective function</a> <q>A Function $f: X \to Y$ is *injective* if it has the property that whenever $f(x) = f(y)$, it is the…</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/instrumental.html">Instrumental</a> <q>What is &quot;instrumental&quot; in the context of Value Alignment Theory?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/intended_goal.html">Intended goal</a> <q>Definition.  An &quot;intended goal&quot; refers to the intuitive intention in the mind of a human programmer …</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/kernel_of_group_homomorphism.html">Kernel of group homomorphism</a> <q>The kernel of a Group homomorphism $f: G \to H$ is the collection of all elements $g$ in $G$ such th…</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/likelihood_notation.html">Likelihood notation</a> <q>The likelihood of a piece of evidence $e$ according to a hypothesis $H,$ known as &quot;the likelihood of…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/5b.html">Linguistic conventions in value alignment</a> <q>How and why to use precise language and words with special meaning when talking about value alignment.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/modalized_modal_sentence.html">Modalized modal sentence</a> <q>A [ modal sentence] $A$ is said to be **modalized** in $p$ if every occurrence of $p$ happens within…</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/natural_number.html">Natural number</a> <q>The numbers we use to count: 0, 1, 2, 3, ...</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/normal_subgroup.html">Normal subgroup</a> <q>Normal subgroups are subgroups which are in some sense &quot;the same from all points of view&quot;.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/object_level_goal.html">Object-level vs. indirect goals</a> <q>Difference between &quot;give Alice the apple&quot; and &quot;give Alice what she wants&quot;.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/group_order.html">Order of a group</a> <q>The order $|G|$ of a group $G$ is the size of its underlying set. For example, if $G=(X,\bullet)$ an…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/pivotal.html">Pivotal event</a> <q>Which types of AIs, if they work, can do things that drastically change the nature of the further game?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/preference_framework.html">Preference framework</a> <q>What's the thing an agent uses to compare its preferences?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/value_alignment_programmer.html">Programmer</a> <q>Who is building these advanced agents?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/function_range.html">Range (of a function)</a> <q>The &quot;range&quot; of a function is an ambiguous term that is generally used to refer to either the functio…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/set_builder_notation.html">Set builder notation</a> <q>$\{ 2n \mid n \in \mathbb N \}$ denotes the set of all even numbers, using set builder notation. Set…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/sign_homomorphism_symmetric_group.html">Sign homomorphism (from the symmetric group)</a> <q>The sign homomorphism is how we extract the alternating group from the symmetric group.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/simple_group.html">Simple group</a> <q>The simple groups form the &quot;building blocks&quot; of group theory, analogously to the prime numbers in number theory.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/text_string.html">String (of text)</a> <q>A string (of text) is a series of letters (often denoted by quote marks), such as `&quot;abcd&quot;` or `&quot;hell…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/strong_uncontainability.html">Strong cognitive uncontainability</a> <q>An advanced agent can win in ways humans can't understand in advance.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/surjective_function.html">Surjective function</a> <q>A surjective function is one which &quot;hits everything in the codomain&quot;.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/transposition_in_symmetric_group.html">Transposition (as an element of a symmetric group)</a> <q>A transposition is the simplest kind of permutation: it swaps two elements.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/value_alignment_utility.html">Utility</a> <q>What is &quot;utility&quot; in the context of Value Alignment Theory?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/value_alignment_value.html">Value</a> <q>The word 'value' in the phrase 'value alignment' is a metasyntactic variable that indicates the speaker's future goals for intelligent life.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/n_message.html">n-message</a> <q>A message singling out one thing from a set of $n$ is sometimes called an $n$-message. For example,…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="development_phase_unpredictable"><a class="page-link" href="page/development_phase_unpredictable.html">Development phase unpredictable</a></h2><ul class="page-list"><li><a class="page-link" href="page/ontology_identification.html">Ontology identification problem</a> <q>How do we link an agent's utility function to its model of the world, when we don't know what that model will look like?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="disambiguation_meta_tag"><a class="page-link" href="page/disambiguation_meta_tag.html">Disambiguation</a></h2><ul class="page-list"><li><a class="page-link" href="page/bit.html">Bit</a> <q>The term &quot;bit&quot; refers to different concepts in different fields. The common theme across all the us…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/whole_number.html">Whole number</a> <q>A term that can refer to three different sets of &quot;numbers that are not fractions&quot;.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li></ul><h2 id="discussion_norms"><a class="page-link" href="page/discussion_norms.html">Discussion norms</a></h2><ul class="page-list"><li><a class="page-link" href="page/7f6.html">Arbital needs a mechanism for defining terms</a> <q>Much of the discussion in claims seems to be about defining terms, which is a foundational part of r…</q> - <a class="page-link" href="page/AndreaGallagher.html">Andrea Gallagher</a></li><li><a class="page-link" href="page/72c.html">Comments are a high-quality, high-sensitivity measure of engagement with little in the way of viable substitutes.</a> <q>Source of claim: Improve comments by tagging claims by Benjamin Hoffman</q> - <a class="page-link" href="page/StephanieZolayvar.html">Stephanie Zolayvar</a></li><li><a class="page-link" href="page/6yv.html">Correct credit-tracking is very important if we want our community to generate new good ideas.</a> <q>Correct credit-tracking is very important if we want our community to generate new good ideas.</q> - <a class="page-link" href="page/AnnaSalamon.html">Anna Salamon</a></li><li><a class="page-link" href="page/72f.html">Explicitly tagging the core claims of a post will make people substantially more likely to respond to these claims.</a> <q>Source of claim: Improve comments by tagging claims by Benjamin Hoffman</q> - <a class="page-link" href="page/StephanieZolayvar.html">Stephanie Zolayvar</a></li><li><a class="page-link" href="page/72d.html">Irrelevant nitpicks are an important problem in comment sections on sites such as LessWrong.</a> <q>Source of claim: Improve comments by tagging claims by Benjamin Hoffman</q> - <a class="page-link" href="page/StephanieZolayvar.html">Stephanie Zolayvar</a></li><li><a class="page-link" href="page/72b.html">Location on the comments-links continuum is an important aspect of discourse design.</a> <q>Source of claim: Improve comments by tagging claims by Benjamin Hoffman</q> - <a class="page-link" href="page/StephanieZolayvar.html">Stephanie Zolayvar</a></li><li><a class="page-link" href="page/793.html">Scalable ways to associate evidence (pro or con) with claims will be more valuable in elevating accuracy than complex voting and reputation systems</a> <q>Discussions on Less Wrong have delved into [complex systems of voting and moderation](http://lesswro…</q> - <a class="page-link" href="page/AndreaGallagher.html">Andrea Gallagher</a></li></ul><h2 id="dwim"><a class="page-link" href="page/dwim.html">Do-What-I-Mean hierarchy</a></h2><ul class="page-list"><li><a class="page-link" href="page/cev.html">Coherent extrapolated volition (alignment target)</a> <q>A proposed direction for an extremely well-aligned autonomous superintelligence - do what humans would want, if we knew what the AI knew, thought that fast, and understood ourselves.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="donor_coordination"><a class="page-link" href="page/donor_coordination.html">Donor coordination</a></h2><ul class="page-list"><li><a class="page-link" href="page/6xw.html">Displaying the list of fundraiser donors sorted by the donation date would help with the &quot;wait and see&quot; problem.</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/739.html">Donor lotteries: demonstration and FAQ</a> - <a class="page-link" href="page/RyanCarey2.html">Ryan Carey</a></li><li><a class="page-link" href="page/6wq.html">I often wait to see how much other people will donate to a fundraiser before donating myself.</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/6y2.html">It's good for GiveWell and Good Ventures to crowd out donors by their donations.</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li></ul><h2 id="DuncanSabien"><a class="page-link" href="page/DuncanSabien.html">Duncan Sabien</a></h2><ul class="page-list"><li><a class="page-link" href="page/6nj.html">Double Crux — A Strategy for Resolving Disagreement</a> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li></ul><h2 id="edge_instantiation"><a class="page-link" href="page/edge_instantiation.html">Edge instantiation</a></h2><ul class="page-list"><li><a class="page-link" href="page/low_impact.html">Low impact</a> <q>The open problem of having an AI carry out tasks in ways that cause minimum side effects and change as little of the rest of the universe as possible.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="ea"><a class="page-link" href="page/ea.html">Effective altruism</a></h2><ul class="page-list"><li><a class="page-link" href="page/dollar_per_day_animal_offset.html">A $1 donation to a top animal charity alleviates more suffering than is caused by a day of eating meat.</a> <q>For the purposes of this claim, top animal welfare charities include:

 - [Animal Charity Evaluators…</q> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li><li><a class="page-link" href="page/ethics_offsets_to_the_rescue.html">Ethics Offsets to the Rescue</a> <q>Hate hurting animals, but love eating meat? Throw money at the problem!</q> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li><li><a class="page-link" href="page/76v.html">For most EA-Blank projects, we would expect more good to be done if they would: i) disband or ii) remove EA from the name and aim to outgrow the EA movement.</a> <q>The claim refers to projects like:

* Effective Altruism Forum
* Effective Altruism Handbook
* Effec…</q> - <a class="page-link" href="page/RyanCarey2.html">Ryan Carey</a></li><li><a class="page-link" href="page/6wm.html">Fundraisers should have a threshold amount which, if not hit, results in a refund.</a> <q>When starting a fundraiser, a nonprofit should declare a threshold amount. If the nonprofit doesn't …</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/grow_ea.html">Growing the EA movement is net positive</a> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li><li><a class="page-link" href="page/76r.html">If EA leaders with similar values disagree about how the EA movement should be branded, then they should discuss in detail the subquestions that would cause them to change their minds if they have not already done so.</a> - <a class="page-link" href="page/RyanCarey2.html">Ryan Carey</a></li><li><a class="page-link" href="page/73b.html">If they spent 100x longer deciding where to donate, then most effective altruists would choose targets with much higher expected impact.</a> <q>Does analysis help?</q> - <a class="page-link" href="page/RyanCarey2.html">Ryan Carey</a></li><li><a class="page-link" href="page/763.html">Kickstarter project is a better tool for fundraising a threshold amount of money to start an EA project than a donor charity</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/76w.html">On the margin, effective altruist researchers and leaders should carry out more empirical investigation of strategic questions.</a> <q>Strategic question might include:

* How can we shape the development of brain-computer interfaces?
…</q> - <a class="page-link" href="page/RyanCarey2.html">Ryan Carey</a></li><li><a class="page-link" href="page/70j.html">The current message of effective altruism heavily discourages creativity.</a> <q>Alyssa Vance expands on this point in her [FB post](https://www.facebook.com/alyssamvance/posts/1021…</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/6wp.html">When I donate to a charity, I am concerned whether or not the charity will raise enough money to make my donation worthwhile.</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li></ul><h2 id="empty_set"><a class="page-link" href="page/empty_set.html">Empty set</a></h2><ul class="page-list"><li><a class="page-link" href="page/empty_set_universal_property.html">Universal property of the empty set</a> <q>The empty set can be characterised by how it interacts with other sets, rather than by any explicit property of the empty set itself.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li></ul><h2 id="example_problem"><a class="page-link" href="page/example_problem.html">Example problem</a></h2><ul class="page-list"><li><a class="page-link" href="page/blue_oysters.html">Blue oysters</a> <q>A probability problem about blue oysters.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/diseasitis.html">Diseasitis</a> <q>20% of patients have Diseasitis. 90% of sick patients and 30% of healthy patients turn a tongue depressor black. You turn a tongue depressor black. What's the chance you have Diseasitis?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/poset_lattice_examples.html">Lattice: Examples</a> <q>Here are some additional examples of lattices. $\newcommand{\nsubg}{\mathcal N \mbox{-} Sub~G}$

A f…</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="page/sockdresser_search.html">Sock-dresser search</a> <q>There's a 4/5 chance your socks are in one of your dresser's 8 drawers. You check 6 drawers at random. What's the probability they'll be in the next drawer you check?</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/sparking_widgets.html">Sparking widgets</a> <q>10% of widgets are bad and 90% are good. 4% of good widgets emit sparks, and 12% of bad widgets emit…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="executable_philosophy"><a class="page-link" href="page/executable_philosophy.html">Executable philosophy</a></h2><ul class="page-list"><li><a class="page-link" href="page/rescue_utility.html">Rescuing the utility function</a> <q>If your utility function values 'heat', and then you discover to your horror that there's no ontologically basic heat, switch to valuing disordered kinetic energy. Likewise 'free will' or 'people'.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="exercise_meta_tag"><a class="page-link" href="page/exercise_meta_tag.html">Exercise </a></h2><ul class="page-list"><li><a class="page-link" href="page/group_exercises.html">Group: Exercises</a> <q>Test your understanding of the definition of a group with these exercises.</q> - <a class="page-link" href="page/QiaochuYuan.html">Qiaochu Yuan</a></li><li><a class="page-link" href="page/poset_join_exercises.html">Join and meet: Exercises</a> <q>Try these exercises to test your knowledge of joins and meets.


Tangled up 
--------------------

!…</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="page/poset_lattice_exercise.html">Lattice: Exercises</a> <q>Try these exercises to test your knowledge of lattices.

## Distributivity

Does the lattice meet op…</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="page/log_exercises.html">Logarithm: Exercises</a> <q>Without using a calculator: What is $\log_{10}(4321)$? What integer is it larger than, what integer …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/poset_exercises.html">Poset: Exercises</a> <q>Try these exercises to test your poset knowledge.

# Corporate Ladder

Imagine a company with five …</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li></ul><h2 id="x_risk"><a class="page-link" href="page/x_risk.html">Existential risk</a></h2><ul class="page-list"><li><a class="page-link" href="page/off_earth_efficiently_mitigates_xrisk.html">A permanent, self-sustaining off-Earth colony would be a much more effective mitigation of x-risk than even an equally well funded system of disaster shelters on Earth.</a> <q>See also the less precise claim: Establishing a permanent off-Earth colony would be a useful way to …</q> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li><li><a class="page-link" href="page/consciousness_research_important.html">Consciousness research is critically important</a> <q>See: Principia Qualia: blueprint for a new cause area, consciousness research with an eye toward et…</q> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li><li><a class="page-link" href="page/off_earth_mitigates_xrisk.html">Establishing a permanent off-Earth colony would be a useful way to mitigate x-risk</a> <q>- Posed by [purplepeople](http://effective-altruism.com/user/purplepeople/) on the [EA Forum](http:/…</q> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li><li><a class="page-link" href="page/6xk.html">Ethics research should proceed in parallel to value alignment research</a> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li><li><a class="page-link" href="page/off_earth_warm_scarf.html">For mitigating AI x-risk, an off-Earth colony would be about as useful as a warm scarf</a> <q>H/T to Eliezer Yudkowsky for [&quot;warm scarf&quot;](https://www.facebook.com/robert.wiblin/posts/75711126783…</q> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li></ul><h2 id="external_resources_meta_tag"><a class="page-link" href="page/external_resources_meta_tag.html">External resources</a></h2><ul class="page-list"><li><a class="page-link" href="page/orbit_stabiliser_theorem_external_resources.html">Orbit-Stabiliser theorem: External Resources</a> <q>External resources on the Orbit-Stabiliser theorem.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/turing_machine_external_resources.html">Turing machine: External resources</a> <q>* [Wikipedia](https://en.wikipedia.org/wiki/Turing_machine)
* [Wolfram MathWorld](http://mathworld.w…</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li></ul><h2 id="extraordinary_claims"><a class="page-link" href="page/extraordinary_claims.html">Extraordinary claims</a></h2><ul class="page-list"><li><a class="page-link" href="page/bayes_extraordinary_claims.html">Extraordinary claims require extraordinary evidence</a> <q>The people who adamantly claim they were abducted by aliens do provide some evidence for aliens. They just don't provide quantitatively enough evidence.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="fallacy"><a class="page-link" href="page/fallacy.html">Fallacies</a></h2><ul class="page-list"><li><a class="page-link" href="page/not_more_paperclips.html">You can't get more paperclips that way</a> <q>Most arguments that &quot;A paperclip maximizer could get more paperclips by (doing nice things)&quot; are flawed.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="formal_definition_meta_tag"><a class="page-link" href="page/formal_definition_meta_tag.html">Formal definition</a></h2><h3 id="formal_definition_meta_tag-wiki">wiki</h3><ul class="page-list"><li><a class="page-link" href="page/algebraic_structure.html">Algebraic structure</a> <q>Roughly speaking, an algebraic structure is a set $X$, known as the underlying set, paired with a co…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/conjugacy_class.html">Conjugacy class</a> <q>In a group, the elements can be partitioned naturally into certain classes.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/category_theory_equaliser.html">Equaliser (category theory)</a> <q>In Category theory, an *equaliser* of a pair of arrows $f, g: A \to B$ is an object $E$ and a univer…</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/field_structure_of_rational_numbers.html">Field structure of rational numbers</a> <q>In which we describe the field structure on the rationals.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/group_coset.html">Group coset</a> <q>Given a subgroup $H$ of Group $G$, the *left cosets* of $H$ in $G$ are sets of the form $\{ gh : h \…</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/group_orbit.html">Group orbit</a> <q>When we have a group acting on a set, we are often interested in how the group acts on a particular …</q> - <a class="page-link" href="page/AdeleLopez.html">Adele Lopez</a></li><li><a class="page-link" href="page/identity_element.html">Identity element</a> <q>An element in a set with a binary operation that leaves every element unchanged when used as the other operand.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/iff.html">Iff</a> <q>If and only if...</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/inverse_function.html">Inverse function</a> <q>The inverse of a function returns an input of the original function when fed the original's corresponding output.</q> - <a class="page-link" href="page/MichaelCohen.html">Michael Cohen</a></li><li><a class="page-link" href="page/order_of_a_group_element.html">Order of a group element</a> <q>Given an element $g$ of group $(G, +)$ (which henceforth we abbreviate simply as $G$), the order of …</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/order_relation.html">Order relation</a> <q>A way of determining which elements of a set come &quot;before&quot; or &quot;after&quot; other elements.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/ordered_field.html">Ordered field</a> <q>An ordered ring with division.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/prime_number.html">Prime number</a> <q>The prime numbers are the &quot;building blocks&quot; of the counting numbers.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/relation_mathematics.html">Relation</a> <q>A **relation** is a set of [tuple\_mathematics tuples], all of which have the same [tuple\_arity ar…</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="page/group_stabiliser.html">Stabiliser (of a group action)</a> <q>If a group acts on a set, it is useful to consider which elements of the group don't move a certain element of the set.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/transitive_relation.html">Transitive relation</a> <q>If a is related to b and b is related to c, then a is related to c.</q> - <a class="page-link" href="page/DylanHendrickson.html">Dylan Hendrickson</a></li><li><a class="page-link" href="page/set_union.html">Union</a> <q>The union of two sets is the set of elements which are in one or the other, or both</q> - <a class="page-link" href="page/MYass.html">M Yass</a></li></ul><h3 id="formal_definition_meta_tag-no-type">no-type</h3><ul class="page-list"><li><a class="page-link" href="page/3ls.html">3ls</a></li></ul><h2 id="function"><a class="page-link" href="page/function.html">Function</a></h2><ul class="page-list"><li><a class="page-link" href="page/category_theory.html">Category theory</a> <q>How mathematical objects are related to others in the same category.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li></ul><h2 id="value_alignment_glossary"><a class="page-link" href="page/value_alignment_glossary.html">Glossary (Value Alignment Theory)</a></h2><ul class="page-list"><li><a class="page-link" href="page/hypercomputer.html">Hypercomputer</a> <q>Some formalisms demand computers larger than the limit of all finite computers</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/relative_ability.html">Infrahuman, par-human, superhuman, efficient, optimal</a> <q>A categorization of AI ability levels relative to human, with some gotchas in the ordering.  E.g., in simple domains where humans can play optimally, optimal play is not superhuman.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/instrumental.html">Instrumental</a> <q>What is &quot;instrumental&quot; in the context of Value Alignment Theory?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/pivotal.html">Pivotal event</a> <q>Which types of AIs, if they work, can do things that drastically change the nature of the further game?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/value_alignment_programmer.html">Programmer</a> <q>Who is building these advanced agents?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/value_alignment_utility.html">Utility</a> <q>What is &quot;utility&quot; in the context of Value Alignment Theory?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/value_alignment_value.html">Value</a> <q>The word 'value' in the phrase 'value alignment' is a metasyntactic variable that indicates the speaker's future goals for intelligent life.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="goodness_estimate_bias"><a class="page-link" href="page/goodness_estimate_bias.html">Goodness estimate biaser</a></h2><ul class="page-list"><li><a class="page-link" href="page/edge_instantiation.html">Edge instantiation</a> <q>When you ask the AI to make people happy, and it tiles the universe with the smallest objects that can be happy.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/goodharts_curse.html">Goodhart's Curse</a> <q>The Optimizer's Curse meets Goodhart's Law.  For example, if our values are V, and an AI's utility function U is a proxy for V, optimizing for high U seeks out 'errors'--that is, high values of U - V.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="group_mathematics"><a class="page-link" href="page/group_mathematics.html">Group</a></h2><ul class="page-list"><li><a class="page-link" href="page/category_theory.html">Category theory</a> <q>How mathematical objects are related to others in the same category.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li></ul><h2 id="group_isomorphism"><a class="page-link" href="page/group_isomorphism.html">Group isomorphism</a></h2><ul class="page-list"><li><a class="page-link" href="page/isomorphism.html">Isomorphism</a> <q>A morphism between two objects which describes how they are &quot;essentially equivalent&quot; for the purposes of the theory under consideration.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li></ul><h2 id="guarded_definition"><a class="page-link" href="page/guarded_definition.html">Guarded definition</a></h2><ul class="page-list"><li><a class="page-link" href="page/pivotal.html">Pivotal event</a> <q>Which types of AIs, if they work, can do things that drastically change the nature of the further game?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="guide_meta_tag"><a class="page-link" href="page/guide_meta_tag.html">Guide</a></h2><ul class="page-list"><li><a class="page-link" href="page/bayes_rule_guide.html">Bayes' rule: Guide</a> <q>The Arbital guide to Bayes' rule</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/ldt_guide.html">Guide to Logical Decision Theory</a> <q>The entry point for learning about logical decision theory.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/log_guide.html">Introductory guide to logarithms</a> <q>Welcome to the Arbital introduction to logarithms! In modern education, logarithms are often mention…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="high_speed_meta_tag"><a class="page-link" href="page/high_speed_meta_tag.html">High-speed explanation</a></h2><ul class="page-list"><li><a class="page-link" href="page/bayes_rule_fast_intro.html">High-speed intro to Bayes's rule</a> <q>A high-speed introduction to Bayes's Rule on one page, for the impatient and mathematically adept.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/odds_refresher.html">Odds: Refresher</a> <q>A quick review of the notations and mathematical behaviors for odds (e.g. odds of 1 : 2 for drawing a red ball vs. green ball from a barrel).</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="bayes_for_humans"><a class="page-link" href="page/bayes_for_humans.html">Humans doing Bayes</a></h2><ul class="page-list"><li><a class="page-link" href="page/bayes_examples_realistic_math1.html">Realistic (Math 1)</a> <q>Real-life examples of Bayesian reasoning</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="humean_free_boundary"><a class="page-link" href="page/humean_free_boundary.html">Humean degree of freedom</a></h2><ul class="page-list"><li><a class="page-link" href="page/value_laden.html">Value-laden</a> <q>Cure cancer, but avoid any bad side effects?  Categorizing &quot;bad side effects&quot; requires knowing what's &quot;bad&quot;.  If an agent needs to load complex human goals to evaluate something, it's &quot;value-laden&quot;.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="image_requested_meta_tag"><a class="page-link" href="page/image_requested_meta_tag.html">Image requested</a></h2><ul class="page-list"><li><a class="page-link" href="page/addition_of_rational_numbers_math_0.html">Addition of rational numbers (Math 0)</a> <q>The simplest operation on rational numbers is addition.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li></ul><h2 id="Isomorphism_intro_math_0"><a class="page-link" href="page/Isomorphism_intro_math_0.html">Isomorphism: Intro (Math 0)</a></h2><ul class="page-list"><li><a class="page-link" href="page/bijective_function_intro_math_0.html">Bijective Function: Intro (Math 0)</a> <q>Two boxes are bijective if they contain the same number of items.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li></ul><h2 id="6th"><a class="page-link" href="page/6th.html">It's better to give $1000 to one person one time than to lend it out through microloans and then, as the money's repaid, keep relending it to other people indefinitely</a></h2><ul class="page-list"><li><a class="page-link" href="page/6tg.html">Mic-Ra-finance and the illusion of control</a> <q>This post discusses the following claims:

* [claim([6th])]
* [claim([6tk])]
* [claim([6tl])]</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li></ul><h2 id="requisite_meta_tag"><a class="page-link" href="page/requisite_meta_tag.html">Just a requisite</a></h2><ul class="page-list"><li><a class="page-link" href="page/reads_algebra.html">Ability to read algebra</a> <q>Do you have sufficient mathematical ability that you can read a sentence that uses some algebra or invokes a mathematical idea, without slowing down too much?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/reads_calculus.html">Ability to read calculus</a> <q>Can you take integral signs and differentiations in stride?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/reads_logic.html">Ability to read logic</a> <q>Can you read sentences symbolically stating &quot;For all x: exists y: phi(x, y) or not theta(y)&quot; without slowing down too much?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/blue_oysters.html">Blue oysters</a> <q>A probability problem about blue oysters.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/math0.html">Math 0</a> <q>Are you not actively bad at math, nor traumatized about math?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/math1.html">Math 1</a> <q>Is math sometimes fun for you, and are you not anxious if you see a math puzzle you don't know how to solve?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/math2.html">Math 2</a> <q>Do you work with math on a fairly routine basis?  Do you have little trouble grasping abstract structures and ideas?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/math3.html">Math 3</a> <q>Can you read the sort of things that professional mathematicians read, aka LaTeX formulas with a minimum of explanation?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_update_details.html">Path: Insights from Bayesian updating</a> <q>A learning-path placeholder page for insights derived from the Bayesian rule for updating beliefs.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_rule_details.html">Path: Multiple angles on Bayes's Rule</a> <q>A learning-path placeholder page for learning multiple angles on Bayes's Rule.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/sockdresser_search.html">Sock-dresser search</a> <q>There's a 4/5 chance your socks are in one of your dresser's 8 drawers. You check 6 drawers at random. What's the probability they'll be in the next drawer you check?</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/sparking_widgets.html">Sparking widgets</a> <q>10% of widgets are bad and 90% are good. 4% of good widgets emit sparks, and 12% of bad widgets emit…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/692.html">Wants to get straight to Bayes</a> <q>A simple requisite page to mark whether the user has selected wanting to get straight into Bayes on …</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="KANSI"><a class="page-link" href="page/KANSI.html">Known-algorithm non-self-improving agent</a></h2><ul class="page-list"><li><a class="page-link" href="page/behaviorist.html">Behaviorist genie</a> <q>An advanced agent that's forbidden to model minds in too much detail.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="list_meta_tag"><a class="page-link" href="page/list_meta_tag.html">List</a></h2><ul class="page-list"><li><a class="page-link" href="page/value_alignment_central_examples.html">Central examples</a> <q>List of central examples in Value Alignment Theory domain.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/orbit_stabiliser_theorem_external_resources.html">Orbit-Stabiliser theorem: External Resources</a> <q>External resources on the Orbit-Stabiliser theorem.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li></ul><h2 id="pointing_finger"><a class="page-link" href="page/pointing_finger.html">Look where I'm pointing, not at my finger</a></h2><ul class="page-list"><li><a class="page-link" href="page/identify_causal_goals.html">Identifying causal goal concepts from sensory data</a> <q>If the intended goal is &quot;cure cancer&quot; and you show the AI healthy patients, it sees, say, a pattern of pixels on a webcam.  How do you get to a goal concept *about* the real patients?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="low_speed_meta_tag"><a class="page-link" href="page/low_speed_meta_tag.html">Low-speed explanation</a></h2><ul class="page-list"><li><a class="page-link" href="page/odds_intro.html">Odds: Introduction</a> <q>What's the difference between probabilities and odds? Why is a 20% probability of success equivalent to 1 : 4 odds favoring success?</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="math0"><a class="page-link" href="page/math0.html">Math 0</a></h2><ul class="page-list"><li><a class="page-link" href="page/addition_of_rational_numbers_math_0.html">Addition of rational numbers (Math 0)</a> <q>The simplest operation on rational numbers is addition.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/arithmetic_of_rational_numbers_math_0.html">Arithmetic of rational numbers (Math 0)</a> <q>How do we combine rational numbers together?</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/bijective_function_intro_math_0.html">Bijective Function: Intro (Math 0)</a> <q>Two boxes are bijective if they contain the same number of items.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/cyclic_group_intro_math_0.html">Cyclic Group Intro (Math 0)</a> <q>A finite cyclic group is a little bit like a clock.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/division_of_rational_numbers_math_0.html">Division of rational numbers (Math 0)</a> <q>&quot;Division&quot; is the idea of &quot;dividing something up among some people so that we can give equal amounts to each person&quot;.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/integers_intro_math0.html">Integers: Intro (Math 0)</a> <q>The integers are the whole numbers extended into the negatives.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/Isomorphism_intro_math_0.html">Isomorphism: Intro (Math 0)</a> <q>Things which are basically the same, except for some stuff you don't care about.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/subtraction_of_rational_numbers_math_0.html">Subtraction of rational numbers (Math 0)</a> <q>In which we meet anti-apples.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/uncountability_intuitive.html">Uncountability: Intuitive Intro</a> <q>Are all sizes of infinity the same?  What does &quot;the same&quot; even mean here?</q> - <a class="page-link" href="page/JasonGross.html">Jason Gross</a></li></ul><h2 id="math1"><a class="page-link" href="page/math1.html">Math 1</a></h2><ul class="page-list"><li><a class="page-link" href="page/data_bit.html">Bit (of data)</a> <q>A bit of data is the amount of data required to single out one message from a set of two. Equivalen…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/combining_vectors.html">Combining vectors</a> <q>One of the most useful things we can do with vectors is to combine them!</q> - <a class="page-link" href="page/AdeleLopez.html">Adele Lopez</a></li><li><a class="page-link" href="page/derivative_calculus.html">Derivative</a> <q>How things change</q> - <a class="page-link" href="page/MichaelCohen.html">Michael Cohen</a></li><li><a class="page-link" href="page/proof_by_contradiction.html">Proof by contradiction</a> <q>Discover what 'reductio ad absurdum' means!</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/6bf.html">Rice's Theorem: Intro (Math 1)</a> <q>You can't write a program that looks at another programs source code, and tells you whether it computes the Fibonacci sequence.</q> - <a class="page-link" href="page/DylanHendrickson.html">Dylan Hendrickson</a></li><li><a class="page-link" href="page/vector_arithmetic.html">Vector arithmetic</a> <q>Vectors: what they are, and how to add and scale them.</q> - <a class="page-link" href="page/AdeleLopez.html">Adele Lopez</a></li></ul><h2 id="math2"><a class="page-link" href="page/math2.html">Math 2</a></h2><ul class="page-list"><li><a class="page-link" href="page/binary_function.html">Binary function</a> <q>A binary function $f$ is a function of two inputs (i.e., a function with arity 2). For example, $+,$…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bezout_theorem.html">Bézout's theorem</a> <q>Bézout's theorem is an important link between highest common factors and the integer solutions of a certain equation.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/mathematics_ceiling.html">Ceiling</a> <q>The ceiling of a real number $x,$ denoted $\lceil x \rceil$ or sometimes $\operatorname{ceil}(x),$ i…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/group_conjugate.html">Group conjugate</a> <q>Conjugation lets us perform permutations &quot;from the point of view of&quot; another permutation.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/group_isomorphism.html">Group isomorphism</a> <q>&quot;Isomorphism&quot; is the proper notion of &quot;sameness&quot; or &quot;equality&quot; among groups.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/identity_element.html">Identity element</a> <q>An element in a set with a binary operation that leaves every element unchanged when used as the other operand.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/math_join.html">Join and meet</a> <q>Let $\langle P, \leq \rangle$ be a poset, and let $S \subseteq P$. The **join** of $S$ in $P$, deno…</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="page/list_mathematics.html">List</a> <q>A list is an ordered collection of objects, such as `[0, 1, 2, 3]` or `[&quot;red&quot;, &quot;blue&quot;, 0, &quot;shoe&quot;]`. …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/exclusive_exhaustive.html">Mutually exclusive and exhaustive</a> <q>The condition needed for probabilities to sum to 1</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/operator_mathematics.html">Operator</a> <q>An operation $f$ on a set $S$ is a function that takes some values from $S$ and produces a new value…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/poset.html">Partially ordered set</a> <q>A set endowed with a relation that is reflexive, transitive, and antisymmetric.</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="page/probability.html">Probability</a> <q>The degree to which someone believes something, measured on a scale from 0 to 1, allowing us to do math to it.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/rice_theorem.html">Rice's Theorem</a> <q>Rice's Theorem tells us that if we want to determine pretty much anything about the behaviour of an arbitrary computer program, we can't in general do better than just running it.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/underlying_set.html">Underlying set</a> <q>What do a Group, a Partially ordered set, and a [ topological space] have in common? Each is a Set …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="math3"><a class="page-link" href="page/math3.html">Math 3</a></h2><ul class="page-list"><li><a class="page-link" href="page/every_group_is_quotient_of_free_group.html">Every group is a quotient of a free group</a> <q>Given a group $G$, there is a Free group $F(X)$ on some set $X$, such that $G$ is isomorphic to some…</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/free_group_formal_definition.html">Formal definition of the free group</a> <q>Van der Waerden's trick lets us define the free groups in a slick but mostly incomprehensible way.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/group_presentation.html">Group presentation</a> <q>Presentations are a fairly compact way of expressing groups.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li></ul><h2 id="labs_meta"><a class="page-link" href="page/labs_meta.html">Meta (Arbital Labs)</a></h2><ul class="page-list"><li><a class="page-link" href="page/73t.html">A clarification period for claims is net positive for Arbital</a> <q>Example pros: Claims are more carefully defined and less ambiguous, less wrong questions visible

Ex…</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/73s.html">Arbital claims are significantly more useful* when they are fairly well-specified and unambiguous**</a> <q>\*  At least 30% more valuable to people sharing models.

 ** Not lojban level, but with some thoug…</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/7f6.html">Arbital needs a mechanism for defining terms</a> <q>Much of the discussion in claims seems to be about defining terms, which is a foundational part of r…</q> - <a class="page-link" href="page/AndreaGallagher.html">Andrea Gallagher</a></li><li><a class="page-link" href="page/72f.html">Explicitly tagging the core claims of a post will make people substantially more likely to respond to these claims.</a> <q>Source of claim: Improve comments by tagging claims by Benjamin Hoffman</q> - <a class="page-link" href="page/StephanieZolayvar.html">Stephanie Zolayvar</a></li><li><a class="page-link" href="page/793.html">Scalable ways to associate evidence (pro or con) with claims will be more valuable in elevating accuracy than complex voting and reputation systems</a> <q>Discussions on Less Wrong have delved into [complex systems of voting and moderation](http://lesswro…</q> - <a class="page-link" href="page/AndreaGallagher.html">Andrea Gallagher</a></li><li><a class="page-link" href="page/7gc.html">Why argument structure is important</a> <q>How might we make collaborative truth-seeking both fun and easy?</q> - <a class="page-link" href="page/AndreaGallagher.html">Andrea Gallagher</a></li></ul><h2 id="arbital_meta_tag"><a class="page-link" href="page/arbital_meta_tag.html">Meta tags</a></h2><ul class="page-list"><li><a class="page-link" href="page/needs_motivation.html">Needs motivation</a> <q>A tag for text that could benefit from some motivating statements. Why is the reader interested in w…</q> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li><li><a class="page-link" href="page/thought_experiment.html">Thought experiment</a> <q>Meta-tag for thought experiments.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="3zj"><a class="page-link" href="page/3zj.html">Meta tags which request an edit to the page</a></h2><ul class="page-list"><li><a class="page-link" href="page/c_class_meta_tag.html">C-Class</a> <q>This page has substantial content, but may not thoroughly cover the topic, may not meet style and prose standards, or may not explain the concept in a way the target audience will reliably understand.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/needs_brief_summary_meta_tag.html">Needs brief summary</a> <q>Meta tag for pages which need a brief summary.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/needs_clickbait_meta_tag.html">Needs clickbait</a> <q>This page does not have clickbait (a short teaser for the page displayed on various lists). Feel free to add it!</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li></ul><h2 id="meta_utility"><a class="page-link" href="page/meta_utility.html">Meta-utility function</a></h2><ul class="page-list"><li><a class="page-link" href="page/meta_unsolved.html">Meta-rules for (narrow) value learning are still unsolved</a> <q>We don't currently know a simple meta-utility function that would take in observation of humans and spit out our true values, or even a good target for a Task AGI.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="foreseeable_difficulties"><a class="page-link" href="page/foreseeable_difficulties.html">Methodology of foreseeable difficulties</a></h2><ul class="page-list"><li><a class="page-link" href="page/goodharts_curse.html">Goodhart's Curse</a> <q>The Optimizer's Curse meets Goodhart's Law.  For example, if our values are V, and an AI's utility function U is a proxy for V, optimizing for high U seeks out 'errors'--that is, high values of U - V.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="microlending"><a class="page-link" href="page/microlending.html">Microlending</a></h2><ul class="page-list"><li><a class="page-link" href="page/6tl.html">Assuming significant overhead in monitoring recipients of a microloan, it's more efficient to let them keep the money.</a> <q>A claim about microfinance.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/6th.html">It's better to give $1000 to one person one time than to lend it out through microloans and then, as the money's repaid, keep relending it to other people indefinitely</a> <q>A claim about microloans.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/6tg.html">Mic-Ra-finance and the illusion of control</a> <q>This post discusses the following claims:

* [claim([6th])]
* [claim([6tk])]
* [claim([6tl])]</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/6tk.html">With some fixed amount of money to start, a microloan charity could make loans indefinitely</a> <q>A claim about microloans.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li></ul><h2 id="mindcrime"><a class="page-link" href="page/mindcrime.html">Mindcrime</a></h2><ul class="page-list"><li><a class="page-link" href="page/behaviorist.html">Behaviorist genie</a> <q>An advanced agent that's forbidden to model minds in too much detail.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="morphism"><a class="page-link" href="page/morphism.html">Morphism</a></h2><ul class="page-list"><li><a class="page-link" href="page/isomorphism.html">Isomorphism</a> <q>A morphism between two objects which describes how they are &quot;essentially equivalent&quot; for the purposes of the theory under consideration.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li></ul><h2 id="nearest_unblocked"><a class="page-link" href="page/nearest_unblocked.html">Nearest unblocked strategy</a></h2><ul class="page-list"><li><a class="page-link" href="page/low_impact.html">Low impact</a> <q>The open problem of having an AI carry out tasks in ways that cause minimum side effects and change as little of the rest of the universe as possible.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/mindcrime.html">Mindcrime</a> <q>Might a machine intelligence contain vast numbers of unhappy conscious subprocesses?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="needs_accessible_summary_meta_tag"><a class="page-link" href="page/needs_accessible_summary_meta_tag.html">Needs accessible summary</a></h2><ul class="page-list"><li><a class="page-link" href="page/function_codomain.html">Codomain (of a function)</a> <q>The codomain $\operatorname{cod}(f)$ of a function $f : X \to Y$ is $Y$, the set of possible outputs…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/lobs_theorem.html">Löb's theorem</a> <q>Löb's theorem</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li></ul><h2 id="needs_brief_summary_meta_tag"><a class="page-link" href="page/needs_brief_summary_meta_tag.html">Needs brief summary</a></h2><ul class="page-list"><li><a class="page-link" href="page/decimal_notation.html">Decimal notation</a> <q>The winning architecture for numerals</q> - <a class="page-link" href="page/MichaelCohen.html">Michael Cohen</a></li><li><a class="page-link" href="page/group_mathematics.html">Group</a> <q>The algebraic structure that captures symmetry, relationships between transformations, and part of what multiplication and addition have in common.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="needs_clickbait_meta_tag"><a class="page-link" href="page/needs_clickbait_meta_tag.html">Needs clickbait</a></h2><ul class="page-list"><li><a class="page-link" href="page/algebraic_structure.html">Algebraic structure</a> <q>Roughly speaking, an algebraic structure is a set $X$, known as the underlying set, paired with a co…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/arbital_alias.html">Arbital page alias</a> <q>The alias is a short, unique name assigned to each page. For example: &quot;arbital_alias&quot;.

The alias u…</q> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li><li><a class="page-link" href="page/1mj.html">Arithmetical hierarchy: If you don't read logic</a> <q>The arithmetical hierarchy is a way of stratifying statements by how many &quot;for every number&quot; and &quot;th…</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/function_arity.html">Arity (of a function)</a> <q>The arity of a function is the number of parameters that it takes. For example, the function $f(a, b…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/associative_operation.html">Associative operation</a> <q>An **associative operation** $\bullet : X \times X \to X$ is a binary operation such that for all $x…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/associativity_vs_commutativity.html">Associativity vs commutativity</a> <q>Associativity and commutativity are often confused, because they are both constraints on how a funct…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/associativity_intuition.html">Associativity: Intuition</a> <q>Associative functions can be interpreted as families of functions that reduce lists down to a singl…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bag_mathematics.html">Bag</a> <q>In mathematics, a &quot;bag&quot; is an unordered list. A bag differs from a set in that it can contain the sa…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/binary_function.html">Binary function</a> <q>A binary function $f$ is a function of two inputs (i.e., a function with arity 2). For example, $+,$…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/cartesian_product.html">Cartesian product</a> <q>The Cartesian product of two sets $A$ and $B,$ denoted $A \times B,$ is the set of all [ordered\_pai…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/cauchy_theorem_on_subgroup_existence_intuitive.html">Cauchy's theorem on subgroup existence: intuitive version</a> <q>Cauchy's Theorem states that if $G$ is a finite [-group], and $p$ is a prime dividing the order of $…</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/mathematics_ceiling.html">Ceiling</a> <q>The ceiling of a real number $x,$ denoted $\lceil x \rceil$ or sometimes $\operatorname{ceil}(x),$ i…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/closure_mathematics.html">Closure</a> <q>A set $S$ is _closed_ under an operation $f$ if, whenever $f$ is fed elements of $S$, it produces an…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/function_codomain.html">Codomain (of a function)</a> <q>The codomain $\operatorname{cod}(f)$ of a function $f : X \to Y$ is $Y$, the set of possible outputs…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/codomain_vs_image.html">Codomain vs image</a> <q>It is useful to distinguish codomain from image both (a) when the type of thing that the function pr…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/commutative_operation.html">Commutative operation</a> <q>A commutative function $f$ is a function that takes multiple inputs from a set $X$ and produces an o…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/commutativity_examples.html">Commutativity: Examples</a> <q>Yes: addition, multiplication, maximum, minimum, rock-paper-scissors. No: subtraction, division, st…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/commutativity_intuition.html">Commutativity: Intuition</a> <q>We can think of commutativity either as an artifact of notation, or as a symmetry in the output of a…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/complex_number.html">Complex number</a> <q>A complex number is a number of the form $z = a + b\textrm{i}$, where $\textrm{i}$ is the imaginary …</q> - <a class="page-link" href="page/ElianaRuby.html">Eliana Ruby</a></li><li><a class="page-link" href="page/function_domain.html">Domain (of a function)</a> <q>The domain $\operatorname{dom}(f)$ of a function $f : X \to Y$ is $X$, the set of valid inputs for t…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/function.html">Function</a> <q>Intuitively, a function $f$  is a procedure (or machine) that takes an input and performs some opera…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/function_physical_metaphor.html">Function: Physical metaphor</a> <q>Many functions can be visualized as physical mechanisms of wheels and gears, that take their inputs …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/generalized_associative_law.html">Generalized associative law</a> <q>Given an associative operator $\cdot$ and a list $[a, b, c, \ldots]$ of parameters, all ways of red…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/group_coset.html">Group coset</a> <q>Given a subgroup $H$ of Group $G$, the *left cosets* of $H$ in $G$ are sets of the form $\{ gh : h \…</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/group_orbit.html">Group orbit</a> <q>When we have a group acting on a set, we are often interested in how the group acts on a particular …</q> - <a class="page-link" href="page/AdeleLopez.html">Adele Lopez</a></li><li><a class="page-link" href="page/function_image.html">Image (of a function)</a> <q>The image $\operatorname{im}(f)$ of a function $f : X \to Y$ is the set of all possible outputs of $…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/information_theory.html">Information theory</a> <q>The study (and quantificaiton) of information, and its communication and storage.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/injective_function.html">Injective function</a> <q>A Function $f: X \to Y$ is *injective* if it has the property that whenever $f(x) = f(y)$, it is the…</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/integer.html">Integer</a> <q>An **integer** is a Number that can be represented as either a Natural number or its [-additive\_inv…</q> - <a class="page-link" href="page/MichaelCohen.html">Michael Cohen</a></li><li><a class="page-link" href="page/kernel_of_group_homomorphism.html">Kernel of group homomorphism</a> <q>The kernel of a Group homomorphism $f: G \to H$ is the collection of all elements $g$ in $G$ such th…</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/bayesian_likelihood.html">Likelihood</a> <q>&quot;Likelihood&quot;, when speaking of Bayesian reasoning, denotes *the probability of an observation, sup…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log_inverts_exp.html">Logarithms invert exponentials</a> <q>The function $\log_b(\cdot)$ inverts the function $b^{(\cdot)}.$ In other words, $\log_b(n) = x$ imp…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/logical_system.html">Logical system</a> <q>Logical systems (a.k.a. formal systems) are mathematical abstractions that aim to capture the notion…</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/algebraic_monoid.html">Monoid</a> <q>A monoid $M$ is a pair $(X, \diamond)$ where $X$ is a [set\_theory\_set set] and $\diamond$ is an [a…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bayes_odds_to_probability.html">Odds form to probability form</a> <q>The odds form of Bayes' rule works for any two hypotheses $H_i$ and $H_j,$ and looks like this:

$$\…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/group_order.html">Order of a group</a> <q>The order $|G|$ of a group $G$ is the size of its underlying set. For example, if $G=(X,\bullet)$ an…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/order_of_a_group_element.html">Order of a group element</a> <q>Given an element $g$ of group $(G, +)$ (which henceforth we abbreviate simply as $G$), the order of …</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/bayes_rule_probability_proof.html">Proof of Bayes' rule: Probability form</a> <q>Let $\mathbf H$ be a [random\_variable variable] in $\mathbb P$ for the true hypothesis, and let $H_…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/algebraic_ring.html">Ring</a> <q>A ring is a kind of Algebraic structure which we obtain by considering groups as being &quot;things with…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/set_mathematics.html">Set</a> <q>An unordered collection of distinct objects.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/shannon.html">Shannon</a> <q>The shannon (Sh) is a unit of Information. One shannon is the difference in [info\_entropy entropy] …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/underlying_set.html">Underlying set</a> <q>What do a Group, a Partially ordered set, and a [ topological space] have in common? Each is a Set …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="needs_examples_meta_tag"><a class="page-link" href="page/needs_examples_meta_tag.html">Needs examples</a></h2><ul class="page-list"><li><a class="page-link" href="page/chestertons_fence.html">Chesterton's fence</a> <q>If someone did something, it's generally good to understand their reasons for doing it before undoing it.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li></ul><h2 id="needs_exercises_meta_tag"><a class="page-link" href="page/needs_exercises_meta_tag.html">Needs exercises</a></h2><ul class="page-list"><li><a class="page-link" href="page/isomorphism.html">Isomorphism</a> <q>A morphism between two objects which describes how they are &quot;essentially equivalent&quot; for the purposes of the theory under consideration.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li></ul><h2 id="needs_image_meta_tag"><a class="page-link" href="page/needs_image_meta_tag.html">Needs image</a></h2><ul class="page-list"><li><a class="page-link" href="page/addition_of_rational_numbers_math_0.html">Addition of rational numbers (Math 0)</a> <q>The simplest operation on rational numbers is addition.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/cartesian_product.html">Cartesian product</a> <q>The Cartesian product of two sets $A$ and $B,$ denoted $A \times B,$ is the set of all [ordered\_pai…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/category_theory.html">Category theory</a> <q>How mathematical objects are related to others in the same category.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/proportion.html">Proportion</a> <q>A representation of a value as a fraction or multiple of another value.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li></ul><h2 id="needs_lenses_meta_tag"><a class="page-link" href="page/needs_lenses_meta_tag.html">Needs lenses</a></h2><ul class="page-list"><li><a class="page-link" href="page/algebraic_structure.html">Algebraic structure</a> <q>Roughly speaking, an algebraic structure is a set $X$, known as the underlying set, paired with a co…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/exponential.html">Exponential</a> <q>Any function that constantly gets larger as a proportion of itself.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/function.html">Function</a> <q>Intuitively, a function $f$  is a procedure (or machine) that takes an input and performs some opera…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bits_in_a_trit.html">How many bits to a trit?</a> <q>$\log_2(3) \approx 1.585.$ This can be interpreted a few different ways:

1. If you multiply the nu…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log_identities.html">Logarithmic identities</a> <q>- [ Inversion of exponentials]: $b^{\log_b(n)} = \log_b(b^n) = n.$
- [ Log of 1 is 0]: $\log_b(1) …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="needs_links_meta_tag"><a class="page-link" href="page/needs_links_meta_tag.html">Needs links</a></h2><ul class="page-list"><li><a class="page-link" href="page/arbital_page.html">Arbital page</a> <q>The Arbital is a series of pages.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arithmetical_hierarchy.html">Arithmetical hierarchy</a> <q>The arithmetical hierarchy is a way of classifying logical statements by the number of clauses saying &quot;for every object&quot; and &quot;there exists an object&quot;.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/1mj.html">Arithmetical hierarchy: If you don't read logic</a> <q>The arithmetical hierarchy is a way of stratifying statements by how many &quot;for every number&quot; and &quot;th…</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="needs_parent_meta_tag"><a class="page-link" href="page/needs_parent_meta_tag.html">Needs parent</a></h2><ul class="page-list"><li><a class="page-link" href="page/binary_notation.html">Binary notation</a> <q>A way to write down numbers using powers of two.</q> - <a class="page-link" href="page/MalcolmMcCrimmon.html">Malcolm McCrimmon</a></li><li><a class="page-link" href="page/boolean.html">Boolean</a> <q>A value in logic that evaluates to either &quot;true&quot; or &quot;false&quot;.</q> - <a class="page-link" href="page/MalcolmMcCrimmon.html">Malcolm McCrimmon</a></li><li><a class="page-link" href="page/diagonal_lemma.html">Diagonal lemma</a> <q>Constructing self-referential sentences</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/freely_reduced_word.html">Freely reduced word</a> <q>&quot;Freely reduced&quot; captures the idea of &quot;no cancellation&quot; in a free group.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/greatest_common_divisor.html">Greatest common divisor</a> <q>The greatest common divisor of two natural numbers is… the largest number which is a divisor of both. The clue is in the name, really.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/godels_first_incompleteness_theorem.html">Gödel's first incompleteness theorem</a> <q>The theorem that destroyed Hilbert's program</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/logistic_function.html">Logistic function</a> <q>A monotonic function from the real numbers to the open unit interval.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/modular_arithmetic.html">Modular arithmetic</a> <q>Addition as traveling around a circle, instead of along a line.</q> - <a class="page-link" href="page/MalcolmMcCrimmon.html">Malcolm McCrimmon</a></li><li><a class="page-link" href="page/ordered_field.html">Ordered field</a> <q>An ordered ring with division.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/provability_predicate.html">Provability predicate</a> <q>A provability predicate of a theory $T$ is a formula $P(x)$ with one free variable $x$ such that:
…</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/566.html">The n-th root of m is either an integer or irrational</a> <q>In other words, no power of a rational number that is not an integer is ever an integer.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li></ul><h2 id="split_by_mastery_meta_tag"><a class="page-link" href="page/split_by_mastery_meta_tag.html">Needs splitting by mastery</a></h2><ul class="page-list"><li><a class="page-link" href="page/cardinality.html">Cardinality</a> <q>The &quot;size&quot; of a set, or the &quot;number of elements&quot; that it has.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/convex_set.html">Convex set</a> <q>A set that contains all line segments between points in the set</q> - <a class="page-link" href="page/JessicaTaylor.html">Jessica Taylor</a></li></ul><h2 id="needs_summary_meta_tag"><a class="page-link" href="page/needs_summary_meta_tag.html">Needs summary</a></h2><h3 id="needs_summary_meta_tag-wiki">wiki</h3><ul class="page-list"><li><a class="page-link" href="page/ackermann_function.html">Ackermann function</a> <q>The slowest-growing fast-growing function.</q> - <a class="page-link" href="page/AlexAppel.html">Alex Appel</a></li><li><a class="page-link" href="page/advanced_nonagent.html">Advanced nonagent</a> <q>Hypothetically, cognitively powerful programs that don't follow the loop of &quot;observe, learn, model the consequences, act, observe results&quot; that a standard &quot;agent&quot; would.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/arbital_hidden_text.html">Arbital hidden text</a> <q>How to hide text in Markdown behind a button.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/CT_thesis.html">Church-Turing thesis</a> <q>A thesis about computational models</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/convex_function.html">Convex function</a> <q>A function that only curves upward</q> - <a class="page-link" href="page/JessicaTaylor.html">Jessica Taylor</a></li><li><a class="page-link" href="page/convex_set.html">Convex set</a> <q>A set that contains all line segments between points in the set</q> - <a class="page-link" href="page/JessicaTaylor.html">Jessica Taylor</a></li><li><a class="page-link" href="page/bayes_extraordinary_claims.html">Extraordinary claims require extraordinary evidence</a> <q>The people who adamantly claim they were abducted by aliens do provide some evidence for aliens. They just don't provide quantitatively enough evidence.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/fractional_bit.html">Fractional bits</a> <q>It takes $\log_2(8) = 3$ bits of data to carry one message from a set of 8 possible messages. Simila…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/22w.html">Introductory Bayesian problems</a> <q>Bayesian problems to try to solve yourself, before beginning to learn about Bayes' rule.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayesian_likelihood.html">Likelihood</a> <q>&quot;Likelihood&quot;, when speaking of Bayesian reasoning, denotes *the probability of an observation, sup…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/lobs_theorem.html">Löb's theorem</a> <q>Löb's theorem</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/normal_system_of_provability.html">Normal system of provability logic</a> <q>Between the modal systems of provability, the normal systems distinguish themselves by exhibiting ni…</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/posterior_probability.html">Posterior probability</a> <q>What we believe, after seeing the evidence and doing a Bayesian update.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/prior_probability.html">Prior probability</a> <q>What we believed before seeing the evidence.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/real_number.html">Real number</a> <q>A **real number** is any number that can be used to represent a physical quantity.

Intuitively, rea…</q> - <a class="page-link" href="page/MichaelCohen.html">Michael Cohen</a></li><li><a class="page-link" href="page/bayes_examples_realistic_math1.html">Realistic (Math 1)</a> <q>Real-life examples of Bayesian reasoning</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/set_product.html">Set product</a> <q>A fundamental way of combining sets is to take their product, making a set that contains all tuples of elements from the originals.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/group_stabiliser.html">Stabiliser (of a group action)</a> <q>If a group acts on a set, it is useful to consider which elements of the group don't move a certain element of the set.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/strong_Church_Turing_thesis.html">Strong Church Turing thesis</a> <q>A strengthening of the Church Turing thesis</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/symmetric_group.html">Symmetric group</a> <q>The symmetric groups form the fundamental link between group theory and the notion of symmetry.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/only_one_log.html">There is only one logarithm</a> <q>All logarithm functions are the same, up to a multiplicative constant.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/totally_ordered_set.html">Totally ordered set</a> <q>A set where all the elements can be compared as greater than or less than.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li></ul><h3 id="needs_summary_meta_tag-no-type">no-type</h3><ul class="page-list"><li><a class="page-link" href="page/3j7.html">3j7</a></li></ul><h2 id="4bn"><a class="page-link" href="page/4bn.html">Needs work</a></h2><ul class="page-list"><li><a class="page-link" href="page/axiom_of_choice.html">Axiom of Choice</a> <q>The most controversial axiom of the 20th century.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/edge_instantiation.html">Edge instantiation</a> <q>When you ask the AI to make people happy, and it tiles the universe with the smallest objects that can be happy.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/universal_property_proposal.html">Project proposal: Intro to the Universal Property</a> <q>Proposal for one of the first Arbital Projects.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li></ul><h2 id="niceness_defense"><a class="page-link" href="page/niceness_defense.html">Niceness is the first line of defense</a></h2><ul class="page-list"><li><a class="page-link" href="page/omni_test.html">Omnipotence test for AI safety</a> <q>Would your AI produce disastrous outcomes if it suddenly gained omnipotence and omniscience? If so, why did you program something that *wants* to hurt you and is held back only by lacking the power?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="NickBostrom"><a class="page-link" href="page/NickBostrom.html">Nick Bostrom</a></h2><ul class="page-list"><li><a class="page-link" href="page/bostrom_superintelligence.html">Nick Bostrom's book Superintelligence</a> <q>The current best book-form introduction to AI alignment theory.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="nonadversarial"><a class="page-link" href="page/nonadversarial.html">Non-adversarial principle</a></h2><ul class="page-list"><li><a class="page-link" href="page/corrigibility.html">Corrigibility</a> <q>&quot;I can't let you do that, Dave.&quot;</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="nonstandard_terminology_meta_tag"><a class="page-link" href="page/nonstandard_terminology_meta_tag.html">Non-standard terminology</a></h2><ul class="page-list"><li><a class="page-link" href="page/colon_to_notation.html">Colon-to notation</a> <q>Find out what the notation &quot;f : X -&gt; Y&quot; means that everyone keeps using.</q> - <a class="page-link" href="page/QiaochuYuan.html">Qiaochu Yuan</a></li><li><a class="page-link" href="page/galcom.html">GalCom</a> <q>In the GalCom thought experiment, you live in the future, and make your money by living in the Dene…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/intradependent_encoding.html">Intradependent encoding</a> <q>An encoding $E(m)$ of a message $m$ is intradependent if the fact that $E(m)$ encodes $m$ can be de…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/likelihood_notation.html">Likelihood notation</a> <q>The likelihood of a piece of evidence $e$ according to a hypothesis $H,$ known as &quot;the likelihood of…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/strictly_confused.html">Strictly confused</a> <q>A hypothesis is strictly confused by the raw data, if the hypothesis did much worse in predicting it than the hypothesis itself expected.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/n_digit.html">n-digit</a> <q>An $n$-digit is a physical object that can be stably placed into any of $n$ distinguishable states. …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/n_message.html">n-message</a> <q>A message singling out one thing from a set of $n$ is sometimes called an $n$-message. For example,…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="ontology_identification"><a class="page-link" href="page/ontology_identification.html">Ontology identification problem</a></h2><ul class="page-list"><li><a class="page-link" href="page/pointing_finger.html">Look where I'm pointing, not at my finger</a> <q>When trying to communicate the concept &quot;glove&quot;, getting the AGI to focus on &quot;gloves&quot; rather than &quot;my user's decision to label something a glove&quot; or &quot;anything that depresses the glove-labeling button&quot;.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="taskagi_open_problems"><a class="page-link" href="page/taskagi_open_problems.html">Open subproblems in aligning a Task-based AGI</a></h2><ul class="page-list"><li><a class="page-link" href="page/avert_instrumental_pressure.html">Averting instrumental pressures</a> <q>Almost-any utility function for an AI, whether the target is diamonds or paperclips or eudaimonia, implies subgoals like rapidly self-improving and refusing to shut down.  Can we make that not happen?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/conservative_concept.html">Conservative concept boundary</a> <q>Given N example burritos, draw a boundary around what is a 'burrito' that is relatively simple and allows as few positive instances as possible.  Helps make sure the next thing generated is a burrito.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/corrigibility.html">Corrigibility</a> <q>&quot;I can't let you do that, Dave.&quot;</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/faithful_simulation.html">Faithful simulation</a> <q>How would you identify, to a Task AGI (aka Genie), the problem of scanning a human brain, and then running a sufficiently accurate simulation of it for the simulation to not be crazy or psychotic?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/inductive_ambiguity.html">Identifying ambiguous inductions</a> <q>What do a &quot;red strawberry&quot;, a &quot;red apple&quot;, and a &quot;red cherry&quot; have in common that a &quot;yellow carrot&quot; doesn't?  Are they &quot;red fruits&quot; or &quot;red objects&quot;?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/identify_causal_goals.html">Identifying causal goal concepts from sensory data</a> <q>If the intended goal is &quot;cure cancer&quot; and you show the AI healthy patients, it sees, say, a pattern of pixels on a webcam.  How do you get to a goal concept *about* the real patients?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/informed_oversight.html">Informed oversight</a> <q>Incentivize a reinforcement learner that's less smart than you to accomplish some task</q> - <a class="page-link" href="page/JessicaTaylor.html">Jessica Taylor</a></li><li><a class="page-link" href="page/pointing_finger.html">Look where I'm pointing, not at my finger</a> <q>When trying to communicate the concept &quot;glove&quot;, getting the AGI to focus on &quot;gloves&quot; rather than &quot;my user's decision to label something a glove&quot; or &quot;anything that depresses the glove-labeling button&quot;.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/low_impact.html">Low impact</a> <q>The open problem of having an AI carry out tasks in ways that cause minimum side effects and change as little of the rest of the universe as possible.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/soft_optimizer.html">Mild optimization</a> <q>An AGI which, if you ask it to paint one car pink, just paints one car pink and doesn't tile the universe with pink-painted cars, because it's not trying *that* hard to max out its car-painting score.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/nonadversarial.html">Non-adversarial principle</a> <q>At no point in constructing an Artificial General Intelligence should we construct a computation that tries to hurt us, and then try to stop it from hurting us.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/safe_training_for_imitators.html">Safe training procedures for human-imitators</a> <q>How does one train a reinforcement learner to act like a human?</q> - <a class="page-link" href="page/JessicaTaylor.html">Jessica Taylor</a></li><li><a class="page-link" href="page/shutdown_problem.html">Shutdown problem</a> <q>How to build an AGI that lets you shut it down, despite the obvious fact that this will interfere with whatever the AGI's goals are.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="opinion_meta_tag"><a class="page-link" href="page/opinion_meta_tag.html">Opinion page</a></h2><ul class="page-list"><li><a class="page-link" href="page/likelihood_vs_pvalue.html">Likelihood functions, p-values, and the replication crisis</a> <q>What's the whole Bayesian-vs.-frequentist debate about?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/likelihood_not_pvalue_faq.html">Report likelihoods not p-values: FAQ</a> <q>This page answers frequently asked questions about the Report likelihoods, not p-values proposal for…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/likelihoods_not_pvalues.html">Report likelihoods, not p-values</a> <q>If scientists reported likelihood functions instead of p-values, this could help science avoid p-ha…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="out_of_date_meta_tag"><a class="page-link" href="page/out_of_date_meta_tag.html">Out of date</a></h2><h3 id="out_of_date_meta_tag-wiki">wiki</h3><ul class="page-list"><li><a class="page-link" href="page/Arbital_requires.html">Arbital &quot;requires&quot; relationship</a> <q>A page can require a requisite if the reader needs to have it before they are able to understand the page.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/Arbital_teaches.html">Arbital &quot;teaches&quot; relationship</a> <q>A page can teach a requisite when the user can acquire it by reading the page.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/Arbital_comment.html">Arbital comment</a> <q>A comment is a way for you to express your thoughts and opinions within the context of a page.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arbital_features.html">Arbital features</a> <q>Overview of all Arbital features.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arbital_mark.html">Arbital mark</a> <q>What is a mark on Arbital? When is it created? Why is it important?</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/Arbital_path.html">Arbital path</a> <q>Arbital path is a linear sequence of pages tailored specifically to teach a given concept to a user.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arbital_requisite.html">Arbital requisites</a> <q>To understand a thing you often need to understand some other things.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li></ul><h3 id="out_of_date_meta_tag-no-type">no-type</h3><ul class="page-list"><li><a class="page-link" href="page/14y.html">14y</a></li><li><a class="page-link" href="page/17h.html">17h</a></li><li><a class="page-link" href="page/3r.html">3r</a></li><li><a class="page-link" href="page/3v.html">3v</a></li></ul><h2 id="paperclip_maximizer"><a class="page-link" href="page/paperclip_maximizer.html">Paperclip maximizer</a></h2><ul class="page-list"><li><a class="page-link" href="page/not_more_paperclips.html">You can't get more paperclips that way</a> <q>Most arguments that &quot;A paperclip maximizer could get more paperclips by (doing nice things)&quot; are flawed.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="patch_resistant"><a class="page-link" href="page/patch_resistant.html">Patch resistance</a></h2><ul class="page-list"><li><a class="page-link" href="page/edge_instantiation.html">Edge instantiation</a> <q>When you ask the AI to make people happy, and it tiles the universe with the smallest objects that can be happy.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/low_impact.html">Low impact</a> <q>The open problem of having an AI carry out tasks in ways that cause minimum side effects and change as little of the rest of the universe as possible.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/nearest_unblocked.html">Nearest unblocked strategy</a> <q>If you patch an agent's preference framework to avoid an undesirable solution, what can you expect to happen?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="PaulChristiano"><a class="page-link" href="page/PaulChristiano.html">Paul Christiano</a></h2><ul class="page-list"><li><a class="page-link" href="page/imitation_agent.html">Imitation-based agent</a> <q>An AI meant to imitate the behavior of a reference human as closely as possible.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="philosophy"><a class="page-link" href="page/philosophy.html">Philosophy</a></h2><ul class="page-list"><li><a class="page-link" href="page/executable_philosophy.html">Executable philosophy</a> <q>Philosophical discourse aimed at producing a trustworthy answer or meta-answer, in limited time, which can used in constructing an Artificial Intelligence.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="placeholder_meta_tag"><a class="page-link" href="page/placeholder_meta_tag.html">Placeholder</a></h2><ul class="page-list"><li><a class="page-link" href="page/Arbital_editor_advanced.html">Arbital editor: Advanced</a> <q>Advanced features of Arbital editor.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/convex.html">Convex</a> <q>**Placeholder**</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/LaTeX.html">LaTeX</a> <q>**Placeholder**</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/mathematical_object.html">Mathematical object</a> <q>**Placeholder**</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/proof_technique.html">Proof technique</a> <q>**Placeholder**</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li></ul><h2 id="politics"><a class="page-link" href="page/politics.html">Politics</a></h2><ul class="page-list"><li><a class="page-link" href="page/7bm.html">Angela Merkel will be re-elected Chancellor of Germany in 2017</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/7bw.html">Donald Trump remains President at the end of 2017</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/7c6.html">Donald Trump’s approval rating at the end of 2017 is lower than fifty percent</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/7c7.html">Donald Trump’s approval rating at the end of 2017 is lower than forty percent</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/79p.html">In 2017, Assad will remain President of Syria</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/7bz.html">In 2017, Trump administration will not initiate extra prosecution of Hillary Clinton</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/7bd.html">Keith Ellison will be chosen as new DNC chair in 2017</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/7bl.html">Marine Le Pen will not be elected President of France in 2017</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/7bx.html">No serious impeachment proceedings are active against Trump in 2017</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/ssc_predicts_2017.html">Predictions For 2017</a> <q>Scott Alexander made 105 predictions for 2017. Most of them are not personal and are listed below. …</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/7bk.html">The UK will trigger Article 50 in 2017</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/7bn.html">Theresa May will remain PM of Britain in 2017</a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/78p.html">What is the probability that impeachment proceedings will be commenced against President Donald Trump during his first term?</a> <q>More on impeachment in United States: https://en.wikipedia.org/wiki/Impeachment_in_the_United_States</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li></ul><h2 id="proof_meta_tag"><a class="page-link" href="page/proof_meta_tag.html">Proof</a></h2><ul class="page-list"><li><a class="page-link" href="page/bezout_theorem.html">Bézout's theorem</a> <q>Bézout's theorem is an important link between highest common factors and the integer solutions of a certain equation.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/cauchy_theorem_on_subgroup_existence.html">Cauchy's theorem on subgroup existence</a> <q>Cauchy's theorem is a useful condition for the existence of cyclic subgroups of finite groups.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/dihedral_groups_are_non_abelian.html">Dihedral groups are non-abelian</a> <q>The group of symmetries of the triangle and all larger regular polyhedra are not abelian.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/field_homomorphism_is_trivial_or_injective.html">Field homomorphism is trivial or injective</a> <q>Field homomorphisms preserve a *lot* of structure; they preserve so much structure that they are always either injective or totally boring.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/group_orbits_partition.html">Group orbits partition</a> <q>When a group acts on a set, the set falls naturally into distinct pieces, where the group action only permutes elements within any given piece, not between them.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/pi_is_irrational.html">Pi is irrational</a> <q>The number pi is famously not rational, in spite of joking attempts at legislation to fix its value at 3 or 22/7.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/product_is_unique_up_to_isomorphism.html">Product is unique up to isomorphism</a> <q>If something satisfies the universal property of the product, then it is uniquely specified by that property, up to isomorphism.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/infinitely_many_primes.html">Proof that there are infinitely many primes</a> <q>Suppose there were finitely many primes. Then consider the product of all the primes plus 1...</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/real_numbers_uncountable.html">Real numbers are uncountable</a> <q>The real numbers are uncountable.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/stabiliser_is_a_subgroup.html">Stabiliser is a subgroup</a> <q>Given a group acting on a set, each element of the set induces a subgroup of the group.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/566.html">The n-th root of m is either an integer or irrational</a> <q>In other words, no power of a rational number that is not an integer is ever an integer.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/rationals_are_a_field.html">The rationals form a field</a> <q>The set $\mathbb{Q}$ of rational numbers is a field.

# Proof

$\mathbb{Q}$ is a (commutative) ring …</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/reals_as_dedekind_cuts_form_a_field.html">The reals (constructed as Dedekind cuts) form a field</a> <q>The reals are an archetypal example of a field, but if we are to construct them from simpler objects, we need to show that our construction does indeed have the right properties.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/reals_as_classes_of_cauchy_sequences_form_a_field.html">The reals (constructed as classes of Cauchy sequences of rationals) form a field</a> <q>The reals are an archetypal example of a field, but if we are to construct them from simpler objects, we need to show that our construction does indeed have the right properties.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/rationals_are_countable.html">The set of rational numbers is countable</a> <q>Although there are &quot;lots and lots&quot; of rational numbers, there are still only countably many of them.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/sqrt_2_is_irrational.html">The square root of 2 is irrational</a> <q>The number whose square is 2 can't be written is a quotient of natural numbers</q> - <a class="page-link" href="page/DylanHendrickson.html">Dylan Hendrickson</a></li></ul><h2 id="proposed_a_class"><a class="page-link" href="page/proposed_a_class.html">Proposed A-Class</a></h2><ul class="page-list"><li><a class="page-link" href="page/bayes_log_odds.html">Bayes' rule: Log-odds form</a> <q>A simple transformation of Bayes' rule reveals tools for measuring degree of belief, and strength of evidence.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/uncountability_intuitive.html">Uncountability: Intuitive Intro</a> <q>Are all sizes of infinity the same?  What does &quot;the same&quot; even mean here?</q> - <a class="page-link" href="page/JasonGross.html">Jason Gross</a></li><li><a class="page-link" href="page/bayes_waterfall_diseasitis.html">Waterfall diagrams and relative odds</a> <q>A way to visualize Bayes' rule that yields an easier way to solve some problems</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="proposed_b_class"><a class="page-link" href="page/proposed_b_class.html">Proposed B-Class</a></h2><ul class="page-list"><li><a class="page-link" href="page/data_bit.html">Bit (of data)</a> <q>A bit of data is the amount of data required to single out one message from a set of two. Equivalen…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/group_isomorphism.html">Group isomorphism</a> <q>&quot;Isomorphism&quot; is the proper notion of &quot;sameness&quot; or &quot;equality&quot; among groups.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/rationals_form_a_field_math_0.html">Rational arithmetic all works together</a> <q>The various operations of arithmetic all play nicely together in a certain specific way.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/uncountable.html">Uncountability</a> <q>Some infinities are bigger than others. Uncountable infinities are larger than countable infinities.</q> - <a class="page-link" href="page/JasonGross.html">Jason Gross</a></li></ul><h2 id="psychologizing"><a class="page-link" href="page/psychologizing.html">Psychologizing</a></h2><ul class="page-list"><li><a class="page-link" href="page/missing_weird.html">Missing the weird alternative</a> <q>People might systematically overlook &quot;make tiny molecular smileyfaces&quot; as a way of &quot;producing smiles&quot;, because our brains automatically search for high-utility-to-us ways of &quot;producing smiles&quot;.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/underestimate_value_complexity_perceputal_property.html">Underestimating complexity of value because goodness feels like a simple property</a> <q>When you just want to yell at the AI, &quot;Just do normal high-value X, dammit, not weird low-value X!&quot; and that 'high versus low value' boundary is way more complicated than your brain wants to think.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="rationality"><a class="page-link" href="page/rationality.html">Rationality</a></h2><h3 id="rationality-wiki">wiki</h3><ul class="page-list"><li><a class="page-link" href="page/bayes_reasoning.html">Bayesian reasoning</a> <q>A probability-theory-based view of the world; a coherent way of changing probabilistic beliefs based on evidence.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h3 id="rationality-no-type">no-type</h3><ul class="page-list"><li><a class="page-link" href="page/43m.html">43m</a></li></ul><h2 id="set_mathematics"><a class="page-link" href="page/set_mathematics.html">Set</a></h2><ul class="page-list"><li><a class="page-link" href="page/extensionality_axiom.html">Extensionality Axiom</a> <q>If two sets have exactly the same members, then they are equal</q> - <a class="page-link" href="page/IliaZaichuk.html">Ilia Zaichuk</a></li></ul><h2 id="shutdown_problem"><a class="page-link" href="page/shutdown_problem.html">Shutdown problem</a></h2><ul class="page-list"><li><a class="page-link" href="page/updated_deference.html">Problem of fully updated deference</a> <q>Why moral uncertainty doesn't stop an AI from defending its off-switch.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="shutdown_utility_function"><a class="page-link" href="page/shutdown_utility_function.html">Shutdown utility function</a></h2><ul class="page-list"><li><a class="page-link" href="page/shutdown_problem.html">Shutdown problem</a> <q>How to build an AGI that lets you shut it down, despite the obvious fact that this will interfere with whatever the AGI's goals are.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="start_meta_tag"><a class="page-link" href="page/start_meta_tag.html">Start</a></h2><h3 id="start_meta_tag-wiki">wiki</h3><ul class="page-list"><li><a class="page-link" href="page/5r7.html">0.999...=1</a> <q>No, it's not &quot;infinitesimally far&quot; from 1 or anything like that. 0.999... and 1 are literally the same number.</q> - <a class="page-link" href="page/DylanHendrickson.html">Dylan Hendrickson</a></li><li><a class="page-link" href="page/googolplex.html">A googolplex</a> <q>A moderately large number, as large numbers go.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/ackermann_function.html">Ackermann function</a> <q>The slowest-growing fast-growing function.</q> - <a class="page-link" href="page/AlexAppel.html">Alex Appel</a></li><li><a class="page-link" href="page/algebraic_structure_tree.html">Algebraic structure tree</a> <q>When is a monoid a semilattice? What's the difference between a semigroup and a groupoid? Find out here!</q> - <a class="page-link" href="page/RyanHendrickson.html">Ryan Hendrickson</a></li><li><a class="page-link" href="page/5kv.html">An Introduction to Logical Decision Theory for Everyone Else</a> <q>So like what the heck is 'logical decision theory' in terms a normal person can understand?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/arbital_labs.html">Arbital Labs</a> <q>Landing page for the Arbital Labs domain.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arbital_resources.html">Arbital external resources</a> <q>Arbital wants to link users to great content, wherever it is!</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arbital_hidden_text.html">Arbital hidden text</a> <q>How to hide text in Markdown behind a button.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arbital_like.html">Arbital likes</a> <q>What are likes? When should I use them? What happens when I like something?</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arbital_markdown_demo.html">Arbital markdown demo</a> <q>Demo of Arbital's markdown</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arbital_math.html">Arbital math levels</a> <q>How mathy do you like your pages?</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arbital_page.html">Arbital page</a> <q>The Arbital is a series of pages.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arbital_practices.html">Arbital practices</a> <q>Guidelines and rules for interacting on Arbital.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/arbital_quality.html">Arbital quality</a> <q>Arbital's system for tracking page quality.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arbital_do_what_works.html">Arbital: Do what works</a> <q>When deciding things on Arbital, think about the real goals, and move towards them.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/b_class_meta_tag.html">B-Class</a> <q>This page is mostly complete and without major problems, but has not had detailed feedback from the target audience and reviewers.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/bayes_rule_examples.html">Bayes' rule examples</a> <q>Interesting problems solvable by Bayes' rule</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_update.html">Bayesian update</a> <q>Bayesian updating: the ideal way to change probabilistic beliefs based on evidence.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/binary_notation.html">Binary notation</a> <q>A way to write down numbers using powers of two.</q> - <a class="page-link" href="page/MalcolmMcCrimmon.html">Malcolm McCrimmon</a></li><li><a class="page-link" href="page/abstract_bit.html">Bit (abstract)</a> <q>An abstract bit is an element of the set $\mathbb B$, which has two elements. An abstract bit is to …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/cartesian_product.html">Cartesian product</a> <q>The Cartesian product of two sets $A$ and $B,$ denoted $A \times B,$ is the set of all [ordered\_pai…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/magician_message.html">Communication: magician example</a> <q>Imagine that you and I are both magicians, performing a trick where I think of a card from a deck of…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/complex_number.html">Complex number</a> <q>A complex number is a number of the form $z = a + b\textrm{i}$, where $\textrm{i}$ is the imaginary …</q> - <a class="page-link" href="page/ElianaRuby.html">Eliana Ruby</a></li><li><a class="page-link" href="page/complexity_zoo.html">Complexity theory: Complexity zoo</a> <q>Pass and see the exotic beasts coming from the lands of afar!</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/preference_stability.html">Consequentialist preferences are reflectively stable by default</a> <q>Gandhi wouldn't take a pill that made him want to kill people, because he knows in that case more people will be murdered.  A paperclip maximizer doesn't want to stop maximizing paperclips.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/convex_function.html">Convex function</a> <q>A function that only curves upward</q> - <a class="page-link" href="page/JessicaTaylor.html">Jessica Taylor</a></li><li><a class="page-link" href="page/convex_set.html">Convex set</a> <q>A set that contains all line segments between points in the set</q> - <a class="page-link" href="page/JessicaTaylor.html">Jessica Taylor</a></li><li><a class="page-link" href="page/decision_problem.html">Decision problem</a> <q>Formalization of general problems</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/encoding_dependent_messages.html">Dependent messages can be encoded cheaply</a> <q>Say you want to transmit a 2-message, a 4-message, and a 256-message to somebody. For example, you m…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/domain_distance.html">Distances between cognitive domains</a> <q>Often in AI alignment we want to ask, &quot;How close is 'being able to do X' to 'being able to do Y'?&quot;</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/empty_set.html">Empty set</a> <q>The empty set does what it says on the tin: it is the set which is empty.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/trits_with_galcom_bits.html">Encoding trits with GalCom bits</a> <q>There are $\log_2(3) \approx 1.585$ bits to a Trit. Why is it that particular value? Consider the Ga…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/equivalence_relation.html">Equivalence relation</a> <q>A relation that allows you to partition a set into equivalence classes.</q> - <a class="page-link" href="page/DylanHendrickson.html">Dylan Hendrickson</a></li><li><a class="page-link" href="page/examination_through_isomorphism.html">Examination through isomorphism</a> <q>Isomorphism is the correct notion of equality between objects in a category. From the category-theor…</q> - <a class="page-link" href="page/LukeSciarappa.html">Luke Sciarappa</a></li><li><a class="page-link" href="page/exponential.html">Exponential</a> <q>Any function that constantly gets larger as a proportion of itself.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/extensionality_axiom.html">Extensionality Axiom</a> <q>If two sets have exactly the same members, then they are equal</q> - <a class="page-link" href="page/IliaZaichuk.html">Ilia Zaichuk</a></li><li><a class="page-link" href="page/fair_problem_class.html">Fair problem class</a> <q>A problem is 'fair' (according to logical decision theory) when only the results matter and not how we get there.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/function.html">Function</a> <q>Intuitively, a function $f$  is a procedure (or machine) that takes an input and performs some opera…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/fundamental_theorem_of_arithmetic.html">Fundamental Theorem of Arithmetic</a> <q>The FTA tells us that natural numbers can be decomposed uniquely into prime factors; it is the basis of almost all number theory.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/information.html">Information</a> <q>Information is a measure of how much a message grants an observer the ability to predict the world.…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/intradependent_encoding.html">Intradependent encoding</a> <q>An encoding $E(m)$ of a message $m$ is intradependent if the fact that $E(m)$ encodes $m$ can be de…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/3x3.html">Intradependent encodings can be compressed</a> <q>Given an encoding scheme $E$ which gives an Intradependent encoding of a message $m,$ we can in prin…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/ldt_intro_phil.html">Introduction to Logical Decision Theory for Analytic Philosophers</a> <q>Why &quot;choose as if controlling the logical output of your decision algorithm&quot; is the most appealing candidate for the principle of rational choice.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/ldt_intro_compsci.html">Introduction to Logical Decision Theory for Computer Scientists</a> <q>'Logical decision theory' from a math/programming standpoint, including how two agents with mutual knowledge of each other's code can cooperate on the Prisoner's Dilemma.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/ldt_intro_econ.html">Introduction to Logical Decision Theory for Economists</a> <q>An introduction to 'logical decision theory' and its implications for the Ultimatum Game, voting in elections, bargaining problems, and more.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/22w.html">Introductory Bayesian problems</a> <q>Bayesian problems to try to solve yourself, before beginning to learn about Bayes' rule.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/lesswrong.html">Less Wrong</a> <q>A community blog devoted to refining the art of human rationality.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/bayesian_likelihood.html">Likelihood</a> <q>&quot;Likelihood&quot;, when speaking of Bayesian reasoning, denotes *the probability of an observation, sup…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/likelihood_notation.html">Likelihood notation</a> <q>The likelihood of a piece of evidence $e$ according to a hypothesis $H,$ known as &quot;the likelihood of…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/likelihood_ratio.html">Likelihood ratio</a> <q>Given a piece of evidence $e$ and two hypothsese $H_i$ and $H_j,$ the likelihood ratio between them…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log_base_infinity.html">Log base infinity</a> <q>There is no log base infinity, but if there were, it would send everything to zero</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log_base_1.html">Logarithm base 1</a> <q>There is no log base 1.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log_identities.html">Logarithmic identities</a> <q>- [ Inversion of exponentials]: $b^{\log_b(n)} = \log_b(b^n) = n.$
- [ Log of 1 is 0]: $\log_b(1) …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/logistic_function.html">Logistic function</a> <q>A monotonic function from the real numbers to the open unit interval.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/meta_unsolved.html">Meta-rules for (narrow) value learning are still unsolved</a> <q>We don't currently know a simple meta-utility function that would take in observation of humans and spit out our true values, or even a good target for a Task AGI.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/mind_projection.html">Mind projection fallacy</a> <q>Uncertainty is in the mind, not in the environment; a blank map does not correspond to a blank territory.  In general, the territory may have a different ontology from the map.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/minimality_principle.html">Minimality principle</a> <q>The first AGI ever built should save the world in a way that requires the least amount of the least dangerous cognition.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/modal_logic.html">Modal logic</a> <q>The logic of boxes and bots.</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/modular_arithmetic.html">Modular arithmetic</a> <q>Addition as traveling around a circle, instead of along a line.</q> - <a class="page-link" href="page/MalcolmMcCrimmon.html">Malcolm McCrimmon</a></li><li><a class="page-link" href="page/moral_uncertainty.html">Moral uncertainty</a> <q>A meta-utility function in which the utility function as usually considered, takes on different values in different possible worlds, potentially distinguishable by evidence.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/most_complexity_incompressible.html">Most complex things are not very compressible</a> <q>We can't *prove* it's impossible, but it would be *extremely surprising* to discover a 500-state Turing machine that output the exact text of &quot;Romeo and Juliet&quot;.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/natural_number.html">Natural number</a> <q>The numbers we use to count: 0, 1, 2, 3, ...</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/natural_number_numbersets.html">Natural numbers: Intro to Number Sets</a> <q>Natural numbers are the numbers we use to count in everyday life.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/object_identity_via_interactions.html">Object identity via interactions</a> <q>If we think of objects as opaque &quot;black boxes&quot;, how can we tell whether two objects are different? By looking at how they interact with other objects!</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/odds_refresher.html">Odds: Refresher</a> <q>A quick review of the notations and mathematical behaviors for odds (e.g. odds of 1 : 2 for drawing a red ball vs. green ball from a barrel).</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/order_of_operations.html">Order of operations</a> <q>Conventions used for disambiguating infix notation.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/ordered_ring.html">Ordered ring</a> <q>A ring with a total ordering compatible with its ring structure.</q> - <a class="page-link" href="page/DylanHendrickson.html">Dylan Hendrickson</a></li><li><a class="page-link" href="page/rational_number.html">Rational number</a> <q>The rational numbers are &quot;fractions&quot;.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/real_number.html">Real number</a> <q>A **real number** is any number that can be used to represent a physical quantity.

Intuitively, rea…</q> - <a class="page-link" href="page/MichaelCohen.html">Michael Cohen</a></li><li><a class="page-link" href="page/relative_likelihood.html">Relative likelihood</a> <q>How relatively likely an observation is, given two or more hypotheses, determines the strength and direction of evidence.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/6bf.html">Rice's Theorem: Intro (Math 1)</a> <q>You can't write a program that looks at another programs source code, and tells you whether it computes the Fibonacci sequence.</q> - <a class="page-link" href="page/DylanHendrickson.html">Dylan Hendrickson</a></li><li><a class="page-link" href="page/algebraic_ring.html">Ring</a> <q>A ring is a kind of Algebraic structure which we obtain by considering groups as being &quot;things with…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/solomonoff_induction.html">Solomonoff induction</a> <q>A simple way to superintelligently predict sequences of data, given unlimited computing power.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/strong_Church_Turing_thesis.html">Strong Church Turing thesis</a> <q>A strengthening of the Church Turing thesis</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/nonadversarial_safety.html">The AI must tolerate your safety measures</a> <q>A corollary of the nonadversarial principle is that &quot;The AI must tolerate your safety measures.&quot;</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/the_plan.html">The plan </a> <q>Root page for the plan on how to approach and navigate through AGI development.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/totally_ordered_set.html">Totally ordered set</a> <q>A set where all the elements can be compared as greater than or less than.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/toxoplasmosis_dilemma.html">Toxoplasmosis dilemma</a> <q>A parasitic infection, carried by cats, may make humans enjoy petting cats more.  A kitten, now in front of you, isn't infected.  But if you *want* to pet it, you may already be infected.  Do you?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/underestimate_value_complexity_perceputal_property.html">Underestimating complexity of value because goodness feels like a simple property</a> <q>When you just want to yell at the AI, &quot;Just do normal high-value X, dammit, not weird low-value X!&quot; and that 'high versus low value' boundary is way more complicated than your brain wants to think.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/underlying_set.html">Underlying set</a> <q>What do a Group, a Partially ordered set, and a [ topological space] have in common? Each is a Set …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/set_union.html">Union</a> <q>The union of two sets is the set of elements which are in one or the other, or both</q> - <a class="page-link" href="page/MYass.html">M Yass</a></li><li><a class="page-link" href="page/universal_prior.html">Universal prior</a> <q>A &quot;universal prior&quot; is a probability distribution containing *all* the hypotheses, for some reasonable meaning of &quot;all&quot;.  E.g., &quot;every possible computer program that computes probabilities&quot;.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/universal_property.html">Universal property</a> <q>A universal property is a way of defining an object based purely on how it interacts with other objects, rather than by any internal property of the object itself.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/up_to_isomorphism.html">Up to isomorphism</a> <q>A phrase mathematicians use when saying &quot;we only care about the structure of an object, not about specific implementation details of the object&quot;.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/why_is_log_like_length.html">Why is log like length?</a> <q>If a number $x$ is $n$ digits long (in Decimal notation), then its logarithm (base 10) is between $n…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log2_of_3_never_ends.html">Why is the decimal expansion of log2(3) infinite?</a> <q>Because 2 and 3 are relatively prime.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h3 id="start_meta_tag-no-type">no-type</h3><ul class="page-list"><li><a class="page-link" href="page/43m.html">43m</a></li></ul><h2 id="stub_meta_tag"><a class="page-link" href="page/stub_meta_tag.html">Stub</a></h2><h3 id="stub_meta_tag-wiki">wiki</h3><ul class="page-list"><li><a class="page-link" href="page/beneficial.html">'Beneficial'</a> <q>Really actually good.  A metasyntactic variable to mean &quot;favoring whatever the speaker wants ideally to accomplish&quot;, although different speakers have different morals and metaethics.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/detrimental.html">'Detrimental'</a> <q>The opposite of beneficial.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/googol.html">A googol</a> <q>A pretty small large number.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/ai_arms_race.html">AI arms races</a> <q>AI arms races are bad</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/aixitl.html">AIXI-tl</a> <q>A time-bounded version of the ideal agent AIXI that uses an impossibly large finite computer instead of a hypercomputer.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/reads_algebra.html">Ability to read algebra</a> <q>Do you have sufficient mathematical ability that you can read a sentence that uses some algebra or invokes a mathematical idea, without slowing down too much?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/reads_calculus.html">Ability to read calculus</a> <q>Can you take integral signs and differentiations in stride?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/reads_logic.html">Ability to read logic</a> <q>Can you read sentences symbolically stating &quot;For all x: exists y: phi(x, y) or not theta(y)&quot; without slowing down too much?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/abortable.html">Abortable plans</a> <q>Plans that can be undone, or switched to having low further impact.  If the AI builds abortable nanomachines, they'll have a quiet self-destruct option that includes any replicated nanomachines.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/actual_effectiveness.html">Actual effectiveness</a> <q>If you want the AI's so-called 'utility function' to actually be steering the AI, you need to think about how it meshes up with beliefs, or what gets output to actions.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/hack.html">Ad-hoc hack (alignment theory)</a> <q>A &quot;hack&quot; is when you alter the behavior of your AI in a way that defies, or doesn't correspond to, a principled approach for that problem.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/43j.html">Another another playpen child</a> <q>May it be a light for you in dark places, when all other lights go out.</q> - <a class="page-link" href="page/StephanieZolayvar.html">Stephanie Zolayvar</a></li><li><a class="page-link" href="page/arbital_blog.html">Arbital Blog</a> <q>Stay up to date on all things Arbital</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arbital_slack.html">Arbital Slack</a> <q>Where the cool kids hang out.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arbital_arbiter.html">Arbital arbiter</a> <q>Arbiters provide oversight and dispute resolution to an Arbital domain.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arbital_biographies.html">Arbital biographies</a> <q>As a very strong default (presently an absolute rule), Joe Smith's page only says nice things about Joe.  Even if a negative fact is true, it doesn't go on Joe's page.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/arbital_content_request.html">Arbital content request</a> <q>Arbital doesn't explain something you'd like to learn? We'd like to know, so we can prioritize.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arbital_draft.html">Arbital draft</a> <q>Drafts are private work-in-progress pages.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/Arbital_editor.html">Arbital editor</a> <q>How to use Arbital's page editor.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/Arbital_editor_advanced.html">Arbital editor: Advanced</a> <q>Advanced features of Arbital editor.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arbital_greenlink.html">Arbital greenlink</a> <q>What happens when you hover over an Arbital link?</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arbital_reviewer.html">Arbital reviewer</a> <q>Reviewers help writers improve their pages, check over all changes to Arbital's content, and assess page quality.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arbital_todo.html">Arbital todo</a> <q>So many things todo!</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arbital_trusted.html">Arbital trusted user</a> <q>Trusted users can edit most pages directly, and don't need approval to add pages to a domain.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arbital_unlisted_page.html">Arbital unlisted page</a> <q>What do you call a page that's not part of any domain?</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/agi.html">Artificial General Intelligence</a> <q>An AI which has the same kind of &quot;significantly more general&quot; intelligence that humans have compared to chimpanzees; it can learn new domains, like we can.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/attainable_optimum.html">Attainable optimum</a> <q>The 'attainable optimum' of an agent's preferences is the best that agent can actually do given its finite intelligence and resources (as opposed to the global maximum of those preferences).</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/avert_instrumental_pressure.html">Averting instrumental pressures</a> <q>Almost-any utility function for an AI, whether the target is diamonds or paperclips or eudaimonia, implies subgoals like rapidly self-improving and refusing to shut down.  Can we make that not happen?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/avert_self_improvement.html">Averting the convergent instrumental strategy of self-improvement</a> <q>We probably want the first AGI to *not* improve as fast as possible, but improving as fast as possible is a convergent strategy for accomplishing most things.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bag_mathematics.html">Bag</a> <q>In mathematics, a &quot;bag&quot; is an unordered list. A bag differs from a set in that it can contain the sa…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bayes_reasoning.html">Bayesian reasoning</a> <q>A probability-theory-based view of the world; a coherent way of changing probabilistic beliefs based on evidence.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/oh_notation.html">Big-O Notation</a> <q>This notation describes asymptotic behavior of functions.

# O(x)
A function f is O(g(x)) if, for la…</q> - <a class="page-link" href="page/AeneasMackenzie.html">Aeneas Mackenzie</a></li><li><a class="page-link" href="page/bijective_function.html">Bijective function</a> <q>A bijective function is a function with an inverse.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/binary_function.html">Binary function</a> <q>A binary function $f$ is a function of two inputs (i.e., a function with arity 2). For example, $+,$…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bit_examples.html">Bit (of data): Examples</a> <q>In the game &quot;20 questions&quot;, one player (the &quot;leader&quot;) thinks of a concept, and the other players ask…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/boolean.html">Boolean</a> <q>A value in logic that evaluates to either &quot;true&quot; or &quot;false&quot;.</q> - <a class="page-link" href="page/MalcolmMcCrimmon.html">Malcolm McCrimmon</a></li><li><a class="page-link" href="page/bounded_agent.html">Bounded agent</a> <q>An agent that operates in the real world, using realistic amounts of computing power, that is uncertain of its environment, etcetera.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/cartesian_boundary.html">Cartesian agent-environment boundary</a> <q>If your agent is separated from the environment by an absolute border that can only be crossed by sensory information and motor outputs, it might just be a Cartesian agent.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/category_of_finite_sets.html">Category of finite sets</a> <q>The category of finite sets is exactly what it claims to be. It's a useful training ground for some of the ideas of category theory.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/cauchy_sequence.html">Cauchy sequence</a> <q>Infinite sequences whose terms get arbitrarily close together.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/chestertons_fence.html">Chesterton's fence</a> <q>If someone did something, it's generally good to understand their reasons for doing it before undoing it.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/CT_thesis.html">Church-Turing thesis</a> <q>A thesis about computational models</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/cognitive_domain.html">Cognitive domain</a> <q>An allegedly compact unit of knowledge, such that ideas inside the unit interact mainly with each other and less with ideas in other domains.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/cognitive_steganography.html">Cognitive steganography</a> <q>Disaligned AIs that are modeling human psychology and trying to deceive their programmers will want to hide their internal thought processes from their programmers.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/programming_familiarity.html">Computer Programming Familiarity</a> <q>Want to see programming analogies and applications in your math explanations? Mark this as known.</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="page/conjugacy_class.html">Conjugacy class</a> <q>In a group, the elements can be partitioned naturally into certain classes.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/decision_theory.html">Decision theory</a> <q>The mathematical study of ideal decisionmaking</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/decit.html">Decit</a> <q>Decimal digit</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/diagonal_lemma.html">Diagonal lemma</a> <q>Constructing self-referential sentences</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/dihedral_group.html">Dihedral group</a> <q>The dihedral groups are natural examples of groups, arising from the symmetries of regular polygons.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/vector_space_direct_sum.html">Direct sum of vector spaces</a> <q>The direct sum of two vector spaces $U$ and $W,$ written $U \oplus W,$ is just the sum of $U$ and $W…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/disambiguation_meta_tag.html">Disambiguation</a> <q>Several distinct concepts use this page's name, this page helps readers find what they're looking for.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/disjoint_cycle_notation_is_unique.html">Disjoint cycle notation is unique</a> <q>Disjoint cycle notation provides a canonical way to express elements of the symmetric group.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/distinguish_advancement.html">Distinguish which advanced-agent properties lead to the foreseeable difficulty</a> <q>Say what kind of AI, or threshold level of intelligence, or key type of advancement, first produces the difficulty or challenge you're talking about.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/donor_lottery.html">Donor lottery</a> <q>An arrangement where a group of people pool their money and pick one person to give it away.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/emphemeral_premises.html">Emphemeral premises</a> <q>When somebody says X, don't just say, &quot;Oh, not-X because Y&quot; and then forget about Y a day later.  Y is now an important load-bearing assumption in your worldview.  Write Y down somewhere.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/category_theory_equaliser.html">Equaliser (category theory)</a> <q>In Category theory, an *equaliser* of a pair of arrows $f, g: A \to B$ is an object $E$ and a univer…</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/evidential_dt.html">Evidential decision theories</a> <q>Theories which hold that the principle of rational choice is &quot;Choose the act that would be the best news, if somebody told you that you'd chosen that act.&quot;</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/expected_utility.html">Expected utility</a> <q>Scoring actions based on the average score of their probable consequences.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/expected_utility_formalism.html">Expected utility formalism</a> <q>Expected utility is the central idea in the quantitative implementation of consequentialism</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/external_resources_meta_tag.html">External resources</a> <q>This lens links out to other great resources across the web.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/fallacy.html">Fallacies</a> <q>To call something a fallacy is to assert that you think people shouldn't think like that.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/finite_set.html">Finite set</a> <q>A finite set is one which is not infinite. Some of these are the least complicated sets.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/load_bearing_premises.html">Flag the load-bearing premises</a> <q>If somebody says, &quot;This AI safety plan is going to fail, because X&quot; and you reply, &quot;Oh, that's fine because of Y and Z&quot;, then you'd better clearly flag Y and Z as &quot;load-bearing&quot; parts of your plan.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/focusing.html">Focusing</a> <q>Focusing is a psychotherapeutic process developed by psychotherapist Eugene Gendlin</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/formal_definition_meta_tag.html">Formal definition</a> <q>This page gives a purely formal definition of a topic, rather than motivating, explaining, and giving examples.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/3v3.html">Fractional bits: Digit usage interpretation</a> <q>It is 316, not 500, that requires about two and a half digits to write down. 500 requires nearly 2.7…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/FAI.html">Friendly AI</a> <q>Old terminology for an AI whose preferences have been successfully aligned with idealized human values.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/identify_goal_concept.html">Goal-concept identification</a> <q>Figuring out how to say &quot;strawberry&quot; to an AI that you want to bring you strawberries (and not fake plastic strawberries, either).</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/grahams_number.html">Graham's number</a> <q>A fairly large number, as numbers go.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/greatest_common_divisor.html">Greatest common divisor</a> <q>The greatest common divisor of two natural numbers is… the largest number which is a divisor of both. The clue is in the name, really.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/poset_greatest_lower_bound.html">Greatest lower bound in a poset</a> <q>The greatest lower bound is an abstraction of the idea of the greatest common divisor to a general poset.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/group_presentation.html">Group presentation</a> <q>Presentations are a fairly compact way of expressing groups.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/godels_first_incompleteness_theorem.html">Gödel's first incompleteness theorem</a> <q>The theorem that destroyed Hilbert's program</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/happiness_maximizer.html">Happiness maximizer</a> <q>It is sometimes proposed that we build an AI intended to maximize human happiness.  (One early propo…</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/hub_page_meta_tag.html">Hub page</a> <q>This tag is applied to pages which server the role of a &quot;hub&quot;: the user starts there, goes off to learn more about the topic, and then comes back. This meta tag modifies the page's UI.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/1qc.html">Human perception of sound</a> <q>What is the mechanism by which vibrations around the human ear are translated into the sensation of sound?</q> - <a class="page-link" href="page/SilasBarta.html">Silas Barta</a></li><li><a class="page-link" href="page/bayes_for_humans.html">Humans doing Bayes</a> <q>The human use of Bayesian reasoning in everyday life</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/humean_free_boundary.html">Humean degree of freedom</a> <q>A concept includes 'Humean degrees of freedom' when the intuitive borders of the human version of that concept depend on our values, making that concept less natural for AIs to learn.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/iff.html">Iff</a> <q>If and only if...</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/ignorance_prior.html">Ignorance prior</a> <q>Key equations for quantitative Bayesian problems, describing exactly the right shape for what we believed before observation.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/image_requested_meta_tag.html">Image requested</a> <q>An editor has requested an image for this page.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/inductive_prior.html">Inductive prior</a> <q>Some states of pre-observation belief can learn quickly; others never learn anything.  An &quot;inductive prior&quot; is of the former type.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/information_theory.html">Information theory</a> <q>The study (and quantificaiton) of information, and its communication and storage.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/instrumental.html">Instrumental</a> <q>What is &quot;instrumental&quot; in the context of Value Alignment Theory?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/intelligence_explosion.html">Intelligence explosion</a> <q>What happens if a self-improving AI gets to the point where each amount x of self-improvement triggers &gt;x further self-improvement, and it stays that way for a while.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/intension_extension.html">Intension vs. extension</a> <q>&quot;Red is a light with a wavelength of 700 nm&quot; vs. &quot;Look at this red apple, red car, and red cup.&quot;</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/number_sets_intro.html">Intro to Number Sets</a> <q>An introduction to number sets for people who have no idea what a number set is.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/intution_pump.html">Intution pump</a> <q>In philosophy, a metaphor or visualization used to shove the listener's intuition in a particular direction.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/irrational_number.html">Irrational number</a> <q>Real numbers that are not rational numbers</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/joint_probability.html">Joint probability</a> <q>The notation for writing the chance that both X and Y are true.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/requisite_meta_tag.html">Just a requisite</a> <q>A tag for nodes that just act as part of Arbital's requisite system</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/linear_algebra.html">Linear algebra</a> <q>The study of [linear\_transformation linear transformations] and vector spaces.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log_examples.html">Logarithm: Examples</a> <q>$\log_{10}(100)=2.$ $\log_2(4)=2.$ $\log_2(3)\approx 1.58.$ (TODO)</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log_exercises.html">Logarithm: Exercises</a> <q>Without using a calculator: What is $\log_{10}(4321)$? What integer is it larger than, what integer …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/log_inverts_exp.html">Logarithms invert exponentials</a> <q>The function $\log_b(\cdot)$ inverts the function $b^{(\cdot)}.$ In other words, $\log_b(n) = x$ imp…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/logical_dt.html">Logical decision theories</a> <q>Root page for topics on logical decision theory, with multiple intros for different audiences.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/lobs_theorem.html">Löb's theorem</a> <q>Löb's theorem</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/math0.html">Math 0</a> <q>Are you not actively bad at math, nor traumatized about math?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/math1.html">Math 1</a> <q>Is math sometimes fun for you, and are you not anxious if you see a math puzzle you don't know how to solve?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/math2.html">Math 2</a> <q>Do you work with math on a fairly routine basis?  Do you have little trouble grasping abstract structures and ideas?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/math3.html">Math 3</a> <q>Can you read the sort of things that professional mathematicians read, aka LaTeX formulas with a minimum of explanation?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/math.html">Mathematics</a> <q>Mathematics is the study of numbers and other ideal objects that can be described by axioms.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/meta_utility.html">Meta-utility function</a> <q>Preference frameworks built out of simple utility functions, but where, e.g., the 'correct' utility function for a possible world depends on whether a button is pressed.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/metaethics.html">Metaethics</a> <q>Metaethics asks &quot;What kind of stuff is goodness made of?&quot; (or &quot;How would we compute goodness?&quot;) rather than &quot;Which particular policies or outcomes are good or not-good?&quot;</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/microlending.html">Microlending</a> <q>The practice of giving microloans, which are small loans that are issued by individuals.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/mind_design_space_wide.html">Mind design space is wide</a> <q>Imagine all human beings as one tiny dot inside a much vaster sphere of possibilities for &quot;The space of minds in general.&quot;  It is wiser to make claims about *some* minds than *all* minds.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/moral_hazard.html">Moral hazards in AGI development</a> <q>&quot;Moral hazard&quot; is when owners of an advanced AGI give in to the temptation to do things with it that the rest of us would regard as 'bad', like, say, declaring themselves God-Emperor.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/multiplication_of_rational_numbers_math_0.html">Multiplication of rational numbers (Math 0)</a> <q>&quot;Multiplication&quot; is the idea of &quot;now do the same as you just did, but instead of doing it to one apple, do it to some other number&quot;.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/needs_accessible_summary_meta_tag.html">Needs accessible summary</a> <q>This page needs a summary for a less technical audience.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/needs_examples_meta_tag.html">Needs examples</a> <q>This page would benefit from more examples of the concept it teaches.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/needs_parent_meta_tag.html">Needs parent</a> <q>This page is not attached to an appropriate parent page. If you know where it should go, please help categorize it!</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/needs_requisites_meta_tag.html">Needs requisites</a> <q>This page has important requisites which are not listed. If you know what they are, you could help add them!</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/neural_genie_metaphor.html">Neutral genie metaphor</a> <q>Definition. A neutral-genie metaphor is an attempt to illustrate a possible formal problem via an in…</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/newcomblike.html">Newcomblike decision problems</a> <q>Decision problems in which your choice correlates with something other than its physical consequences (say, because somebody has predicted you very well) can do weird things to some decision theories.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bostrom_superintelligence.html">Nick Bostrom's book Superintelligence</a> <q>The current best book-form introduction to AI alignment theory.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/normal_subgroup.html">Normal subgroup</a> <q>Normal subgroups are subgroups which are in some sense &quot;the same from all points of view&quot;.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/number.html">Number</a> <q>An abstract object that expresses quantity or value of some sort.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/opinion_meta_tag.html">Opinion page</a> <q>Opinion pages represent one position on a topic (often from a single author), and are not necessarily balanced or a reflection of consensus.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/orbit_stabiliser_theorem_external_resources.html">Orbit-Stabiliser theorem: External Resources</a> <q>External resources on the Orbit-Stabiliser theorem.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/order_of_rational_operations_math_0.html">Order of rational operations (Math 0)</a> <q>Our shorthand for all the operations on rationals is very useful, but full of brackets; this is how to get rid of some of the brackets.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/ordered_field.html">Ordered field</a> <q>An ordered ring with division.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/otherizer.html">Other-izing (wanted: new optimization idiom)</a> <q>Maximization isn't possible for bounded agents, and satisficing doesn't seem like enough.  What other kind of 'izing' might be good for realistic, bounded agents?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/polynomial_time_complexity_class.html">P (Polynomial Time Complexity Class)</a> <q>P is the class of problems which can be solved by algorithms whose run time is bounded by a polynomial.</q> - <a class="page-link" href="page/EricLeese.html">Eric Leese</a></li><li><a class="page-link" href="page/P_vs_NP.html">P vs NP</a> <q>Is creativity purely mechanical?</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/arguments_against_P_NP.html">P vs NP: Arguments against P=NP</a> <q>Why we believe P and NP are different</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/bayes_update_details.html">Path: Insights from Bayesian updating</a> <q>A learning-path placeholder page for insights derived from the Bayesian rule for updating beliefs.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/perfect_rolling_sphere.html">Perfect rolling sphere</a> <q>If you don't understand something, start by assuming it's a perfect rolling sphere.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/philosophy.html">Philosophy</a> <q>A stub parent node to contain standard concepts, belonging to subfields of academic philosophy, that are being used elsewhere on Arbital.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/pigovian_tax.html">Pigovian tax</a> <q>Taxation of negative externalities so that their producers have an incentive to cheaply reduce them</q> - <a class="page-link" href="page/SilasBarta.html">Silas Barta</a></li><li><a class="page-link" href="page/placeholder_meta_tag.html">Placeholder</a> <q>This is an empty page created for structural reasons (parent, requisite, or teaches).</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/possible_math_pages.html">Possible math pages</a> <q>A list of things which we may want math pages on</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/prime_element_ring_theory.html">Prime element of a ring</a> <q>Despite the name, &quot;prime&quot; in ring theory refers not to elements which are &quot;multiplicatively irreducible&quot; but to those such that if they divide a product then they divide some term of the product.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/prime_number.html">Prime number</a> <q>The prime numbers are the &quot;building blocks&quot; of the counting numbers.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/bayesian_prior.html">Prior</a> <q>A state of prior knowledge, before seeing information on a new problem.  Potentially complicated.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/probability_distribution_countable.html">Probability distribution (countable sample space)</a> <q>A function assigning a probability to each point in the sample space.</q> - <a class="page-link" href="page/TsviBT.html">Tsvi BT</a></li><li><a class="page-link" href="page/bayes_probability_notation.html">Probability notation for Bayes' rule</a> <q>The probability notation used in Bayesian reasoning</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/probability_theory.html">Probability theory</a> <q>The logic of science; coherence relations on quantitative degrees of belief.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/product_category_theory.html">Product (Category Theory)</a> <q>How a product is characterized rather than how it's constructed</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/5dg.html">Quality meta tags</a> <q>Meta tags which determine the page's quality.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/user_querying.html">Querying the AGI user</a> <q>Postulating that an advanced agent will check something with its user, probably comes with some standard issues and gotchas (e.g., prioritizing what to query, not manipulating the user, etc etc).</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/rationality.html">Rationality</a> <q>The subject domain for [ epistemic] and [ instrumental] rationality.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/real_analysis.html">Real analysis</a> <q>The study of real numbers and real-valued functions.</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="page/real_number_as_dedekind_cut.html">Real number (as Dedekind cut)</a> <q>A way to construct the real numbers that follows the intuition of filling in the gaps.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/reflective_consistency.html">Reflective consistency</a> <q>A decision system is reflectively consistent if it can approve of itself, or approve the construction of similar decision systems (as well as perhaps approving other decision systems too).</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/reflective_stability.html">Reflective stability</a> <q>Wanting to think the way you currently think, building other agents and self-modifications that think the same way.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/representability_theorem_for_computable_functions.html">Representability theorem for computable functions</a> <q>A [ logical theory] $T$ is said to satisfy the **representability theorem for computable functions**…</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/safe_plan_identification.html">Safe plan identification and verification</a> <q>On a particular task or problem, the issue of how to communicate to the AGI what you want it to do and all the things you don't want it to do.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/sample_space_probability.html">Sample space</a> <q>The set of possible things that could happen in a part of the world that you are uncertain about.</q> - <a class="page-link" href="page/TsviBT.html">Tsvi BT</a></li><li><a class="page-link" href="page/set_product.html">Set product</a> <q>A fundamental way of combining sets is to take their product, making a set that contains all tuples of elements from the originals.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/shannon.html">Shannon</a> <q>The shannon (Sh) is a unit of Information. One shannon is the difference in [info\_entropy entropy] …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/show_broken.html">Show me what you've broken</a> <q>To demonstrate competence at computer security, or AI alignment, think in terms of breaking proposals and finding technically demonstrable flaws in them.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/shutdown_problem.html">Shutdown problem</a> <q>How to build an AGI that lets you shut it down, despite the obvious fact that this will interfere with whatever the AGI's goals are.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/shutdown_utility_function.html">Shutdown utility function</a> <q>A special case of a low-impact utility function where you just want the AGI to switch itself off harmlessly (and not create subagents to make absolutely sure it stays off, etcetera).</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/simple_group.html">Simple group</a> <q>The simple groups form the &quot;building blocks&quot; of group theory, analogously to the prime numbers in number theory.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/group_stabiliser.html">Stabiliser (of a group action)</a> <q>If a group acts on a set, it is useful to consider which elements of the group don't move a certain element of the set.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/AGI_typology.html">Strategic AGI typology</a> <q>What broad types of advanced AIs, corresponding to which strategic scenarios, might it be possible or wise to create?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bayes_strength_of_evidence.html">Strength of Bayesian evidence</a> <q>From a Bayesian standpoint, the strength of evidence can be identified with its likelihood ratio.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/subgroup.html">Subgroup</a> <q>A group that lives inside a bigger group.</q> - <a class="page-link" href="page/DylanHendrickson.html">Dylan Hendrickson</a></li><li><a class="page-link" href="page/vector_subspace.html">Subspace</a> <q>A subspace $U=(F_U, V_U)$ of a Vector space $W=(F_W, V_W)$ is a vector space where $F_U = F_W$ and $…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/vector_space_sum.html">Sum of vector spaces</a> <q>The sum of two vector spaces $U$ and $W,$ written $U + W,$ is a vector space where the set of vector…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/task_identification.html">Task identification problem</a> <q>If you have a task-based AGI (Genie) then how do you pinpoint exactly what you want it to do (and not do)?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/alternating_group_is_simple.html">The alternating groups on more than four letters are simple</a> <q>The alternating groups are the most accessible examples of simple groups, and this fact also tells us that the symmetric groups are &quot;complicated&quot; in some sense.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/ideal_math_page.html">The ideal Arbital math page</a> <q>Think of the best math textbook you've ever read -- why was it good?</q> - <a class="page-link" href="page/EricRogstad.html">Eric Rogstad</a></li><li><a class="page-link" href="page/advanced_agent_theory.html">Theory of (advanced) agents</a> <q>One of the research subproblems of building powerful nice AIs, is the theory of (sufficiently advanced) minds in general.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/tiling_agents.html">Tiling agents theory</a> <q>The theory of self-modifying agents that build successors that are very similar to themselves, like repeating tiles on a tesselated plane.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/total_alignment.html">Total alignment</a> <q>We say that an advanced AI is &quot;totally aligned&quot; when it knows *exactly* which outcomes and plans are beneficial, with no further user input.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/transitive_relation.html">Transitive relation</a> <q>If a is related to b and b is related to c, then a is related to c.</q> - <a class="page-link" href="page/DylanHendrickson.html">Dylan Hendrickson</a></li><li><a class="page-link" href="page/trit.html">Trit</a> <q>Trinary digit</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/two_independent_events.html">Two independent events</a> <q>What do [a pair of dice], [a pair of coins], and [a pair of people on opposite sides of the planet] all have in common?</q> - <a class="page-link" href="page/TsviBT.html">Tsvi BT</a></li><li><a class="page-link" href="page/type_theory.html">Type theory</a> <q>Modern foundations for formal mathematics.</q> - <a class="page-link" href="page/JackGallagher.html">Jack Gallagher</a></li><li><a class="page-link" href="page/unassessed_meta_tag.html">Unassessed</a> <q>This page's quality has not been assessed.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/understandability_principle.html">Understandability principle</a> <q>The more you understand what the heck is going on inside your AI, the safer you are.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/updateless_dt.html">Updateless decision theories</a> <q>Decision theories that maximize their policies (mappings from sense inputs to actions), rather than using their sense inputs to update their beliefs and then selecting actions.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/useless_variable_decomposition.html">Useless variable decomposition</a> <q>A variable decomposition can be true but useless if it is a poor guide to intervention due to automa…</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/user_manipulation.html">User manipulation</a> <q>If not otherwise averted, many of an AGI's desired outcomes are likely to interact with users and hence imply an incentive to manipulate users.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/30b.html">User maximization</a> <q>A sub-principle of avoiding user manipulation - if you see an argmax over X or 'optimize X' instruction and X includes a user interaction, you've just told the AI to optimize the user.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/value_alignment_problem.html">Value alignment problem</a> <q>You want to build an advanced AI with the right values... but how?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/vector_space.html">Vector space</a> <q>A vector space is a field $F$ paired with a Group $V$ and a function $\cdot : F \times V \to V$ (cal…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/Vingean_reflection.html">Vingean reflection</a> <q>The problem of thinking about your future self when it's smarter than you.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/Vingean_uncertainty.html">Vingean uncertainty</a> <q>You can't predict the exact actions of an agent smarter than you - so is there anything you _can_ say about them?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/calibrated_probabilities.html">Well-calibrated probabilities</a> <q>Even if you're fairly ignorant, you can still strive to ensure that when you say &quot;70% probability&quot;, it's true 70% of the time.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/work_in_progress_meta_tag.html">Work in progress</a> <q>This page is being actively worked on by an editor. Check with them before making major changes.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/string_concatenation.html">concat (function)</a> <q>The string concatenation function `concat` puts two strings together, i.e., `concat(&quot;one&quot;,&quot;two&quot;)=&quot;on…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h3 id="stub_meta_tag-no-type">no-type</h3><ul class="page-list"><li><a class="page-link" href="page/3j7.html">3j7</a></li><li><a class="page-link" href="page/4v0.html">4v0</a></li></ul><h2 id="arbital_style_guide"><a class="page-link" href="page/arbital_style_guide.html">Style guidelines</a></h2><ul class="page-list"><li><a class="page-link" href="page/1c3.html">Page's title should always be capitalized</a> <q>Vote &quot;agree&quot; if you think Arbital should enforce the first letter of a page title to always be capit…</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li></ul><h2 id="subjective_probability"><a class="page-link" href="page/subjective_probability.html">Subjective probability</a></h2><ul class="page-list"><li><a class="page-link" href="page/likelihood_vs_pvalue.html">Likelihood functions, p-values, and the replication crisis</a> <q>What's the whole Bayesian-vs.-frequentist debate about?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="task_identification"><a class="page-link" href="page/task_identification.html">Task identification problem</a></h2><ul class="page-list"><li><a class="page-link" href="page/identify_causal_goals.html">Identifying causal goal concepts from sensory data</a> <q>If the intended goal is &quot;cure cancer&quot; and you show the AI healthy patients, it sees, say, a pattern of pixels on a webcam.  How do you get to a goal concept *about* the real patients?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="task_agi"><a class="page-link" href="page/task_agi.html">Task-directed AGI</a></h2><ul class="page-list"><li><a class="page-link" href="page/neural_genie_metaphor.html">Neutral genie metaphor</a> <q>Definition. A neutral-genie metaphor is an attempt to illustrate a possible formal problem via an in…</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li></ul><h2 id="composition_of_group_homomorphisms_is_homomorphism"><a class="page-link" href="page/composition_of_group_homomorphisms_is_homomorphism.html">The composition of two group homomorphisms is a homomorphism</a></h2><ul class="page-list"><li><a class="page-link" href="page/category_theory.html">Category theory</a> <q>How mathematical objects are related to others in the same category.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li></ul><h2 id="thought_experiment"><a class="page-link" href="page/thought_experiment.html">Thought experiment</a></h2><ul class="page-list"><li><a class="page-link" href="page/galcom.html">GalCom</a> <q>In the GalCom thought experiment, you live in the future, and make your money by living in the Dene…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li></ul><h2 id="type_theory"><a class="page-link" href="page/type_theory.html">Type theory</a></h2><ul class="page-list"><li><a class="page-link" href="page/prog_dep_typ.html">Programming in  Dependent Type Theory</a> <q>Working with simple types in Lean</q> - <a class="page-link" href="page/JackGallagher.html">Jack Gallagher</a></li></ul><h2 id="unassessed_meta_tag"><a class="page-link" href="page/unassessed_meta_tag.html">Unassessed</a></h2><ul class="page-list"><li><a class="page-link" href="page/MalcolmMcCrimmon.html">Malcolm McCrimmon</a> <q>A person, presumably.</q></li></ul><h2 id="unforeseen_maximum"><a class="page-link" href="page/unforeseen_maximum.html">Unforeseen maximum</a></h2><ul class="page-list"><li><a class="page-link" href="page/low_impact.html">Low impact</a> <q>The open problem of having an AI carry out tasks in ways that cause minimum side effects and change as little of the rest of the universe as possible.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="utility_indifference"><a class="page-link" href="page/utility_indifference.html">Utility indifference</a></h2><ul class="page-list"><li><a class="page-link" href="page/shutdown_problem.html">Shutdown problem</a> <q>How to build an AGI that lets you shut it down, despite the obvious fact that this will interfere with whatever the AGI's goals are.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="value_identification"><a class="page-link" href="page/value_identification.html">Value identification problem</a></h2><ul class="page-list"><li><a class="page-link" href="page/updated_deference.html">Problem of fully updated deference</a> <q>Why moral uncertainty doesn't stop an AI from defending its off-switch.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="Vingean_uncertainty"><a class="page-link" href="page/Vingean_uncertainty.html">Vingean uncertainty</a></h2><ul class="page-list"><li><a class="page-link" href="page/Vinge_principle.html">Vinge's Principle</a> <q>An agent building another agent must usually approve its design without knowing the agent's exact policy choices.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/Vingean_reflection.html">Vingean reflection</a> <q>The problem of thinking about your future self when it's smarter than you.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h2 id="6tk"><a class="page-link" href="page/6tk.html">With some fixed amount of money to start, a microloan charity could make loans indefinitely</a></h2><ul class="page-list"><li><a class="page-link" href="page/6tg.html">Mic-Ra-finance and the illusion of control</a> <q>This post discusses the following claims:

* [claim([6th])]
* [claim([6tk])]
* [claim([6tl])]</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li></ul><h2 id="work_in_progress_meta_tag"><a class="page-link" href="page/work_in_progress_meta_tag.html">Work in progress</a></h2><h3 id="work_in_progress_meta_tag-wiki">wiki</h3><ul class="page-list"><li><a class="page-link" href="page/advanced_agent.html">Advanced agent properties</a> <q>How smart does a machine intelligence need to be, for its niceness to become an issue?  &quot;Advanced&quot; is a broad term to cover cognitive abilities such that we'd need to start considering AI alignment.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/Kolmogorov_complexity.html">Algorithmic complexity</a> <q>When you compress the information, what you are left with determines the complexity.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/real_is_rich.html">Almost all real-world domains are rich</a> <q>Anything you're trying to accomplish in the real world can potentially be accomplished in a *lot* of different ways.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/5kv.html">An Introduction to Logical Decision Theory for Everyone Else</a> <q>So like what the heck is 'logical decision theory' in terms a normal person can understand?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/3tk.html">Arbital subscriptions: Maintenance</a> <q>Subscribing to a page with intention of maintaining it.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/arbital_do_what_works.html">Arbital: Do what works</a> <q>When deciding things on Arbital, think about the real goals, and move towards them.</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/arguments.html">Arguments</a> <q>An argument is a formal reasoning, valid or not.</q> - <a class="page-link" href="page/JeremyPerret.html">Jeremy Perret</a></li><li><a class="page-link" href="page/78l.html">Asymptotic Notation</a> <q>Asymptotic notation seeks to capture the behavior of functions as its input(s) become extreme.  It is most widely used in Computer Science and Numerical Approximation.</q> - <a class="page-link" href="page/MorganRedding.html">Morgan Redding</a></li><li><a class="page-link" href="page/Arbital_author_feedback.html">Author's guide to processing feedback</a> <q>Requisite used for teaching authors about Arbital feedback features.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/5f3.html">Bayes' rule: Beginner's guide</a> <q>Beginner's guide to learning about Bayes' rule.</q> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="page/behaviorist.html">Behaviorist genie</a> <q>An advanced agent that's forbidden to model minds in too much detail.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/bijective_function_intro_math_0.html">Bijective Function: Intro (Math 0)</a> <q>Two boxes are bijective if they contain the same number of items.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/data_bit.html">Bit (of data)</a> <q>A bit of data is the amount of data required to single out one message from a set of two. Equivalen…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/bit_examples.html">Bit (of data): Examples</a> <q>In the game &quot;20 questions&quot;, one player (the &quot;leader&quot;) thinks of a concept, and the other players ask…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/AI_boxing.html">Boxed AI</a> <q>Idea: what if we limit how AI can interact with the world. That'll make it safe, right??</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/category_mathematics.html">Category (mathematics)</a> <q>A description of how a collection of mathematical objects are related to one another.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/category_theory.html">Category theory</a> <q>How mathematical objects are related to others in the same category.</q> - <a class="page-link" href="page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="page/causal_dt.html">Causal decision theories</a> <q>On CDT, to choose rationally, you should imagine the world where your physical act changes, then imagine running that world forward in time.  (Therefore, it's irrational to vote in elections.)</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/value_alignment_central_examples.html">Central examples</a> <q>List of central examples in Value Alignment Theory domain.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/245.html">Civilization scale energy</a> <q>What are the main options for powering civilization, and how do they compare?</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/cev.html">Coherent extrapolated volition (alignment target)</a> <q>A proposed direction for an extremely well-aligned autonomous superintelligence - do what humans would want, if we knew what the AI knew, thought that fast, and understood ourselves.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/magician_message.html">Communication: magician example</a> <q>Imagine that you and I are both magicians, performing a trick where I think of a card from a deck of…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/math_order_complete_lattice.html">Complete lattice</a> <q>A poset that is closed under arbitrary joins and meets.</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="page/complex_number.html">Complex number</a> <q>A complex number is a number of the form $z = a + b\textrm{i}$, where $\textrm{i}$ is the imaginary …</q> - <a class="page-link" href="page/ElianaRuby.html">Eliana Ruby</a></li><li><a class="page-link" href="page/complexity_of_value.html">Complexity of value</a> <q>There's no simple way to describe the goals we want Artificial Intelligences to want.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/multiple_compression.html">Compressing multiple messages</a> <q>How many bits of data does it take to encode an $n$-message? Naively, the answer is $\lceil \log_2(n…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/2wk.html">Conjunctions and disjunctions</a> <q>The fancy name for the &quot;and&quot; and &quot;or&quot; connectives.</q> - <a class="page-link" href="page/JeremyPerret.html">Jeremy Perret</a></li><li><a class="page-link" href="page/context_disaster.html">Context disaster</a> <q>Some possible designs cause your AI to behave nicely while developing, and behave a lot less nicely when it's smarter.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/alignment_difficulty.html">Difficulty of AI alignment</a> <q>How hard is it exactly to point an Artificial General Intelligence in an intuitively okay direction?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/probable_environment_hacking.html">Distant superintelligences can coerce the most probable environment of your AI</a> <q>Distant superintelligences may be able to hack your local AI, if your AI's preference framework depends on its most probable environment.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/trits_with_galcom_bits.html">Encoding trits with GalCom bits</a> <q>There are $\log_2(3) \approx 1.585$ bits to a Trit. Why is it that particular value? Consider the Ga…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/epistemic_exclusion.html">Epistemic exclusion</a> <q>How would you build an AI that, no matter what else it learned about the world, never knew or wanted to know what was inside your basement?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/expected_utility_agent.html">Expected utility agent</a> <q>If you're not some kind of expected utility agent, you're going in circles.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/faithful_simulation.html">Faithful simulation</a> <q>How would you identify, to a Task AGI (aka Genie), the problem of scanning a human brain, and then running a sufficiently accurate simulation of it for the simulation to not be crazy or psychotic?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/fixed_point_theorem_provability_logic.html">Fixed point theorem of provability logic</a> <q>Deal with those pesky self-referential sentences!</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/2h8.html">Formal Logic</a> <q>Formal logic studies the form of correct arguments through rigorous and precise mathematical theories.</q> - <a class="page-link" href="page/ErikIstre.html">Erik Istre</a></li><li><a class="page-link" href="page/3v3.html">Fractional bits: Digit usage interpretation</a> <q>It is 316, not 500, that requires about two and a half digits to write down. 500 requires nearly 2.7…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/function.html">Function</a> <q>Intuitively, a function $f$  is a procedure (or machine) that takes an input and performs some opera…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/247.html">Grid scale storage</a> <q>Scalable energy storage is required if civilization's switches to primarily renewables in order to keep the grid powered at night. What are the options and how do they compare?</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/bits_in_a_trit.html">How many bits to a trit?</a> <q>$\log_2(3) \approx 1.585.$ This can be interpreted a few different ways:

1. If you multiply the nu…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/how_to_arbital.html">How to author on Arbital!</a> <q>Want to contribute pages to Arbital?  Here's our current version of the ad-hoc guide to being an author!</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/inductive_ambiguity.html">Identifying ambiguous inductions</a> <q>What do a &quot;red strawberry&quot;, a &quot;red apple&quot;, and a &quot;red cherry&quot; have in common that a &quot;yellow carrot&quot; doesn't?  Are they &quot;red fruits&quot; or &quot;red objects&quot;?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/immediate_goods.html">Immediate goods</a> <q>One of the potential views on 'value' in the value alignment problem is that what we should want fro…</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/information.html">Information</a> <q>Information is a measure of how much a message grants an observer the ability to predict the world.…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/instrumental_convergence.html">Instrumental convergence</a> <q>Some strategies can help achieve most possible simple goals.  E.g., acquiring more computing power or more material resources.  By default, unless averted, we can expect advanced AIs to do that.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/468.html">Joint probability distribution: (Motivation) coherent probabilities</a> <q>If you don't use joint probability distributions, none of your probabilities will make any sense. So, yeah, use joint probability distributions.</q> - <a class="page-link" href="page/TsviBT.html">Tsvi BT</a></li><li><a class="page-link" href="page/KANSI.html">Known-algorithm non-self-improving agent</a> <q>Possible advanced AIs that aren't self-modifying, aren't self-improving, and where we know and understand all the component algorithms.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/law_of_syllogism.html">Law of syllogism</a> <q>Deriving something from the conclusion of another thing.</q> - <a class="page-link" href="page/JeremyPerret.html">Jeremy Perret</a></li><li><a class="page-link" href="page/likelihood_vs_pvalue.html">Likelihood functions, p-values, and the replication crisis</a> <q>What's the whole Bayesian-vs.-frequentist debate about?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/log_tutorial_overview.html">Logarithm tutorial overview</a> <q>The logarithm tutorial covers the following six subjects:

1. What are logarithms?
2. Logarithms as…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/foreseeable_difficulties.html">Methodology of foreseeable difficulties</a> <q>Building a nice AI is likely to be hard enough, and contain enough gotchas that won't show up in the AI's early days, that we need to foresee problems coming in advance.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/unbounded_analysis.html">Methodology of unbounded analysis</a> <q>What we do and don't understand how to do, using unlimited computing power, is a critical distinction and important frontier.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/modus_tollens.html">Modus tollens</a> <q>Deriving a negation from another negation</q> - <a class="page-link" href="page/JeremyPerret.html">Jeremy Perret</a></li><li><a class="page-link" href="page/morphism.html">Morphism</a> <q>A morphism is the abstract representation of a relation between mathematical objects.

Usually, it i…</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/4s.html">Natural language understanding of &quot;right&quot; will yield normativity</a> <q>What will happen if you tell an advanced agent to do the &quot;right&quot; thing?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/natural_number_numbersets.html">Natural numbers: Intro to Number Sets</a> <q>Natural numbers are the numbers we use to count in everyday life.</q> - <a class="page-link" href="page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="page/nearest_unblocked.html">Nearest unblocked strategy</a> <q>If you patch an agent's preference framework to avoid an undesirable solution, what can you expect to happen?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/logical_negation.html">Negation of propositions</a> <q>The proposition that is false if another one is true and vice-versa.</q> - <a class="page-link" href="page/JeremyPerret.html">Jeremy Perret</a></li><li><a class="page-link" href="page/ontology_identification.html">Ontology identification problem</a> <q>How do we link an agent's utility function to its model of the world, when we don't know what that model will look like?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/taskagi_open_problems.html">Open subproblems in aligning a Task-based AGI</a> <q>Open research problems, especially ones we can model today, in building an AGI that can &quot;paint all cars pink&quot; without turning its future light cone into pink-painted cars.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/daemons.html">Optimization daemons</a> <q>When you optimize something so hard that it crystalizes into an optimizer, like the way natural selection optimized apes so hard they turned into human-level intelligences</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/oracle.html">Oracle</a> <q>System designed to safely answer questions.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/order_theory.html">Order theory</a> <q>The study of binary relations that are reflexive, transitive, and antisymmetic.</q> - <a class="page-link" href="page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="page/orthogonality.html">Orthogonality Thesis</a> <q>Will smart AIs automatically become benevolent, or automatically become hostile?  Or do different AI designs imply different goals?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/paperclip_maximizer.html">Paperclip maximizer</a> <q>This agent will not stop until the entire universe is filled with paperclips.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/programmer_deception.html">Programmer deception</a> <q>Programmer deception is when the AI's decision process leads it to optimize for an instrumental goal…</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/prog_dep_typ.html">Programming in  Dependent Type Theory</a> <q>Working with simple types in Lean</q> - <a class="page-link" href="page/JackGallagher.html">Jack Gallagher</a></li><li><a class="page-link" href="page/propositions.html">Propositions</a> <q>Propositions are statements with a truth value.</q> - <a class="page-link" href="page/JeremyPerret.html">Jeremy Perret</a></li><li><a class="page-link" href="page/246.html">Resources and the future</a> <q>Resource constraints are a widely held concern. Which are most likely to be limiting factors, and what can we do to relax those limits?</q> - <a class="page-link" href="page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="page/rice_and_halt.html">Rice's theorem and the Halting problem</a> <q>We will show that Rice's theorem and the the halting problem are equivalent.

#The Halting theorem i…</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/rich_domain.html">Rich domain</a> <q>A domain is 'rich', relative to our own intelligence, to the extent that (1) its [ search space] is …</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/algebraic_ring.html">Ring</a> <q>A ring is a kind of Algebraic structure which we obtain by considering groups as being &quot;things with…</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/shannon.html">Shannon</a> <q>The shannon (Sh) is a unit of Information. One shannon is the difference in [info\_entropy entropy] …</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/arithmetical_adequacy_GL.html">Solovay's theorems of arithmetical adequacy for GL</a> <q>Using GL to reason about PA, and viceversa</q> - <a class="page-link" href="page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="page/standard_agent.html">Standard agent properties</a> <q>What's a Standard Agent, and what can it do?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/task_agi.html">Task-directed AGI</a> <q>An advanced AI that's meant to pursue a series of limited-scope goals given it by the user.  In Bostrom's terminology, a Genie.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/reals_as_dedekind_cuts_form_a_field.html">The reals (constructed as Dedekind cuts) form a field</a> <q>The reals are an archetypal example of a field, but if we are to construct them from simpler objects, we need to show that our construction does indeed have the right properties.</q> - <a class="page-link" href="page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="page/only_one_log.html">There is only one logarithm</a> <q>All logarithm functions are the same, up to a multiplicative constant.</q> - <a class="page-link" href="page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="page/type_theory.html">Type theory</a> <q>Modern foundations for formal mathematics.</q> - <a class="page-link" href="page/JackGallagher.html">Jack Gallagher</a></li><li><a class="page-link" href="page/value_achievement_dilemma.html">Value achievement dilemma</a> <q>How can Earth-originating intelligent life achieve most of its potential value, whether by AI or otherwise?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/value_identification.html">Value identification problem</a> <q>The subproblem category of value alignment which deals with pinpointing valuable outcomes to an adva…</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/value_laden.html">Value-laden</a> <q>Cure cancer, but avoid any bad side effects?  Categorizing &quot;bad side effects&quot; requires knowing what's &quot;bad&quot;.  If an agent needs to load complex human goals to evaluate something, it's &quot;value-laden&quot;.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/Vingean_uncertainty.html">Vingean uncertainty</a> <q>You can't predict the exact actions of an agent smarter than you - so is there anything you _can_ say about them?</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="page/ZF_provability_oracle.html">Zermelo-Fraenkel provability oracle</a> <q>We might be able to build a system that can safely inform us that a theorem has a proof in set theory, but we can't see how to use that capability to save the world.</q> - <a class="page-link" href="page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul><h3 id="work_in_progress_meta_tag-comment">comment</h3><ul class="page-list"><li><a class="page-link" href="page/14n.html"><q>Please delete this if you are no longer using it. If you are, let me know how.</q></a> - <a class="page-link" href="page/AlexeiAndreev.html">Alexei Andreev</a></li></ul></main></body></html>