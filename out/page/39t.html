<!DOCTYPE html><html><head><meta charset="utf-8"><title>&quot;I think we're going to have...&quot;</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">&quot;I think we're going to have...&quot;</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/39t.json.html">39t.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/39t">https://arbital.com/p/39t</a></p><p class="creator">by
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a> Apr 21 2016 
updated
 Apr 21 2016</p></div><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>&quot;I think we're going to have...&quot;</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="value_identification.html">Value identification problem</a></li><li><a href="identify_goal_concept.html">Goal-concept identification</a></li><li><a href="37c.html">&quot;I think it's going to be ha...&quot;</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="value_identification.html">Value identification problem</a></li><li><a href="identify_goal_concept.html">Goal-concept identification</a></li><li>…</li></ul></nav></nav></header><hr><main><p>I think we're going to have to specialize the terminology so we have separate words for "learn any goal concept" and "learn human normativity" instead of calling these both "value", which is something I'm currently trying to think how to revise.  But if by value learning you mean "outcome-preference-criterion learning" and not <a href="value_alignment_value.html">value</a> learning, then yes, we're looking for outcome-preference-criterion learning where the criterion seems simple to us, is hopefully local, and is philosophically unproblematic by our own standards.  Like, say, having the outcome be one in which we just have a damn strawberry.</p>
<blockquote>
  <p>On this definition, what is the difference between "communicating a goal concept" and "communicating a goal"?</p>
</blockquote>
<p>In the language being used here, it sounds to me like "communicating a goal" should parse to "communicating a goal concept to an agent which will then optimize for the outcome-preference-criterion you're about to communicate to it."</p></main><hr><footer></footer></body></html>