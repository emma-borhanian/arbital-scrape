<!DOCTYPE html><html><head><meta charset="utf-8"><title>AIXI</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">AIXI</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/AIXI.json.html">AIXI.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/AIXI">https://arbital.com/p/AIXI</a></p><p class="creator">by
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a> Aug 4 2015 
updated
 Mar 31 2016</p></div><p class="clickbait">How to build an (evil) superintelligent AI using unlimited computing power and one page of Python code.</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>AIXI</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="advanced_safety.html">Advanced safety</a></li><li><a href="unbounded_analysis.html">Methodology of unbounded analysis</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="value_alignment_central_examples.html">Central examples</a></li><li>…</li></ul></nav></nav></header><hr><main><p><a href="http://www.hutter1.net/ai/aixigentle.htm">Marcus Hutter's AIXI</a> is the <a href="perfect_rolling_sphere.html">perfect rolling sphere</a> of <a href="advanced_agent.html">advanced agent</a> theory - it's not realistic, but you can't understand more complicated scenarios if you can't envision the rolling sphere. At the core of AIXI is <a href="solomonoff_induction.html">Solomonoff induction</a>, a way of using [ infinite computing power] to probabilistically predict binary sequences with (vastly) superintelligent acuity. Solomonoff induction proceeds roughly by considering all possible computable explanations, with [ prior probabilities] weighted by their <a href="Kolmogorov_complexity.html">algorithmic simplicity</a>, and [Bayesian_update updating their probabilities] based on how well they match observation. We then translate the agent problem into a sequence of percepts, actions, and rewards, so we can use sequence prediction. AIXI is roughly the agent that considers all computable hypotheses to explain the so-far-observed relation of sensory data and actions to rewards, and then searches for the best strategy to maximize future rewards.  To a first approximation, AIXI could figure out every ordinary problem that any human being or intergalactic civilization could solve.  If AIXI actually existed, it wouldn't be a god; it'd be something that could tear apart a god like tinfoil.</p>
<p>[summary(Brief): AIXI is the [perfect rolling sphere] of <a href="advanced_agent.html">advanced agent theory</a>, an ideal intelligent agent that uses infinite computing power to consider all computable hypotheses that relate its actions and sensory data to its rewards, then maximizes expected reward.]</p>
<p>[summary(Technical): <a href="http://www.hutter1.net/ai/aixigentle.htm">Marcus Hutter's AIXI</a> combines Solomonoff induction, expected utility maximization, and the [ Cartesian agent-environment-reward formalism] to yield a completely specified superintelligent agent that can be written out a single equation but would require a high-level [ halting oracle] to run.  The formalism requires that percepts, actions, and rewards can all be encoded as integer sequences.  AIXI considers all computable hypotheses, with prior probabilities weighted by algorithmic simplicity, that describe the relation of actions and percepts to rewards.  AIXI updates on its observations so far, then maximizes its next action's expected reward, under the assumption that its future selves up to some finite time horizon will similarly update and maximize.  The AIXI$~$tl$~$ variant requires (vast but) bounded computing power, and only considers hypotheses under a bounded length $~$l$~$ that can be computed within time $~$t$~$.  AIXI is a <a href="central_example.html">central example</a> throughout <a href="ai_alignment.html">value alignment theory</a>; it illustrates the [ Cartesian boundary problem], the <a href="unbounded_analysis.html">methodology of unbounded analysis</a>, the <a href="orthogonality.html">Orthogonality Thesis</a>, and [ seizing control of a reward signal].]</p>
<p>Further information:</p>
<ul>
<li><a href="http://www.hutter1.net/ai/uaibook.htm">Marcus Hutter's book on AIXI</a></li>
<li><a href="http://www.hutter1.net/ai/aixigentle.htm">Marcus Hutter's gentler introduction</a></li>
<li><a href="https://en.wikipedia.org/wiki/AIXI">Wikpedia article on AIXI</a></li>
<li><a href="https://wiki.lesswrong.com/wiki/AIXI">LessWrong Wiki article on AIXI</a></li>
</ul></main><hr><footer><p class="all-creators"><h2>All Creators</h2><span class="page-comma-list"><a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a>,
 <a class="page-link" href="../page/BrianMuhia.html">Brian Muhia</a>,
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a>,
 <a class="page-link" href="../page/EricRogstad.html">Eric Rogstad</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/BrianMuhia.html">Brian Muhia</a>,
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a>,
 <a class="page-link" href="../page/RokResnik.html">Rok Resnik</a></span></p><p class="children"><h2>Children</h2><ul class="page-tree"><li><a class="page-link" href="../page/aixitl.html">AIXI-tl</a> <q>A time-bounded version of the ideal agent AIXI that uses an impossibly large finite computer instead of a hypercomputer.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul></p></footer></body></html>