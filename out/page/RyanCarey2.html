<!DOCTYPE html><html><head><meta charset="utf-8"><title>Ryan Carey</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Ryan Carey</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/RyanCarey2.json.html">RyanCarey2.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/RyanCarey2">https://arbital.com/p/RyanCarey2</a></p><p class="creator">by
 <a class="page-link" href="../page/RyanCarey2.html">Ryan Carey</a> Dec 17 2016 
updated
 Dec 17 2016</p></div><p class="clickbait">Automatically generated page for Ryan Carey</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Ryan Carey</li></ul></nav></nav></header><hr><main><p>Automatically generated page for "Ryan Carey" user.
If you are the owner, click <a href="http://arbital.com/edit/700">here to edit</a>.</p></main><hr><footer><hr><p class="created"><h2>Created</h2><h3 id="createdwiki">wiki</h3><ul class="page-list"><li><a class="page-link" href="../page/76p.html">Approaches to strategic disagreement</a> <q>Organizations self-select staff to agree with their strategies. By default, this causes them to sacrifice the fulfillment of others' plans. How can we resolve these strategic disagreements?</q></li><li><a class="page-link" href="../page/739.html">Donor lotteries: demonstration and FAQ</a></li><li><a class="page-link" href="../page/76v.html">For most EA-Blank projects, we would expect more good to be done if they would: i) disband or ii) remove EA from the name and aim to outgrow the EA movement.</a> <q>The claim refers to projects like:

* Effective Altruism Forum
* Effective Altruism Handbook
* Effec…</q></li><li><a class="page-link" href="../page/76r.html">If EA leaders with similar values disagree about how the EA movement should be branded, then they should discuss in detail the subquestions that would cause them to change their minds if they have not already done so.</a></li><li><a class="page-link" href="../page/73b.html">If they spent 100x longer deciding where to donate, then most effective altruists would choose targets with much higher expected impact.</a> <q>Does analysis help?</q></li><li><a class="page-link" href="../page/76w.html">On the margin, effective altruist researchers and leaders should carry out more empirical investigation of strategic questions.</a> <q>Strategic question might include:

* How can we shape the development of brain-computer interfaces?
…</q></li></ul><h3 id="createdgroup">group</h3><ul class="page-list"><li><a class="page-link" href="../page/RyanCarey2.html">Ryan Carey</a></li></ul><h3 id="createdcomment">comment</h3><ul class="page-list"><li><a class="page-link" href="../page/89r.html"><q>&gt; That is to say, the “right” behavior is surrounded by a massive crater of “good enough” behaviors,…</q></a></li><li><a class="page-link" href="../page/772.html"><q>&gt; What is &quot;be more useful&quot;?

The question is what would happen if the people actually running the pr…</q></a></li><li><a class="page-link" href="../page/89c.html"><q>As Eric and EY jointly point out, this article seems to be roughly pointing at a simple classifier t…</q></a></li><li><a class="page-link" href="../page/724.html"><q>Confusing question. I guess this is talking about the claim pages. It could also be talking about ho…</q></a></li><li><a class="page-link" href="../page/89t.html"><q>Do we mean &quot;coerce behavior&quot; or &quot;determine environment&quot; here?</q></a></li><li><a class="page-link" href="../page/787.html"><q>I got the idea from someone who suggested that if donors would fund some organization-leaders to do …</q></a></li><li><a class="page-link" href="../page/898.html"><q>I think the &quot;task AI&quot; term has been a bit confusing. When people first hear the term &quot;task AI&quot; they …</q></a></li><li><a class="page-link" href="../page/89f.html"><q>Interesting question.

Here's how this problem is motivated in my head... The more obvious way to ge…</q></a></li><li><a class="page-link" href="../page/786.html"><q>Nice! That's exactly what I have in mind. The hope is to flesh out how this would and should be addr…</q></a></li><li><a class="page-link" href="../page/785.html"><q>Say we value article views and user signups. If I'm taking actions that achieve n views for each los…</q></a></li><li><a class="page-link" href="../page/722.html"><q>The thing that seems necessary to me is having a way to transmit good ideas from those who reliably …</q></a></li><li><a class="page-link" href="../page/89s.html"><q>This is a fair thing for more perfectionistic researchers to ask from pragmatists.

One thing that p…</q></a></li><li><a class="page-link" href="../page/897.html"><q>This is discussed under some name or other, by at least the utilitarians and by Paul Christiano.</q></a></li><li><a class="page-link" href="../page/72p.html"><q>This raises a new issue of how e.g. Steph is supposed to feel when the claim's wording has changed, …</q></a></li><li><a class="page-link" href="../page/723.html"><q>To clarify my view, I think EA moderately discourages creativity but this is a big mistake: it shoul…</q></a></li><li><a class="page-link" href="../page/89m.html"><q>You could argue that a superintelligence would be efficient at all tasks as follows:

Assume that:
1…</q></a></li><li><a class="page-link" href="../page/869.html"><q>detailed enough to be *sentient*</q></a></li><li><a class="page-link" href="../page/89l.html"><q>subhuman should contrast with superhuman, or infrahuman with suprahuman.</q></a></li><li><a class="page-link" href="../page/89b.html"><q>the strawberry diagrams are currently unavailable</q></a></li></ul></p></footer></body></html>