<!DOCTYPE html><html><head><meta charset="utf-8"><title>Likelihood</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Likelihood</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/bayesian_likelihood.json.html">bayesian_likelihood.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/bayesian_likelihood">https://arbital.com/p/bayesian_likelihood</a></p><p class="creator">by
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a> Jul 7 2016 
updated
 Oct 8 2016</p></div><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Likelihood</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="math.html">Mathematics</a></li><li><a href="probability_theory.html">Probability theory</a></li><li><a href="bayes_reasoning.html">Bayesian reasoning</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="rationality.html">Rationality</a></li><li><a href="probability_theory.html">Probability theory</a></li><li><a href="bayes_reasoning.html">Bayesian reasoning</a></li><li>…</li></ul></nav></nav></header><hr><main><p>[summary:  "Likelihood", when speaking of Bayesian reasoning, denotes <em>the probability of an observation, supposing some hypothesis to be correct.</em></p>
<p>Suppose our piece of evidence $~$e$~$ is that "Mr. Boddy was shot."  One of our suspects is Miss Scarlett, and we denote by $~$H_S$~$ the hypothesis that Miss Scarlett shot Mr. Boddy.  Suppose that if Miss Scarlett <em>were</em> the killer, we'd have predicted in advance a 20% probability she would use a gun, and an 80% chance she'd use some other weapon.</p>
<p>Then the <em>likelihood</em> from the evidence, to Miss Scarlett being the killer, is 0.20.  Using <a href="conditional_probability.html">conditional probability notation</a>, $~$\mathbb P(e \mid H_S) = 0.20.$~$</p>
<p>This doesn't mean Miss Scarlett has a 20% chance of being the killer; it means that if she is the killer, our observation had a probability of 20%.</p>
<p>Relative likelihoods are a key ingredient for <a href="bayes_update.html">Bayesian reasoning</a> and one of the quantities plugged into <a href="bayes_rule.html">Bayes&#39;s Rule</a>.]</p>
<p>Consider a piece of evidence $~$e,$~$ such as "Mr. Boddy was shot." We might have a number of different hypotheses that explain this evidence, including $~$H_S$~$ = "Miss Scarlett killed him", $~$H_M$~$ = "Colonel Mustard killed him", and so on.</p>
<p>Each of those hypotheses assigns a different probability to the evidence. For example, imagine that <em>if</em> Miss Scarlett <em>were</em> the killer, there's a 20% chance she would use a gun, and an 80% chance she'd use some other weapon. In this case, the "Miss Scarlett" hypothesis assigns a <em>likelihood</em> of 20% to $~$e.$~$</p>
<p>When reasoning about different hypotheses using a [-probability_distribution probability distribution] $~$\mathbb P$~$, the likelihood of evidence $~$e$~$ given hypothesis $~$H_i$~$ is often written using the <a href="conditional_probability.html">conditional probability</a> $~$\mathbb P(e \mid H_i).$~$ When reporting likelihoods of many different hypotheses at once, it is common to use a [-likelihood_function,] sometimes written [51n $~$\mathcal L_e(H_i)$~$].</p>
<p><a href="relative_likelihood.html">Relative likelihoods</a> measure the degree of support that a piece of evidence $~$e$~$ provides for different hypotheses. For example, let's say that if Colonel Mustard were the killer, there's a 40% chance he would use a gun. Then the absolute likelihoods of $~$H_S$~$ and $~$H_M$~$ are 20% and 40%, for <em>relative</em> likelihoods of (1 : 2). This says that the evidence $~$e$~$ supports $~$H_M$~$ twice as much as it supports $~$H_S,$~$ and that the amount of support would have been the same if the absolute likelihoods were 2% and 4% instead.</p>
<p>According to <a href="bayes_rule.html">Bayes&#39; rule</a>, relative likelihoods are the appropriate tool for measuring the <a href="bayes_strength_of_evidence.html">strength of a given piece evidence</a>. Relative likelihoods are one of two key constituents of belief in [bayesian_reasoning Bayesian reasoning], the other being <a href="prior_probability.html">prior probabilities</a>.</p>
<p>While absolute likelihoods aren't necessary when updating beliefs by Bayes' rule, they are useful when checking for <a href="strictly_confused.html">confusion</a>. For example, say you have a coin and only two hypotheses about how it works: $~$H_{0.3}$~$ = "the coin is random and comes up heads 30% of the time", and $~$H_{0.9}$~$ = "the coin is random and comes up heads 90% of the time." Now let's say you toss the coin 100 times, and observe the data HTHTHTHTHTHTHTHT… (alternating heads and tails). The <em>relative</em> likelihoods strongly favor $~$H_{0.3},$~$ because it was less wrong. However, the <em>absolute</em> likelihood of $~$H_{0.3}$~$ will be much lower than expected, and this deficit is a hint that $~$H_{0.3}$~$ isn't right. (For more on this idea, see <a href="strictly_confused.html">Strictly confused</a>.)</p></main><hr><footer><p class="tagged"><h2>Tagged</h2><span class="page-comma-list"><a class="page-link" href="../page/needs_clickbait_meta_tag.html">Needs clickbait</a>,
 <a class="page-link" href="../page/needs_summary_meta_tag.html">Needs summary</a>,
 <a class="page-link" href="../page/start_meta_tag.html">Start</a></span></p><p class="all-creators"><h2>All Creators</h2><span class="page-comma-list"><a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a>,
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a>,
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a>,
 <a class="page-link" href="../page/SzymonWilczyski.html">Szymon Wilczyński</a></span></p><p class="reverse-related"><h2>Reverse Related</h2><ul class="page-list"><li><a class="page-link" href="../page/needs_clickbait_meta_tag.html">Needs clickbait</a> <q>This page does not have clickbait (a short teaser for the page displayed on various lists). Feel free to add it!</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/needs_summary_meta_tag.html">Needs summary</a> <q>This page does not have a summary which provides an informative overview of the page's primary topic.</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/start_meta_tag.html">Start</a> <q>This page gives a basic overview of the topic, but may be missing important information or have stylistic issues. If you're able to, please help expand or improve it!</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul></p><p class="children"><h2>Children</h2><ul class="page-tree"><li><a class="page-link" href="../page/likelihood_function.html">Likelihood function</a> <q>Let's say you have a piece of evidence $e$ and a set of hypotheses $\mathcal H.$ Each $H_i \in \math…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/likelihood_notation.html">Likelihood notation</a> <q>The likelihood of a piece of evidence $e$ according to a hypothesis $H,$ known as &quot;the likelihood of…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/likelihood_ratio.html">Likelihood ratio</a> <q>Given a piece of evidence $e$ and two hypothsese $H_i$ and $H_j,$ the likelihood ratio between them…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/relative_likelihood.html">Relative likelihood</a> <q>How relatively likely an observation is, given two or more hypotheses, determines the strength and direction of evidence.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul></p></footer></body></html>