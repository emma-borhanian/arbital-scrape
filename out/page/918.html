<!DOCTYPE html><html><head><meta charset="utf-8"><title>&quot;Eliezer goes back and forth between &quot;sapient&quot; a...&quot;</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">&quot;Eliezer goes back and forth between &quot;sapient&quot; a...&quot;</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/918.json.html">918.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/918">https://arbital.com/p/918</a></p><p class="creator">by
 <a class="page-link" href="../page/PhilGoetz.html">Phil Goetz</a> Mar 13 2018 
updated
 Mar 13 2018</p></div><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>&quot;Eliezer goes back and forth between &quot;sapient&quot; a...&quot;</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="mindcrime.html">Mindcrime</a></li><li>â€¦</li></ul></nav></nav></header><hr><main><p>Eliezer goes back and forth between "sapient" and "sentient", which are not synonyms.  Neither is obviously a justification for claiming moral status as an agent.</p>
<p>It is important either to state clearly <em>what</em> one presumes gives an agent moral status (and hence what constitutes mindcrime), or to change each occurence of "sapient", "sentient", or "personhood" to all use the same word.  I recommend stating the general case using personhood(X), a function to be supplied by the user and not defined here.  Addressing the problem depends critically on what that function is--but the statement of the general case shouldn't be bound up with the choice of personhood predicate.</p>
<p>Choosing either "sapient" or "sentient" is problematic: "sentient" because it includes at least all mammals, and "sapient" because it really just means "intelligent", and the AI is going to be equally intelligent (defined as problem-solving or optimizing ability) whether it simulates <em>humans</em> or not.  If intelligence grants moral standing (as it seems to here), and mindcrime means trapping an agent with moral standing in the AI's world, then the construction of any AI is inherently mindcrime.</p></main><hr><footer></footer></body></html>