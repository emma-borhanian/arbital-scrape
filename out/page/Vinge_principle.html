<!DOCTYPE html><html><head><meta charset="utf-8"><title>Vinge's Principle</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Vinge's Principle</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/Vinge_principle.json.html">Vinge_principle.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/Vinge_principle">https://arbital.com/p/Vinge_principle</a></p><p class="creator">by
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a> Dec 18 2015 
updated
 Jun 25 2016</p></div><p class="clickbait">An agent building another agent must usually approve its design without knowing the agent's exact policy choices.</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Vinge's Principle</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="Vingean_reflection.html">Vingean reflection</a></li><li>…</li></ul></nav></nav></header><hr><main><p>[summary:  Vinge's Principle says that, <a href="rich_domain.html">in domains complicated enough</a> that perfect play is not possible, less intelligent agents will not be able to predict the <em>exact</em> moves made by more intelligent agents.</p>
<p>For example, if you knew exactly where <a href="deep_blue.html">Deep Blue</a> would play on a chessboard, you'd be able to play chess at least as well as Deep Blue by making whatever moves you predicted Deep Blue would make.  So if you want to write an algorithm that plays superhuman chess, you necessarily sacrifice your own ability to (without machine aid) predict its exact chess moves.</p>
<p>This doesn't mean we sacrifice our ability to understand <em>anything</em> about Deep Blue.  We can still understand that its goal is to win chess games rather than losing them, and <a href="Vingean_uncertainty.html">predict that whatever actions it takes, they&#39;ll eventually lead into a winning board state</a>.]</p>
<p>Vinge's Principle says that, <a href="rich_domain.html">in domains complicated enough</a> that perfect play is not possible, less intelligent agents will not be able to predict the <em>exact</em> moves made by more intelligent agents.</p>
<p>For example, if you knew exactly where <a href="deep_blue.html">Deep Blue</a> would play on a chessboard, you'd be able to play chess at least as well as Deep Blue by making whatever moves you predicted Deep Blue would make.  So if you want to write an algorithm that plays superhuman chess, you necessarily sacrifice your own ability to (without machine aid) predict the algorithm's exact chess moves.</p>
<p>This is true even though, as we become more confident of a chess algorithm's power, we become more confident that it will <em>eventually</em> win the chess game.  We become more sure of the game's final outcome, even as we become less sure of the chess algorithm's next move.  This is <a href="Vingean_uncertainty.html">Vingean uncertainty</a>.</p>
<p>Now consider agents that build other agents (or build their own successors, or modify their own code).  Vinge's Principle implies that the choice to approve the successor agent's design must be made without knowing the successor's exact sensory information, exact internal state, or exact motor outputs.  In the theory of <a href="tiling_agents.html">tiling agents</a>, this appears as the principle that the successor's sensory information, cognitive state, and action outputs should only appear inside quantifiers.  This is <a href="Vingean_reflection.html">Vingean reflection</a>.</p>
<p>For the rule about fictional characters not being smarter than the author, see <a href="Vinge_law.html">Vinge&#39;s Law</a>.</p></main><hr><section class="comments"><h2>Comments</h2><div class="comment"><p><a class="page-link" href="../page/MicahCarroll.html">Micah Carroll</a></p><p><blockquote class="comment-context">For example, if you knew exactly where Deep Blue would play on a chessboard, you'd be able to play chess at least as well as Deep Blue by making whatever moves you predicted Deep Blue would make\.  <mark>So if you want to write an algorithm that plays superhuman chess, you necessarily sacrifice your own ability to \(without machine aid\) predict the algorithm's exact chess moves\.</mark></blockquote>
<p>Technically, couldn't we run by hand on a piece of paper all the computations that Deep Blue goes through, and this way "predict the algorithm's exact chess moves"? In a way intuitively I feel like it's wrong to say that Deep Blue is "better than" us at playing chess, or AlphaGo is "better than" us at playing go. I feel like it depends on how we define "better", or in general "intelligence" and/or "skill" – if it is related to a notion of efficiency vs to one of speed. Because in terms of pure "competency", it seems like whatever a computer can do, we can do it too, although much slower – by just executing each line one step at a time.</p>
<p>As far as I can tell, current AI systems can just explore the search space of possible moves <em>faster</em> than us. They aren't necessarily as <em>efficient</em> as us – arguably AI systems are still very sample-inefficient (i.e. AlphaGo trained on many more games than any human would be able to play in his lifetime).</p>
<p>Clearly though running through all the computations by hand would take an unfeasible amount of time. Not sure if this is just a minor philosophical point or an actual thing one should care about. I'm still learning more about the field, wouldn't be surprised if someone already talked about this difference between speed and efficiency in defining intelligence but I just haven't found it yet.</p>
<p>I guess what I'm trying to say is that I agree with the premise that "less intelligent agents will not be able to predict the exact moves made by more intelligent agents", but I'm somehow not convinced that DeepBlue or AlphaGo are "more intelligent" than us – depending on the definition of intelligence we use. And under definitions for which they are more intelligent than us, then I don't agree Vinge's Principle applies for them unless there are time constraints.</p>
<p>[The exact phrase that Deep Blue is "better than us at playing chess" – that prompted my comment – is actually mentioned in <a href="instrumental_convergence.html">this</a> page under the "Compatibility with Vingean uncertainty" paragraph]</p></p></div></section><footer><p class="tagged"><h2>Tagged</h2><span class="page-comma-list"><a class="page-link" href="../page/Vingean_uncertainty.html">Vingean uncertainty</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a>,
 <a class="page-link" href="../page/MiddleKek.html">Middle Kek</a>,
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></span></p><p class="reverse-related"><h2>Reverse Related</h2><ul class="page-list"><li><a class="page-link" href="../page/Vingean_uncertainty.html">Vingean uncertainty</a> <q>You can't predict the exact actions of an agent smarter than you - so is there anything you _can_ say about them?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul></p></footer></body></html>