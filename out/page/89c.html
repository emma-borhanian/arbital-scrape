<!DOCTYPE html><html><head><meta charset="utf-8"><title>&quot;As Eric and EY jointly point out, this article ...&quot;</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">&quot;As Eric and EY jointly point out, this article ...&quot;</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/89c.json.html">89c.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/89c">https://arbital.com/p/89c</a></p><p class="creator">by
 <a class="page-link" href="../page/RyanCarey2.html">Ryan Carey</a> Apr 24 2017</p></div><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>&quot;As Eric and EY jointly point out, this article ...&quot;</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="AGI_typology.html">Strategic AGI typology</a></li><li><a href="task_agi.html">Task-directed AGI</a></li><li><a href="conservative_concept.html">Conservative concept boundary</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="task_agi.html">Task-directed AGI</a></li><li><a href="conservative_concept.html">Conservative concept boundary</a></li><li>…</li></ul></nav></nav></header><hr><main><p>As Eric and EY jointly point out, this article seems to be roughly pointing at a simple classifier that places a big penalty on false positives, e.g.:
loss = 100<em>(1-lambda)</em>(false<em>positive</em>rate) + (1-lambda)<em>(false<em>negative</em>rate) + lambda</em>regularization</p>
<p>After all, the purpose of regularization is to ensure simplicity.</p>
<p>To the extent that conservative concepts are at all different, it should run through the notion of ambiguity detection  and KWIK learning. At least that's what machine learning people will round the proposal off to until they have some other concrete proposals. Though maybe I'm missing something.</p></main><hr><footer></footer></body></html>