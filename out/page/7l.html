<!DOCTYPE html><html><head><meta charset="utf-8"><title>&quot;The ZFC provability box is ...&quot;</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">&quot;The ZFC provability box is ...&quot;</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/7l.json.html">7l.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/7l">https://arbital.com/p/7l</a></p><p class="creator">by
 <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a> Jun 18 2015</p></div><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>&quot;The ZFC provability box is ...&quot;</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="AGI_typology.html">Strategic AGI typology</a></li><li><a href="oracle.html">Oracle</a></li><li><a href="ZF_provability_oracle.html">Zermelo-Fraenkel provability oracle</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="AGI_typology.html">Strategic AGI typology</a></li><li><a href="task_agi.html">Task-directed AGI</a></li><li><a href="AI_boxing.html">Boxed AI</a></li><li><a href="ZF_provability_oracle.html">Zermelo-Fraenkel provability oracle</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="AGI_typology.html">Strategic AGI typology</a></li><li><a href="task_agi.html">Task-directed AGI</a></li><li><a href="oracle.html">Oracle</a></li><li><a href="ZF_provability_oracle.html">Zermelo-Fraenkel provability oracle</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="task_agi.html">Task-directed AGI</a></li><li><a href="AI_boxing.html">Boxed AI</a></li><li><a href="ZF_provability_oracle.html">Zermelo-Fraenkel provability oracle</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="task_agi.html">Task-directed AGI</a></li><li><a href="oracle.html">Oracle</a></li><li><a href="ZF_provability_oracle.html">Zermelo-Fraenkel provability oracle</a></li><li>…</li></ul></nav></nav></header><hr><main><p>The ZFC provability box is equivalent to a good SAT solver, up to a constant factor (and I don't see any reason to prefer one over the other). I think that the SAT solver metaphor is more familiar to most people and closer to practice, so I'd use that one unless there is some consideration pointing the other way.</p></main><hr><section class="comments"><h2>Comments</h2><div class="comment"><p><a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></p><p><p>I think that many readers will have an easier time imagining 'what we can do by knowing a theorem is true, without knowing the proof' than the much more abstract case of 'knowing an NP-hard satisfiability problem was solved, without knowing the satisfaction', but you're correct that the Oracle idiom generalizes to the latter case.</p></p></div><div class="comment"><p><a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></p><p><p>I don't see why getting the satisfying assignment really matters. If your AI sometimes declines to answer, then it can cause trouble anyway. If your AI always tries "its best" to answer, then you can just ask "Is there a satisfying solution that starts with 1? With 0?" though admittedly this is less efficient.</p>
<p>Which example is better may depend on your audience and your possible concerns. </p></p></div></section><footer></footer></body></html>