<!DOCTYPE html><html><head><meta charset="utf-8"><title>Toxoplasmosis dilemma</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Toxoplasmosis dilemma</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/toxoplasmosis_dilemma.json.html">toxoplasmosis_dilemma.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/toxoplasmosis_dilemma">https://arbital.com/p/toxoplasmosis_dilemma</a></p><p class="creator">by
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a> Aug 4 2016 
updated
 Aug 5 2016</p></div><p class="clickbait">A parasitic infection, carried by cats, may make humans enjoy petting cats more.  A kitten, now in front of you, isn't infected.  But if you *want* to pet it, you may already be infected.  Do you?</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Toxoplasmosis dilemma</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="decision_theory.html">Decision theory</a></li><li><a href="logical_dt.html">Logical decision theories</a></li><li><a href="newcomblike.html">Newcomblike decision problems</a></li><li>…</li></ul></nav></nav></header><hr><main><p>The parasite <a href="https://en.wikipedia.org/wiki/Toxoplasmosis">toxoplasma gondii</a> can be transmitted by cats and rats.  <em>Toxoplasma gondii</em> can pass from cat feces to rats.  Rats infected by <em>toxoplasma gondii</em> are less averse to cat odors, increasing the probability that they will be eaten by cats (which again transmits the parasite to cats).</p>
<p><em>Toxoplasma gondii</em> can also be transmitted to humans, causing toxoplasmosis; the non-acute form of which is implicated in other problems like schizophrenia.</p>
<p>For a while, starting in 2011, it was thought that infection with <em>toxoplasma gondii</em> may also cause human beings to like cats more (the newspapers talked about "crazy cat lady syndrome").  More recently, these studies may have failed to replicate.  But this is sufficiently lovely for reformulating an old decision-theory problem that we're going to pretend otherwise.</p>
<p>Suppose the human toxoplasmosis studies had replicated.  In particular, imagine that in the following experiment…</p>
<ul>
<li>Subjects are given \$10 to participate in the experiment.</li>
<li>Subjects are told about the general existence of toxoplasmosis.</li>
<li>Subjects are presented with a cute kitten that is guaranteed to not carry toxoplasmosis (it's been tested).</li>
<li>Subjects are offered a chance to pet the cute kitten for five minutes, or just end the experiment there and go home.</li>
</ul>
<p>…subjects who chose to pet the kitten were found to be 20% likely to have latent toxoplasmosis, while those who refrained from petting the kitten were 10% likely to have latent toxoplasmosis.</p>
<p>You are now part of a similar experiment.  If you pet the kitten, an observer would conclude that your absolute risk of latent toxoplasmosis is 10% higher, the health risks of which greatly outweigh the hedonic gains of petting a kitten for five minutes.  (We could postulate perhaps that petting the kitten gains you 1,000 hedonic units, while having latent toxoplasmosis will cost you 10,000,000 hedonic units. %note: The relative quantities chosen to be similar to those in <a href="newcombs_problem.html">Newcomb&#39;s Problem</a>.%)  On the other hand, petting the kitten cannot <em>cause</em> you to have toxoplasmosis--either you already have it or you don't.</p>
<p>Do you pet the kitten?</p>
<p>[todo: insert causal diagram here]</p>
<p>This dilemma is a revised form of the structurally similar [solomons_problem Solomon's Problem] and [smoking_lesion the Smoking Lesion] that are traditionally considered in decision theory.  (The Toxoplasmosis Dilemma has a more realistic causal structure than [solomons_problem Solomon's Problem], where your decision to steal another person's spouse is <em>causally</em> unconnected to the probability of rebellion, or [smoking_lesion the Smoking Lesion], where smoking has nothing to do with lung cancer.  Since these postulates directly contradict innate causal models, they might be confusing to the unfamiliar reader.)</p>
<p>In the form of [solomons_problem Solomon's Problem], and later the [smoking_lesion Smoking Lesion], this dilemma was historically significant and influential in the invention of <a href="causal_dt.html">causal decision theory</a> and its widespread adoption over the alternative of <a href="evidential_dt.html">evidential decision theory</a>.</p>
<h1 id="responses">Responses</h1>
<h2 id="causaldecisiontheory">Causal decision theory</h2>
<p>Pet the cute kitten!  This choice can't <em>cause</em> you to get toxoplasmosis; either you already have it or you don't.  So you might as well get the 1000 hedons from petting the kitten, if that's what you feel like; and if that causes you to update your probability afterward that you have toxoplasmosis, don't both trying to shoot the messenger.</p>
<h2 id="causaldecisiontheorywithratification">Causal decision theory with ratification</h2>
<p>Update your probability of latent toxoplasmosis as soon as you notice the initial impulse to pet the kitten, instead of waiting to observe your final action.  After updating, check if it still makes sense to pet the kitten according to the updated model.  It will still seem to make sense, meaning the model is stable at that point, so a CDT+ratification agent will go ahead and pet the kitten.</p>
<h2 id="evidentialdecisiontheory">Evidential decision theory</h2>
<p>Don't pet the cute kitten!  That would be bad news about your probability of having latent toxoplasmosis!</p>
<p>Of course, if as an EDT agent you decide <em>not</em> to pet the cute kitten on what your internal introspection reveals to be general EDT grounds, a more sophisticated EDT agent might further reason from this news that <em>among EDT agents faced with this dilemma,</em> there is no correlation between kitten-petting and latent toxoplasmosis, since all EDT agents refrain (as you realize once being told your own action as news).  However, this realization doesn't imply any infinite loop.  Upon being told as news that you <em>had</em> petted the kitten, you would expect the updated probability of having toxoplasmosis given that some EDT agents pet the kitten, which would be different from the base rate of agents having toxoplasmosis.  So although a more sophisticated EDT agent might expect the base rate of toxoplasmosis from refraining to pet the kitten, rather than expecting the updated lower toxoplasmosis rate among all subjects who don't pet the kitten, this will still be lower than the estimated rate of toxoplasmosis upon being told as news that one had petted the kitten.</p>
<h2 id="evidentialdecisiontheorywithatickle_defensetickledefense">Evidential decision theory with a [tickle_defense tickle defense]</h2>
<p>Introspectively noticing an impulse to pet the cute kitten is already bad news.  Actually petting the kitten isn't any <em>more</em> bad news on top of that.  So you might as well pet the kitten.</p>
<h2 id="logicaldecisiontheory">Logical decision theory</h2>
<p>To first order:  A logical decision theory would pet the kitten, since you couldn't make yourself not have toxoplasmosis if the logical output of your decision algorithm changed to "don't pet the kitten".</p>
<p>On envisioning a counterfactual world where LDT agents don't pet kittens in scenarios like these, an LDT agent expects that the choice to <em>not</em> pet the kitten would no longer be informative to an outside observer, and that in this counterfactual world, LDT agents would have toxoplasmosis at the base rate for all subjects in the experiment.  In this counterfactual world, we know not just "I am an agent that didn't pet the cat" but "I am an LDT agent that didn't pet the cat"; and since, in this counterfactual world, all LDT agents don't pet the cat, the decision to refrain should not be considered an informative tickle.</p>
<p>To second order, in worlds where an LDT agent <em>does</em> pet the cat, they should ask "Am I a typical agent that pets the cat, or an LDT agent?"  If there was a control version of the experiment where subjects were exposed to a safe kitten and <em>not</em> told about toxoplasmosis, an ideal LDT agent that pets the kitten might expect to have latent toxoplasmosis at a rate similar to a kitten-petting subject from the control experiment; since ideal LDT is not influenced by being told about latent toxoplasmosis if this actual kitten is known to be safe. %note: Of course, it could also be the case that non-ideal humans espousing LDT as a theoretical ideal are still influenced by being told about toxoplasmosis at the start of the experiment, and that thinking about this psychologically affects the degree to which a known-safe kitten seems enjoyable for petting. % A CDT agent with ratification might reason similarly, since it is able to accept its own choices as <em>news</em> or <em>evidence</em> about the choices of other CDT agents, after the fact of the decision, or inside a ratification loop.</p>
<p>On a technical level, it's possible that updating on observing yourself to pet the kitten might introduce difficulties into some formal LDT variants.  We can imagine toxoplasmosis as a disease that influences the utility function of the agent, raising upward the amount that it enjoys petting kittens.  Observing yourself to pet a kitten is informative about having toxoplasmosis because of what this tells you about your own utility function.  But the algorithm $~$\mathcal Q$~$ for [functional_dt functional] decision theory [godelian_diagonalization quotes itself] as $~$\ulcorner \mathcal Q \urcorner$~$ within its definition, including its own utility function $~$\mathcal U.$~$  So ideal FDT agents should already know their own utility functions $~$\mathcal U$~$ and should not be able to gain more information about their source code by watching themselves pet kittens.</p>
<p>Perfect self-knowledge is an unrealistic assumption for human agents, but uncertain self-knowledge has yet to be formalized in logical decision theory.  It's possible that introducing a ratification-like mechanism into LDT would imply infinite loops or money-pumpable mixed strategies on other Newcomblike problem, as in CDT agents facing <a href="death_in_damascus.html">Death in Damascus</a>.</p>
<p>[todo: tag with "open problems in LDT" and/or "uncertain self-knowledge in LDT"]</p>
<h1 id="toxoplasmosisversusnewcombsproblem">Toxoplasmosis versus Newcomb's Problem</h1>
<p>A widespread view in contemporary (2016) decision theory is that [solomons_problem Solomon's Problem] (to which the Toxoplasmosis Dilemma is meant to be structurally identical) is structurally the same as Newcomb's Problem.  That is, the Toxoplasmosis Dilemma and Newcomb's Problem are alleged to have the same structure: in both cases the EDT agent insanely does what corresponds to good news, and the CDT agent sanely does what corresponds to causally potent actions.  This analogous reply of EDT versus CDT to both dilemmas is part of the mainstream perception of [edt_cdt_dichotomy a dichotomy between EDT and CDT] around which most key issues in decision theory revolve.</p>
<p>Since LDT gives different analogous answers on Newcomb's Problem versus the Toxoplasmosis Dilemma, obviously LDT would consider these problems to have importantly different structure.</p>
<p>One broad argument for this important structural difference, which does not rely on LDT per se, is to observe that both EDT agents and CDT agents would prefer different <em>precommitments</em> on Newcomb's Problem versus Toxoplasmosis.  Both EDT agents and CDT agents would prefer to precommit to one-box, although CDT agents demand that they do so [son_of_CDT before Omega scans them].  Conversely, if EDT or CDT agents know in advance that they will face some type of Toxoplasmosis Dilemma, they would both prefer to commit to kitten-petting if this is what the average subject prefers (which commitment is then no longer bad news from an EDT perspective, if you know that you're doing it because of precommitting before you saw the kitten).  Similarly, a [pretheoretical pretheoretical] subject would probably also prefer different precommitments in Toxoplasmosis versus Newcomb's Problem.  This argues that the two dilemmas have baked-in some important structural difference between them, which can be exposed by asking any decision theory about its preferred precommitment, even if EDT and CDT see no <em>relevant</em> difference in the moment of facing the actual dilemmas.</p></main><hr><footer><p class="tagged"><h2>Tagged</h2><span class="page-comma-list"><a class="page-link" href="../page/start_meta_tag.html">Start</a></span></p><p class="reverse-related"><h2>Reverse Related</h2><ul class="page-list"><li><a class="page-link" href="../page/start_meta_tag.html">Start</a> <q>This page gives a basic overview of the topic, but may be missing important information or have stylistic issues. If you're able to, please help expand or improve it!</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul></p></footer></body></html>