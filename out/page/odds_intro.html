<!DOCTYPE html><html><head><meta charset="utf-8"><title>Odds: Introduction</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Odds: Introduction</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/odds_intro.json.html">odds_intro.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/odds_intro">https://arbital.com/p/odds_intro</a></p><p class="creator">by
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a> Jul 6 2016 
updated
 Oct 11 2016</p></div><p class="clickbait">What's the difference between probabilities and odds? Why is a 20% probability of success equivalent to 1 : 4 odds favoring success?</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Odds: Introduction</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="math.html">Mathematics</a></li><li><a href="probability_theory.html">Probability theory</a></li><li><a href="odds.html">Odds</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="rationality.html">Rationality</a></li><li><a href="probability_theory.html">Probability theory</a></li><li><a href="odds.html">Odds</a></li><li>…</li></ul></nav></nav></header><hr><main><p>Lets say we have a bag containing twice as many blue marbles as red marbles. Then, if you reach in without looking and pick out a marble at random, the odds are 2 : 1 in favor of drawing a blue marble as opposed to a red one.</p>
<p>Odds express <em>relative</em> quantities. 2 : 1 odds are the same as 4 : 2 odds are the same as 600 : 300 odds. For example, if the bag contains 1 red marble and 2 blue marbles, or 2 red marbles and 4 blue marbles, then your chance of pulling out a red marble is the same in both cases:</p>
<p><img src="https://i.imgur.com/IcsOXl0.png?0" alt="" /></p>
<p>In other words, given odds of $~$(x : y)$~$ we can scale it by any positive number $~$\alpha$~$ to get equivalent odds of $~$(\alpha x : \alpha y).$~$ </p>
<h1 id="convertingoddstoprobabilities">Converting odds to probabilities</h1>
<p>If there were also green marbles, the <em>relative odds</em> for red <em>versus</em> blue would still be (1 : 2), but the <em>probability</em> of drawing a red marble would be lower.</p>
<p><img src="https://i.imgur.com/ooyn9Py.png?0" alt="" /></p>
<p>If red, blue, and green are the only kinds of marbles in the bag, then we can turn odds of $~$(r : b : g)$~$ into probabilities $~$(p_r : p_b : p_g)$~$ that say the probability of drawing each kind of marble.  Because red, blue, and green are the only possibilities, $~$p_r + p_g + p_b$~$ must equal 1, so $~$(p_r : p_b : p_g)$~$ must be odds equivalent to $~$(r : b : g)$~$ but "normalized" such that it sums to one. For example, $~$(1 : 2 : 1)$~$ would normalize to $~$\frac{1}{4} : \frac{2}{4} : \frac{1}{4},$~$ which are the probabilities of drawing a red / blue / green marble (respectively) from the bag on the right above.</p>
<p>Note that if red and blue are not the only possibilities, then it doesn't make sense to convert the odds $~$(r : b)$~$ of red vs blue into a probability. For example, if there are 100 green marbles, one red marble, and two blue marbles, then the odds of red vs blue are 1 : 2, but the probability of drawing a red marble is much lower than 1/3! Odds can only be converted into probabilities if its terms are <a href="exclusive_exhaustive.html">Mutually exclusive and exhaustive</a>.</p>
<p>Imagine a forest with some sick trees and some healthy trees, where the odds of a tree being sick (as opposed to heathy) are (2 : 3), and every tree is either sick or healthy (there are no in-between states). Then the probability of randomly picking a sick tree from among <em>all</em> trees is 2 / 5, because 2 out of every (2 + 3) trees is sick.</p>
<p><img src="https://i.imgur.com/GVZnz2c.png?0" alt="" /></p>
<p>In general, the operation we're doing here is taking relative odds like $~$(a : b : c \ldots)$~$ and dividing each term by the sum $~$(a + b + c \ldots)$~$ to produce $$~$\left(\frac{a}{a + b + c \ldots} : \frac{b}{a + b + c \ldots} : \frac{c}{a + b + c \ldots}\ldots\right)$~$$ Dividing each term by the sum of all terms gives us an equivalent set of odds (because each element is divided by the same amount) whose terms sum to 1.</p>
<p>This process of dividing a set of odds by the sum of its terms to get a set of probabilities that sum to 1 is called <a href="normalize_probabilities.html">normalization</a>.</p>
<h1 id="convertingprobabilitiestoodds">Converting probabilities to odds</h1>
<p>Let's say we have two events R and B, which might be things like "I draw a red marble" and "I draw a blue marble." Say $~$\mathbb P(R) = \frac{1}{4}$~$ and $~$\mathbb P(B) = \frac{1}{2}.$~$ What are the odds of R vs B? $~$\mathbb P(R) : \mathbb P(B) = \left(\frac{1}{4} : \frac{1}{2}\right),$~$ of course.</p>
<p>Equivalently, we can take the odds $~$\left(\frac{\mathbb P(R)}{\mathbb P(B)} : 1\right)$~$, because $~$\frac{\mathbb P(R)}{\mathbb P(B)}$~$ is how many more times likely R is than B. In this example, $~$\frac{\mathbb P(R)}{\mathbb P(B)} = \frac{1}{2},$~$ because R is half as likely as B. Sometimes, the quantity $~$\frac{\mathbb P(R)}{\mathbb P(B)}$~$ is called the "odds ratio of R vs B," in which case it is understood that the odds for R vs B are $~$\left(\frac{\mathbb P(R)}{\mathbb P(B)} : 1\right).$~$</p>
<h1 id="oddstoratios">Odds to ratios</h1>
<p>When there are only two terms $~$x$~$ and $~$y$~$ in a set of odds, the odds can be written as a ratio $~$\frac{x}{y}.$~$ The odds <em>ratio</em> $~$\frac{x}{y}$~$ refers to the <em>odds</em> $~$(x : y),$~$ or, equivalently, $~$\left(\frac{x}{y} : 1\right).$~$</p></main><hr><section class="comments"><h2>Comments</h2><div class="comment"><p><a class="page-link" href="../page/RichardBatty.html">Richard Batty</a></p><p><blockquote class="comment-context">In other words, given odds of $~$(x : y)$~$ we can scale it by any positive number $~$\\alpha$~$ to get equivalent odds of $~$(\\alpha x : \\alpha y).$~$ <mark>When there are only two terms $~$x$~$ and $~$y$~$ in a set of odds, the odds can be written as a ratio $~$\\frac{x}{y}.$~$ It is understood that the odds ratio $~$\\frac{x}{y}$~$ refers to the odds $~$(x : y),$~$ or, equivalently, $~$\\left(\\frac{x}{y} : 1\\right).$~$</mark></blockquote>
<p>The $~$x/y$~$ notation is confusing - these ratios aren't probabilities are they?</p></p></div></section><footer><p class="tagged"><h2>Tagged</h2><span class="page-comma-list"><a class="page-link" href="../page/c_class_meta_tag.html">C-Class</a>,
 <a class="page-link" href="../page/low_speed_meta_tag.html">Low-speed explanation</a></span></p><p class="all-creators"><h2>All Creators</h2><span class="page-comma-list"><a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a>,
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a>,
 <a class="page-link" href="../page/ChrisCooper.html">Chris Cooper</a>,
 <a class="page-link" href="../page/GeoffroyPlanquart.html">Geoffroy Planquart</a>,
 <a class="page-link" href="../page/JasonWada.html">Jason Wada</a>,
 <a class="page-link" href="../page/KeithBeech.html">Keith Beech</a>,
 <a class="page-link" href="../page/MalcolmMcCrimmon.html">Malcolm McCrimmon</a>,
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a>,
 <a class="page-link" href="../page/PierreThierry.html">Pierre Thierry</a>,
 <a class="page-link" href="../page/SzymonWilczyski.html">Szymon Wilczyński</a>,
 <a class="page-link" href="../page/UltraNihilist.html">Ultra Nihilist</a></span></p><p class="reverse-related"><h2>Reverse Related</h2><ul class="page-list"><li><a class="page-link" href="../page/c_class_meta_tag.html">C-Class</a> <q>This page has substantial content, but may not thoroughly cover the topic, may not meet style and prose standards, or may not explain the concept in a way the target audience will reliably understand.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/low_speed_meta_tag.html">Low-speed explanation</a> <q>Use this tag to indicate that a page offers a relatively slower, more gentle, or more wordy explanat…</q> - <a class="page-link" href="../page/EricRogstad.html">Eric Rogstad</a></li></ul></p></footer></body></html>