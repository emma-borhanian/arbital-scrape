<!DOCTYPE html><html><head><meta charset="utf-8"><title>Identifying causal goal concepts from sensory data</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Identifying causal goal concepts from sensory data</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/identify_causal_goals.json.html">identify_causal_goals.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/identify_causal_goals">https://arbital.com/p/identify_causal_goals</a></p><p class="creator">by
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a> Apr 14 2016</p></div><p class="clickbait">If the intended goal is &quot;cure cancer&quot; and you show the AI healthy patients, it sees, say, a pattern of pixels on a webcam.  How do you get to a goal concept *about* the real patients?</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Identifying causal goal concepts from sensory data</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="value_identification.html">Value identification problem</a></li><li>â€¦</li></ul></nav></nav></header><hr><main><p>Suppose we want an AI to carry out some goals involving strawberries, and as a result, we want to <a href="identify_goal_concept.html">identify</a> to the AI the [ concept] of "strawberry".  One of the potential ways we could do this is by showing the AI objects that a teacher classifies as strawberries or non-strawberries.  However, in the course of doing this, what the AI actually sees will be e.g. a pattern of pixels on a webcam - the actual, physical strawberry is not directly accessible to the AI's intelligence.  When we show the AI a strawberry, what we're really trying to communicate is "A certain proximal [ cause] of this sensory data is a strawberry", not, "This arrangement of sensory pixels is a strawberry."  An AI that learns the latter concept might try to carry out its goal by putting a picture in front of its webcam; the former AI has a goal that actually involves something in its environment.</p>
<p>The open problem of "identifying causal goal concepts from sensory data" or "identifying environmental concepts from sensory data" is about getting an AI to form [ causal] goal concepts instead of [ sensory] goal concepts.  Since almost no <a href="intended_goal.html">human-intended goal</a> will ever be satisfiable solely in virtue of an advanced agent arranging to see a certain field of pixels, safe ways of identifying goals to sufficiently advanced goal-based agents will presumably involve some way of identifying goals among the <em>causes</em> of sense data.</p>
<p>A "toy" (and still pretty difficult) version of this open problem might be to exhibit a machine algorithm that (a) has a causal model of its environment, (b) can learn concepts over any level of its causal model including sense data, (c) can learn and pursue a goal concept, (d) has the potential ability to spoof its own senses or create fake versions of objects, and (e) is shown to learn a proximal causal goal rather than a goal about sensory data as shown by it pursuing only the causal version of that goal even if it would have the option to spoof itself.</p>
<p>For a more elaborated version of this open problem, see "<a href="pointing_finger.html">Look where I&#39;m pointing, not at my finger</a>".</p></main><hr><footer><p class="tagged"><h2>Tagged</h2><span class="page-comma-list"><a class="page-link" href="../page/pointing_finger.html">Look where I'm pointing, not at my finger</a>,
 <a class="page-link" href="../page/taskagi_open_problems.html">Open subproblems in aligning a Task-based AGI</a>,
 <a class="page-link" href="../page/task_identification.html">Task identification problem</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/NateSoares.html">Nate Soares</a></span></p><p class="reverse-related"><h2>Reverse Related</h2><ul class="page-list"><li><a class="page-link" href="../page/pointing_finger.html">Look where I'm pointing, not at my finger</a> <q>When trying to communicate the concept &quot;glove&quot;, getting the AGI to focus on &quot;gloves&quot; rather than &quot;my user's decision to label something a glove&quot; or &quot;anything that depresses the glove-labeling button&quot;.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/taskagi_open_problems.html">Open subproblems in aligning a Task-based AGI</a> <q>Open research problems, especially ones we can model today, in building an AGI that can &quot;paint all cars pink&quot; without turning its future light cone into pink-painted cars.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/task_identification.html">Task identification problem</a> <q>If you have a task-based AGI (Genie) then how do you pinpoint exactly what you want it to do (and not do)?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul></p></footer></body></html>