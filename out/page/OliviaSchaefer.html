<!DOCTYPE html><html><head><meta charset="utf-8"><title>Olivia Schaefer</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Olivia Schaefer</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/OliviaSchaefer.json.html">OliviaSchaefer.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/OliviaSchaefer">https://arbital.com/p/OliviaSchaefer</a></p><p class="creator">by
 <a class="page-link" href="../page/OliviaSchaefer.html">Olivia Schaefer</a> Oct 13 2015</p></div><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Olivia Schaefer</li></ul></nav></nav></header><hr><main><p>Automatically generated page for "Olivia Schaefer" user. Click <a href="https://arbital.com/edit/15d">here to edit</a>.</p></main><hr><footer><hr><p class="created"><h2>Created</h2><h3 id="createdwiki">wiki</h3><ul class="page-list"><li><a class="page-link" href="../page/1qk.html">Active learning for opaque, powerful predictors</a> <q>#### 

(An open theoretical question relevant to AI control.)

Suppose that I have a very powerful p…</q></li><li><a class="page-link" href="../page/1q0.html">Children in a sidebar</a> <q>I always forget to scroll all the way down. I shouldn't have to. Putting children in a sidebar allow…</q></li><li><a class="page-link" href="../page/1qy.html">Collusion is a major concern</a> <q>Breaking out of the Prisoner's Dilemma</q></li><li><a class="page-link" href="../page/1qx.html">Human in the counterfactual loop</a> <q>Consider an autonomous system which is buying or selling assets, operating heavy machinery, or makin…</q></li><li><a class="page-link" href="../page/1qp.html">Learning representations</a> <q>Many AI systems form internal representations of their current environment or of particular data. Pr…</q></li><li><a class="page-link" href="../page/1qm.html">Reinforcement learning</a> <q>Reinforcement learning is the process by which an agent learns what actions to take by maximizing a …</q></li><li><a class="page-link" href="../page/1qn.html">Reward engineering</a> <q>This post gestures at a handful of research questions with a loose thematic connection.

## The idea…</q></li><li><a class="page-link" href="../page/86m.html">Taking people seriously</a></li></ul><h3 id="createdgroup">group</h3><ul class="page-list"><li><a class="page-link" href="../page/OliviaSchaefer.html">Olivia Schaefer</a></li></ul><h3 id="createdcomment">comment</h3><ul class="page-list"><li><a class="page-link" href="../page/1cg.html"><q>I think Wikipedia does it pretty well. Defaulting to capitalizing with the option to disable it look…</q></a></li></ul></p><p class="edited"><h2>Edited</h2><ul class="page-list"><li><a class="page-link" href="../page/1qr.html">Approval-based agents</a> <q>An alternative to goal-directed behavior</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/consequentialist.html">Consequentialist cognition</a> <q>The cognitive ability to foresee the consequences of actions, prefer some outcomes to others, and output actions leading to the preferred outcomes.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/omni_test.html">Omnipotence test for AI safety</a> <q>Would your AI produce disastrous outcomes if it suddenly gained omnipotence and omniscience? If so, why did you program something that *wants* to hurt you and is held back only by lacking the power?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/1ql.html">Scalable AI Control</a> <q>By AI control, I mean the problem of getting AI systems to do what we want them to do, to the best o…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li></ul></p></footer></body></html>