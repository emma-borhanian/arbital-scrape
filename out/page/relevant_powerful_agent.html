<!DOCTYPE html><html><head><meta charset="utf-8"><title>Relevant powerful agent</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Relevant powerful agent</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/relevant_powerful_agent.json.html">relevant_powerful_agent.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/relevant_powerful_agent">https://arbital.com/p/relevant_powerful_agent</a></p><p class="creator">by
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a> Mar 26 2015 
updated
 Dec 16 2015</p></div><p class="clickbait">An agent is relevant if it completely changes the course of history.</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Relevant powerful agent</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li>â€¦</li></ul></nav></nav></header><hr><main><p>A cognitively powerful agent is <em>relevant</em> if it is cognitively powerful enough to be a game-changer in the larger dilemma faced by Earth-originating intelligent life.  Conversely, an agent is <em>irrelevant</em> if it is too weak to make much of a difference, or if the cognitive problems it can solve or tasks it is authorized to perform don't significantly change the overall situation we face.</p>
<h2 id="definition">Definition</h2>
<p>Intuitively speaking, a value-aligned AI is 'relevant' to the extent it has a 'yes' answer to the box 'Can we use this AI to produce a benefit that solves the larger dilemma?' in <a href="https://i.imgur.com/JuIFAxh.png?0">this flowchart</a>, or is part of a larger plan that gets us to the lower green circle without any "Then a miracle occurs" steps.  A cognitively powerful agent is relevant at all if its existence can effectuate good or bad outcomes - e.g., a big neural net is not 'relevant' because it doesn't end the world one way or another.</p>
<p>(A better word than 'relevant' might be helpful here.)</p>
<h2 id="examples">Examples</h2>
<h3 id="positiveexamples">Positive examples</h3>
<ul>
<li>A hypothetical agent that can bootstrap to nanotechnology by solving the inverse protein folding problem and shut down other AI projects, in a way that can reasonably be known safe enough to authorize by the AI's programmers, would be relevant.</li>
</ul>
<h3 id="negativeexamples">Negative examples</h3>
<ul>
<li>An agent authorized to prove or disprove the Riemann Hypothesis, but not to do anything else, is not relevant (unless knowing whether the Riemann Hypothesis is true somehow changes everything for the basic dilemma of AI).</li>
<li>An oracle that can only output verified HOL proofs is not yet 'relevant' until someone can describe theorems to prove such that firm knowledge of their truth would be a game-changer for the AI situation.  (Hypothesizing that someone else will come up with a theorem like that, if you just build the oracle, is a [ hail Mary step] in the plan.)</li>
</ul>
<h2 id="importance">Importance</h2>
<p>Many proposals for AI safety, especially <a href="advanced_safety.html">advanced safety</a>, so severely restrict the applicability of the AI that the AI is no longer allowed to do anything that seems like it could solve the larger dilemma.  (E.g., an oracle that is only allowed to give us binary answers for whether it thinks certain mathematical facts are true, and nobody has yet said how to use this ability to save the world.)</p>
<p>Conversely, proposals to use AIs to do things impactful enough to solve the larger dilemma, generally run smack into all the usual <a href="advanced_safety.html">advanced safety</a> problems, especially if the AI must operate in the rich domain of the real world to carry out the task (this tends to require full trust).</p>
<h2 id="openproblem">Open problem</h2>
<p><a href="relevant_limited_AI.html">It is an open problem to propose a relevant, limited AI</a> that would be significantly easier to handle than the general safety problem, while also being useful enough to resolve the larger .</p></main><hr><section class="comments"><h2>Comments</h2><div class="comment"><p><a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></p><p><blockquote class="comment-context">\(A better word than 'relevant' might be helpful here\.\)</blockquote>
<p>Pivotal? Game-changing? Terminal?</p></p></div></section><footer><p class="all-creators"><h2>All Creators</h2><span class="page-comma-list"><a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a>,
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></span></p></footer></body></html>