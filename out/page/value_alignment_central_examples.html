<!DOCTYPE html><html><head><meta charset="utf-8"><title>Central examples</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="../MathJax-2.7.5/MathJax.js"></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Central examples</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/value_alignment_central_examples.json.html">value_alignment_central_examples.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/value_alignment_central_examples">https://arbital.com/p/value_alignment_central_examples</a></p><p class="creator">by
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a> Jul 14 2015 
updated
 Dec 28 2015</p></div><p class="clickbait">List of central examples in Value Alignment Theory domain.</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Central examples</li></ul></nav></nav></header><hr><main><p>[summary: Comprehensive list of <a href="central_example.html">central examples</a> used in <a href="ai_alignment.html">Value Alignment Theory</a>.]</p>
<p><a href="central_example.html">Central examples</a> used in <a href="ai_alignment.html">Value Alignment Theory</a>:</p>
<ul>
<li><a href="paperclip_maximizer.html">Paperclip maximizer</a></li>
<li>instrumental convergence</li>
<li>Gandhian stability &amp; Orthogonality</li>
<li>value not instrumentally convergent</li>
<li>agents</li>
<li>nanotech catastrophe?</li>
<li>programmer manipulation?</li>
<li>astronomical failure</li>
<li>Smile maximizer</li>
<li><a href="value_identification.html">Value identification problem</a></li>
<li><a href="unforeseen_maximum.html">Unforseen maximum</a></li>
<li><a href="edge_instantiation.html">Edge Instantiation</a></li>
<li><a href="patch_resistant.html">Patch resistance</a></li>
<li>Treacherous Turn<ul>
<li><a href="programmer_deception.html">Programmer deception</a></li></ul></li>
<li><a href="context_disaster.html">Context Change problem</a></li>
<li><a href="complexity_of_value.html">Complexity of value</a></li>
<li><a href="AIXI.html">AIXI</a> and AIXI-tl</li>
<li>Cartesian boundaries<ul>
<li>problem of 'wireheading' the reward signal</li></ul></li>
<li>methodology of unbounded analysis</li>
<li>what we do and don't know about AI</li>
<li>agents</li>
<li>Little box in a cellular automaton?</li>
<li>Naturalized induction</li>
<li>Nuclear Prisoner's Dilemma</li>
<li>timeless decision theory &amp; Newcomblike problems</li>
<li>problem of the blackmail-free equilibrium</li>
<li>division-of-gains problem would need further-expanded matrix</li>
<li>Delta-sigma agents?</li>
<li>tiling agents</li>
<li><a href="ZF_provability_oracle.html">ZF provability Oracle</a></li>
<li>power/safety tradeoff</li>
<li><a href="pivotal.html">Notion of a pivotal achievement</a></li>
<li><a href="AI_boxing.html">Boxing problem</a></li>
<li><a href="behaviorist.html">Behaviorist genie</a></li>
<li>power/safety tradeoff</li>
<li>defeater for some agency and recursion assumptions</li>
<li><a href="http://lesswrong.com/lw/qk/that_alien_message/">That Alien Message</a></li>
<li><a href="AI_boxing.html">Boxing problem</a></li>
<li><a href="uncontainability.html">Cognitive uncontainability</a></li>
<li><a href="diamond_maximizer.html">Diamond maximizer</a></li>
<li><a href="ontology_identification.html">Ontology identification problem</a></li>
</ul></main><hr><footer><p class="tagged"><h2>Tagged</h2><span class="page-comma-list"><a class="page-link" href="../page/central_example.html">Central examples</a>,
 <a class="page-link" href="../page/list_meta_tag.html">List</a>,
 <a class="page-link" href="../page/work_in_progress_meta_tag.html">Work in progress</a></span></p><p class="all-creators"><h2>All Creators</h2><span class="page-comma-list"><a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a>,
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a>,
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></span></p><p class="reverse-related"><h2>Reverse Related</h2><ul class="page-list"><li><a class="page-link" href="../page/central_example.html">Central examples</a> <q>The &quot;central examples&quot; for a subject are examples that are referred to over and over again in the co…</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/list_meta_tag.html">List</a> <q>Meta tags for pages that are basically lists.</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/work_in_progress_meta_tag.html">Work in progress</a> <q>This page is being actively worked on by an editor. Check with them before making major changes.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul></p><p class="children"><h2>Children</h2><ul class="page-tree"><li><a class="page-link" href="../page/AIXI.html">AIXI</a> <q>How to build an (evil) superintelligent AI using unlimited computing power and one page of Python code.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a><ul class="page-tree"><li><a class="page-link" href="../page/aixitl.html">AIXI-tl</a> <q>A time-bounded version of the ideal agent AIXI that uses an impossibly large finite computer instead of a hypercomputer.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul></li><li><a class="page-link" href="../page/happiness_maximizer.html">Happiness maximizer</a> <q>It is sometimes proposed that we build an AI intended to maximize human happiness.  (One early propo…</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul></p></footer></body></html>