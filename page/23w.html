<!DOCTYPE html><html><head><meta charset="utf-8"><title>&quot;Regarding corporations:

I ...&quot;</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG" async></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">&quot;Regarding corporations:

I ...&quot;</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/23w.json.html">23w.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/23w">https://arbital.com/p/23w</a></p><p class="creator">by
 <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a> Feb 26 2016</p></div><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>&quot;Regarding corporations:

I ...&quot;</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="advanced_agent_theory.html">Theory of (advanced) agents</a></li><li><a href="advanced_agent.html">Advanced agent properties</a></li><li><a href="efficiency.html">Epistemic and instrumental efficiency</a></li><li>…</li></ul></nav></nav></header><hr><main><p>Regarding corporations:</p>
<p>I have seen very few arguments about superintelligence that rest on epistemic efficiency. Roughly speaking, epistemic efficiency with respect to X might be interpreted as "smarter in every way than X." But we usually talk about systems that are "smarter in some ways than humans." And the safety problem doesn't seem to change in a qualitative way at the threshold of "smarter in every way." Nor does economic value, or most indicators of interest. The only measure on which that's a fundamental threshold is "how hard it is for humans to do anything useful" (but this is not an indicator people are talking about if they talk about corporations, for obvious reasons…)</p>
<p>So while I might agree that a corporation is not a superintelligence on Nick's definition, this doesn't seem to have much bearing on the way in which the analogy is invoked in discussions.  In general, this notion of superintelligence is a <em>sufficient</em> condition for lots of interesting phenomena, but not a necessary condition for almost anything.</p>
<p>It just seems like you semantically disagreeing about the use of the word "superhuman." This seems like a missed opportunity to help communicate about the value alignment problem. (Also, though it's not precisely related, I think that people really do think about AI better when they think about it as "idealized corporation" rather than "idealized human." Corporatization seems to be a better baseline than anthropomorphization, though neither is great.)</p>
<p>To make things more concrete, I think it is roughly as reasonable to ask about the "value alignment problem for organizations," and that many solutions to the value alignment problem for AI will also be applicable to organizations (and conversely, if someone came to me with an actually good proposal for value alignment for organizations, I would consider it worth-looking-at). Of course I think that value alignment problem for AI systems is much more important, and so where the two problems are disanalogous I care about the AI version (and also I want to reserve undecorated "value alignment" as a technical term referring to the AI version of the problem). But that judgment is unrelated to the epistemic efficiency of corporations---I'd think the same thing even if corporations were epistemically efficient, and I presume so would you.</p>
<p>Your basic complaint with people's use of corporations as an analogy really seems to be that AI systems will become very much more powerful, and that they will never have the same peculiar mix of abilities as human organizations. </p>
<p>(Indeed, assuming that an agent is smarter in every way simply makes the safety problem easier, and many of our disagreements about safety are based on me being willing to assume something like "epistemic efficiency with respect to an average college graduate," at least as a first step.)</p></main><hr><section class="comments"><h2>Comments</h2><div class="comment"><p><a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></p><p><p>The point of 'efficiency' is that:</p>
<ul>
<li>It's an extremely plausible thing to expect given enough raw cognitive power.</li>
<li>It's a compact reply to people saying "An AI will do (believe) X because Y" when the AI is supposed to have a lot of cognitive power and a human could think of a better strategy (inference) for Y.</li>
<li>It has understandable precedents in market prices and in superhuman game-playing.</li>
<li>It's one of several compact properties that lets us distinguish important superintelligences from much weaker objects like corporations which people are tempted to shoehorn in as Objects of Equally Great Concern.</li>
</ul>
<p>Efficiency is indeed a very powerful property and is often overpowered as an assumption for the conclusion being offered.  On the other hand, it's also an important basic idea to understand because an AI which isn't efficient in <em>any</em> domain is not <a href="pivotal.html">relevant</a> (it must not even be able to play superhuman chess, if it's not efficient at chess).</p></p></div></section><footer><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/EricRogstad.html">Eric Rogstad</a>,
 <a class="page-link" href="../page/GlennWillen.html">Glenn Willen</a></span></p></footer></body></html>