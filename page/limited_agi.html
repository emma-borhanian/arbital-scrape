<!DOCTYPE html><html><head><meta charset="utf-8"><title>Limited AGI</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG" async></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Limited AGI</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/limited_agi.json.html">limited_agi.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/limited_agi">https://arbital.com/p/limited_agi</a></p><p class="creator">by
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a> Jul 10 2016 
updated
 Feb 22 2017</p></div><p class="clickbait">Task-based AGIs don't need unlimited cognitive and material powers to carry out their Tasks; which means their powers can potentially be limited.</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Limited AGI</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="AGI_typology.html">Strategic AGI typology</a></li><li><a href="task_agi.html">Task-directed AGI</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="task_agi.html">Task-directed AGI</a></li><li>…</li></ul></nav></nav></header><hr><main><p>One of the reasons why a <a href="task_agi.html">Task AGI</a> can potentially be safer than an <a href="Sovereign.html">Autonomous AGI</a>, is that since Task AGIs only need to carry out activities of limited scope, they <a href="minimality_principle.html">may only need limited material and cognitive powers</a> to carry out those tasks.  The <a href="nonadversarial.html">nonadversarial principle</a> still applies, but takes the form of "<a href="direct_limit_oppose.html">don&#39;t run the search</a>" rather than "make sure the search returns the correct answer".</p>
<h1 id="obstacles">Obstacles</h1>
<p>&bull; Increasing your material and cognitive efficacy is <a href="instrumental_convergence.html">instrumentally convergent</a> in all sorts of places and would presumably need to be <a href="avert_instrumental_pressure.html">averted</a> all over the place.</p>
<p>&bull; Good limitation proposals are [deceptive_ease not as easy as they look] because <a href="general_intelligence.html">particular domain capabilities can often be derived from more general architectures</a>.  An Artificial <em>General</em> Intelligence doesn't have a handcrafted 'thinking about cars' module and a handcrafted 'thinking about planes' module, so you <a href="domain_distance.html">can&#39;t just handcraft the two modules at different levels of ability</a>.</p>
<p>E.g. many have suggested that 'drive' or 'emotion' is something that can be selectively removed from AGIs to 'limit' their ambitions; <a href="psychologizing.html">presumably</a> these people are using a mental model that is not the standard <a href="expected_utility_agent.html">expected utility agent</a> model.  To know which kind of limitations are easy, you need a sufficiently good background picture of the AGI's subprocesses that you understand which kind of system capabilities will naturally carve at the joints.</p>
<h1 id="relatedideas">Related ideas</h1>
<p>The research avenue of <a href="soft_optimizer.html">Mild optimization</a> can be viewed as pursuing a kind of very general Limitation.</p>
<p><a href="behaviorist.html">Behaviorism</a> asks to Limit the AGI's ability to model other minds in non-whitelisted detail.</p>
<p><a href="task_goal.html">Taskishness</a> can be seen as an Alignment/Limitation hybrid in the sense that it asks for the AI to only <em>want</em> or <em>try</em> to do a bounded amount at every level of internal organization.</p>
<p><a href="low_impact.html">Low impact</a> can be seen as an Alignment/Limitation hybrid in the sense that a <a href="4l.html">successful impact penalty</a> would make the AI not <em>want</em> to implement larger-scale plans.</p>
<p>Limitation may be viewed as yet another subproblem of the <a href="hard_corrigibility.html">Hard problem of corrigibility</a>, since it seems like a type of precaution that a generic agent would desire to construct into a generic imperfectly-aligned subagent.</p>
<p>Limitation can be seen as motivated by both the <a href="nonadversarial.html">Non-adversarial principle</a> and the <a href="minimality_principle.html">Minimality principle</a>.</p></main><hr><footer><p class="tagged"><h2>Tagged</h2><span class="page-comma-list"><a class="page-link" href="../page/c_class_meta_tag.html">C-Class</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/EricRogstad.html">Eric Rogstad</a>,
 <a class="page-link" href="../page/RolandPihlakas.html">Roland Pihlakas</a></span></p><p class="reverse-related"><h2>Reverse Related</h2><ul class="page-list"><li><a class="page-link" href="../page/c_class_meta_tag.html">C-Class</a> <q>This page has substantial content, but may not thoroughly cover the topic, may not meet style and prose standards, or may not explain the concept in a way the target audience will reliably understand.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li></ul></p></footer></body></html>