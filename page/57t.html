<!DOCTYPE html><html><head><meta charset="utf-8"><title>&quot;wut&quot;</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG" async></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">&quot;wut&quot;</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/57t.json.html">57t.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/57t">https://arbital.com/p/57t</a></p><p class="creator">by
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a> Jul 8 2016 
updated
 Jul 8 2016</p></div><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>&quot;wut&quot;</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="advanced_safety.html">Advanced safety</a></li><li><a href="goodness_estimate_bias.html">Goodness estimate biaser</a></li><li>…</li></ul></nav></nav></header><hr><main><blockquote class="comment-context">●  Nearest unblocked strategy generally, and especially over <mark>instrumentally convergent corrigibility incorrigibility</mark>, suggests that if there are naturally\-arising AI behaviors we see as bad \(e\.g\. routing around shutdown\), there may emerge a pseudo\-adversarial selection of best strategies that happen to route around our attempted patches to those problems\.  E\.g\., the AI constructs an environmental subagent to continue carrying on its goals, while cheerfully obeying 'the letter of the law' with respect to allowing its current hardware to be shut down\.  This pseudo\-adversarial selection \(though obviously the AI does not actually have a goal of thwarting us or selecting low\-goodness strategies per se\) again implies that operational goodness is likely to be systematically lower than the AI's partially\-learned estimate of goodness; again to an increasing degree as the AI becomes smarter and searches a wider policy space\.</blockquote>
<p>wut</p></main><hr><section class="comments"><h2>Comments</h2><div class="comment"><p><a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></p><p><p>Oh my God you don't know about instrumentally convergent corrigibility incorrigibility</p>
<p>How could I have neglected to tell you this</p>
<p>The world is doomed</p>
<p>(Edited to fix.)</p></p></div></section><footer></footer></body></html>