<!DOCTYPE html><html><head><meta charset="utf-8"><title>Attainable optimum</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG" async></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Attainable optimum</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/attainable_optimum.json.html">attainable_optimum.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/attainable_optimum">https://arbital.com/p/attainable_optimum</a></p><p class="creator">by
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a> Feb 13 2017</p></div><p class="clickbait">The 'attainable optimum' of an agent's preferences is the best that agent can actually do given its finite intelligence and resources (as opposed to the global maximum of those preferences).</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Attainable optimum</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="value_alignment_problem.html">Value alignment problem</a></li><li><a href="preference_framework.html">Preference framework</a></li><li>â€¦</li></ul></nav></nav></header><hr><main><p>The 'attainable optimum' of an agent's preferences is the most preferred option that the agent can (a) obtain using its bounded material capabilities and (b) find as an available option using its limited cognitive resources; as distinct from the theoretical global maximum of the agent's utility function.  When you run a <a href="soft_optimizer.html">non-mildly-optimizing</a> agent, what you actually get as the resulting outcome is not the single outcome that theoretically maximizes the agent's <a href="utility_function.html">utility function</a>; you rather get that agent's attainable optimum of its <a href="expected_utility.html">expectation</a> of that utility function.  A preference framework's 'attainable optimum' is what you get in practice when somebody runs the corresponding agent.</p></main><hr><footer><p class="tagged"><h2>Tagged</h2><span class="page-comma-list"><a class="page-link" href="../page/stub_meta_tag.html">Stub</a></span></p><p class="reverse-related"><h2>Reverse Related</h2><ul class="page-list"><li><a class="page-link" href="../page/stub_meta_tag.html">Stub</a> <q>This page only gives a very brief overview of the topic. If you're able to, please help expand or improve it!</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul></p></footer></body></html>