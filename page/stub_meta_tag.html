<!DOCTYPE html><html><head><meta charset="utf-8"><title>Stub</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG" async></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Stub</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/stub_meta_tag.json.html">stub_meta_tag.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/stub_meta_tag">https://arbital.com/p/stub_meta_tag</a></p><p class="creator">by
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a> Jun 12 2015 
updated
 Oct 11 2016</p></div><p class="clickbait">This page only gives a very brief overview of the topic. If you're able to, please help expand or improve it!</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Stub</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="Arbital.html">Arbital</a></li><li><a href="arbital_meta_tag.html">Meta tags</a></li><li><a href="3zb.html">Meta tags which suppress a page from being featured</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="Arbital.html">Arbital</a></li><li><a href="arbital_meta_tag.html">Meta tags</a></li><li><a href="3zj.html">Meta tags which request an edit to the page</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="Arbital.html">Arbital</a></li><li><a href="arbital_meta_tag.html">Meta tags</a></li><li><a href="5dg.html">Quality meta tags</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="Arbital.html">Arbital</a></li><li><a href="arbital_meta_tag.html">Meta tags</a></li><li>…</li></ul></nav></nav></header><hr><main><p>Stub-Class pages are tiny, often a single paragraph, or a couple of sentences.  Stubs may have been created to provide a <a href="placeholder_meta_tag.html">Placeholder</a> for parenting, tagging, or reference purposes in a section under construction.  An editor expanding a Stub page might start over from scratch.</p>
<p>Contrast:</p>
<ul>
<li><a href="start_meta_tag.html">Start</a>, which is a larger page, but still visibly incomplete or disorganized.</li>
<li><a href="formal_definition_meta_tag.html">Formal definition</a>, for brief pages which only contain a formal definition and don't try to explain the topic.</li>
</ul>
<p><strong>Also</strong> use the tag <a href="work_in_progress_meta_tag.html">Work in progress</a> if the page is being actively edited.</p>
<p><strong><a href="arbital_quality.html">Quality scale</a></strong></p>
<ul>
<li><a href="unassessed_meta_tag.html">Unassessed</a></li>
<li><a href="formal_definition_meta_tag.html">Formal definition</a></li>
<li><a href="seed_meta_tag.html">Seed</a></li>
<li><a href="stub_meta_tag.html">Stub</a></li>
<li><a href="start_meta_tag.html">Start</a></li>
<li><a href="c_class_meta_tag.html">C-Class</a></li>
<li><a href="b_class_meta_tag.html">B-Class</a></li>
<li><a href="a_class_meta_tag.html">A-Class</a></li>
<li><a href="featured_meta_tag.html">Featured</a></li>
</ul></main><hr><footer><p class="all-creators"><h2>All Creators</h2><span class="page-comma-list"><a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a>,
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a>,
 <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></span></p><p class="related"><h2>Related</h2><ul class="page-list"><li><a class="page-link" href="../page/beneficial.html">'Beneficial'</a> <q>Really actually good.  A metasyntactic variable to mean &quot;favoring whatever the speaker wants ideally to accomplish&quot;, although different speakers have different morals and metaethics.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/detrimental.html">'Detrimental'</a> <q>The opposite of beneficial.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/googol.html">A googol</a> <q>A pretty small large number.</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/ai_arms_race.html">AI arms races</a> <q>AI arms races are bad</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/aixitl.html">AIXI-tl</a> <q>A time-bounded version of the ideal agent AIXI that uses an impossibly large finite computer instead of a hypercomputer.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/reads_algebra.html">Ability to read algebra</a> <q>Do you have sufficient mathematical ability that you can read a sentence that uses some algebra or invokes a mathematical idea, without slowing down too much?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/reads_calculus.html">Ability to read calculus</a> <q>Can you take integral signs and differentiations in stride?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/reads_logic.html">Ability to read logic</a> <q>Can you read sentences symbolically stating &quot;For all x: exists y: phi(x, y) or not theta(y)&quot; without slowing down too much?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/abortable.html">Abortable plans</a> <q>Plans that can be undone, or switched to having low further impact.  If the AI builds abortable nanomachines, they'll have a quiet self-destruct option that includes any replicated nanomachines.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/actual_effectiveness.html">Actual effectiveness</a> <q>If you want the AI's so-called 'utility function' to actually be steering the AI, you need to think about how it meshes up with beliefs, or what gets output to actions.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/hack.html">Ad-hoc hack (alignment theory)</a> <q>A &quot;hack&quot; is when you alter the behavior of your AI in a way that defies, or doesn't correspond to, a principled approach for that problem.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/43j.html">Another another playpen child</a> <q>May it be a light for you in dark places, when all other lights go out.</q> - <a class="page-link" href="../page/StephanieZolayvar.html">Stephanie Zolayvar</a></li><li><a class="page-link" href="../page/arbital_blog.html">Arbital Blog</a> <q>Stay up to date on all things Arbital</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/arbital_slack.html">Arbital Slack</a> <q>Where the cool kids hang out.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/arbital_arbiter.html">Arbital arbiter</a> <q>Arbiters provide oversight and dispute resolution to an Arbital domain.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/arbital_biographies.html">Arbital biographies</a> <q>As a very strong default (presently an absolute rule), Joe Smith's page only says nice things about Joe.  Even if a negative fact is true, it doesn't go on Joe's page.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/arbital_content_request.html">Arbital content request</a> <q>Arbital doesn't explain something you'd like to learn? We'd like to know, so we can prioritize.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/arbital_draft.html">Arbital draft</a> <q>Drafts are private work-in-progress pages.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/Arbital_editor.html">Arbital editor</a> <q>How to use Arbital's page editor.</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/Arbital_editor_advanced.html">Arbital editor: Advanced</a> <q>Advanced features of Arbital editor.</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/arbital_greenlink.html">Arbital greenlink</a> <q>What happens when you hover over an Arbital link?</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/arbital_reviewer.html">Arbital reviewer</a> <q>Reviewers help writers improve their pages, check over all changes to Arbital's content, and assess page quality.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/arbital_todo.html">Arbital todo</a> <q>So many things todo!</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/arbital_trusted.html">Arbital trusted user</a> <q>Trusted users can edit most pages directly, and don't need approval to add pages to a domain.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/arbital_unlisted_page.html">Arbital unlisted page</a> <q>What do you call a page that's not part of any domain?</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/agi.html">Artificial General Intelligence</a> <q>An AI which has the same kind of &quot;significantly more general&quot; intelligence that humans have compared to chimpanzees; it can learn new domains, like we can.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/attainable_optimum.html">Attainable optimum</a> <q>The 'attainable optimum' of an agent's preferences is the best that agent can actually do given its finite intelligence and resources (as opposed to the global maximum of those preferences).</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/avert_instrumental_pressure.html">Averting instrumental pressures</a> <q>Almost-any utility function for an AI, whether the target is diamonds or paperclips or eudaimonia, implies subgoals like rapidly self-improving and refusing to shut down.  Can we make that not happen?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/avert_self_improvement.html">Averting the convergent instrumental strategy of self-improvement</a> <q>We probably want the first AGI to *not* improve as fast as possible, but improving as fast as possible is a convergent strategy for accomplishing most things.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/bag_mathematics.html">Bag</a> <q>In mathematics, a &quot;bag&quot; is an unordered list. A bag differs from a set in that it can contain the sa…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/bayes_reasoning.html">Bayesian reasoning</a> <q>A probability-theory-based view of the world; a coherent way of changing probabilistic beliefs based on evidence.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/oh_notation.html">Big-O Notation</a> <q>This notation describes asymptotic behavior of functions.

# O(x)
A function f is O(g(x)) if, for la…</q> - <a class="page-link" href="../page/AeneasMackenzie.html">Aeneas Mackenzie</a></li><li><a class="page-link" href="../page/bijective_function.html">Bijective function</a> <q>A bijective function is a function with an inverse.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/binary_function.html">Binary function</a> <q>A binary function $f$ is a function of two inputs (i.e., a function with arity 2). For example, $+,$…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/bit_examples.html">Bit (of data): Examples</a> <q>In the game &quot;20 questions&quot;, one player (the &quot;leader&quot;) thinks of a concept, and the other players ask…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/boolean.html">Boolean</a> <q>A value in logic that evaluates to either &quot;true&quot; or &quot;false&quot;.</q> - <a class="page-link" href="../page/MalcolmMcCrimmon.html">Malcolm McCrimmon</a></li><li><a class="page-link" href="../page/bounded_agent.html">Bounded agent</a> <q>An agent that operates in the real world, using realistic amounts of computing power, that is uncertain of its environment, etcetera.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/cartesian_boundary.html">Cartesian agent-environment boundary</a> <q>If your agent is separated from the environment by an absolute border that can only be crossed by sensory information and motor outputs, it might just be a Cartesian agent.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/category_of_finite_sets.html">Category of finite sets</a> <q>The category of finite sets is exactly what it claims to be. It's a useful training ground for some of the ideas of category theory.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/cauchy_sequence.html">Cauchy sequence</a> <q>Infinite sequences whose terms get arbitrarily close together.</q> - <a class="page-link" href="../page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="../page/chestertons_fence.html">Chesterton's fence</a> <q>If someone did something, it's generally good to understand their reasons for doing it before undoing it.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/CT_thesis.html">Church-Turing thesis</a> <q>A thesis about computational models</q> - <a class="page-link" href="../page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="../page/cognitive_domain.html">Cognitive domain</a> <q>An allegedly compact unit of knowledge, such that ideas inside the unit interact mainly with each other and less with ideas in other domains.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/cognitive_steganography.html">Cognitive steganography</a> <q>Disaligned AIs that are modeling human psychology and trying to deceive their programmers will want to hide their internal thought processes from their programmers.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/programming_familiarity.html">Computer Programming Familiarity</a> <q>Want to see programming analogies and applications in your math explanations? Mark this as known.</q> - <a class="page-link" href="../page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="../page/conjugacy_class.html">Conjugacy class</a> <q>In a group, the elements can be partitioned naturally into certain classes.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/decision_theory.html">Decision theory</a> <q>The mathematical study of ideal decisionmaking</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/decit.html">Decit</a> <q>Decimal digit</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/diagonal_lemma.html">Diagonal lemma</a> <q>Constructing self-referential sentences</q> - <a class="page-link" href="../page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="../page/dihedral_group.html">Dihedral group</a> <q>The dihedral groups are natural examples of groups, arising from the symmetries of regular polygons.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/vector_space_direct_sum.html">Direct sum of vector spaces</a> <q>The direct sum of two vector spaces $U$ and $W,$ written $U \oplus W,$ is just the sum of $U$ and $W…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/disambiguation_meta_tag.html">Disambiguation</a> <q>Several distinct concepts use this page's name, this page helps readers find what they're looking for.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/disjoint_cycle_notation_is_unique.html">Disjoint cycle notation is unique</a> <q>Disjoint cycle notation provides a canonical way to express elements of the symmetric group.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/distinguish_advancement.html">Distinguish which advanced-agent properties lead to the foreseeable difficulty</a> <q>Say what kind of AI, or threshold level of intelligence, or key type of advancement, first produces the difficulty or challenge you're talking about.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/donor_lottery.html">Donor lottery</a> <q>An arrangement where a group of people pool their money and pick one person to give it away.</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/emphemeral_premises.html">Emphemeral premises</a> <q>When somebody says X, don't just say, &quot;Oh, not-X because Y&quot; and then forget about Y a day later.  Y is now an important load-bearing assumption in your worldview.  Write Y down somewhere.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/category_theory_equaliser.html">Equaliser (category theory)</a> <q>In Category theory, an *equaliser* of a pair of arrows $f, g: A \to B$ is an object $E$ and a univer…</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/evidential_dt.html">Evidential decision theories</a> <q>Theories which hold that the principle of rational choice is &quot;Choose the act that would be the best news, if somebody told you that you'd chosen that act.&quot;</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/expected_utility.html">Expected utility</a> <q>Scoring actions based on the average score of their probable consequences.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/expected_utility_formalism.html">Expected utility formalism</a> <q>Expected utility is the central idea in the quantitative implementation of consequentialism</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/external_resources_meta_tag.html">External resources</a> <q>This lens links out to other great resources across the web.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/fallacy.html">Fallacies</a> <q>To call something a fallacy is to assert that you think people shouldn't think like that.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/finite_set.html">Finite set</a> <q>A finite set is one which is not infinite. Some of these are the least complicated sets.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/load_bearing_premises.html">Flag the load-bearing premises</a> <q>If somebody says, &quot;This AI safety plan is going to fail, because X&quot; and you reply, &quot;Oh, that's fine because of Y and Z&quot;, then you'd better clearly flag Y and Z as &quot;load-bearing&quot; parts of your plan.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/focusing.html">Focusing</a> <q>Focusing is a psychotherapeutic process developed by psychotherapist Eugene Gendlin</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/formal_definition_meta_tag.html">Formal definition</a> <q>This page gives a purely formal definition of a topic, rather than motivating, explaining, and giving examples.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/FAI.html">Friendly AI</a> <q>Old terminology for an AI whose preferences have been successfully aligned with idealized human values.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/identify_goal_concept.html">Goal-concept identification</a> <q>Figuring out how to say &quot;strawberry&quot; to an AI that you want to bring you strawberries (and not fake plastic strawberries, either).</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/grahams_number.html">Graham's number</a> <q>A fairly large number, as numbers go.</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/greatest_common_divisor.html">Greatest common divisor</a> <q>The greatest common divisor of two natural numbers is… the largest number which is a divisor of both. The clue is in the name, really.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/poset_greatest_lower_bound.html">Greatest lower bound in a poset</a> <q>The greatest lower bound is an abstraction of the idea of the greatest common divisor to a general poset.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/group_presentation.html">Group presentation</a> <q>Presentations are a fairly compact way of expressing groups.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/godels_first_incompleteness_theorem.html">Gödel's first incompleteness theorem</a> <q>The theorem that destroyed Hilbert's program</q> - <a class="page-link" href="../page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="../page/happiness_maximizer.html">Happiness maximizer</a> <q>It is sometimes proposed that we build an AI intended to maximize human happiness.  (One early propo…</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/hub_page_meta_tag.html">Hub page</a> <q>This tag is applied to pages which server the role of a &quot;hub&quot;: the user starts there, goes off to learn more about the topic, and then comes back. This meta tag modifies the page's UI.</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/1qc.html">Human perception of sound</a> <q>What is the mechanism by which vibrations around the human ear are translated into the sensation of sound?</q> - <a class="page-link" href="../page/SilasBarta.html">Silas Barta</a></li><li><a class="page-link" href="../page/bayes_for_humans.html">Humans doing Bayes</a> <q>The human use of Bayesian reasoning in everyday life</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/humean_free_boundary.html">Humean degree of freedom</a> <q>A concept includes 'Humean degrees of freedom' when the intuitive borders of the human version of that concept depend on our values, making that concept less natural for AIs to learn.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/iff.html">Iff</a> <q>If and only if...</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/ignorance_prior.html">Ignorance prior</a> <q>Key equations for quantitative Bayesian problems, describing exactly the right shape for what we believed before observation.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/image_requested_meta_tag.html">Image requested</a> <q>An editor has requested an image for this page.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/inductive_prior.html">Inductive prior</a> <q>Some states of pre-observation belief can learn quickly; others never learn anything.  An &quot;inductive prior&quot; is of the former type.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/information_theory.html">Information theory</a> <q>The study (and quantificaiton) of information, and its communication and storage.</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/instrumental.html">Instrumental</a> <q>What is &quot;instrumental&quot; in the context of Value Alignment Theory?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/intelligence_explosion.html">Intelligence explosion</a> <q>What happens if a self-improving AI gets to the point where each amount x of self-improvement triggers &gt;x further self-improvement, and it stays that way for a while.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/intension_extension.html">Intension vs. extension</a> <q>&quot;Red is a light with a wavelength of 700 nm&quot; vs. &quot;Look at this red apple, red car, and red cup.&quot;</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/number_sets_intro.html">Intro to Number Sets</a> <q>An introduction to number sets for people who have no idea what a number set is.</q> - <a class="page-link" href="../page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="../page/intution_pump.html">Intution pump</a> <q>In philosophy, a metaphor or visualization used to shove the listener's intuition in a particular direction.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/irrational_number.html">Irrational number</a> <q>Real numbers that are not rational numbers</q> - <a class="page-link" href="../page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="../page/joint_probability.html">Joint probability</a> <q>The notation for writing the chance that both X and Y are true.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/requisite_meta_tag.html">Just a requisite</a> <q>A tag for nodes that just act as part of Arbital's requisite system</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/linear_algebra.html">Linear algebra</a> <q>The study of [linear\_transformation linear transformations] and vector spaces.</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_examples.html">Logarithm: Examples</a> <q>$\log_{10}(100)=2.$ $\log_2(4)=2.$ $\log_2(3)\approx 1.58.$ (TODO)</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_exercises.html">Logarithm: Exercises</a> <q>Without using a calculator: What is $\log_{10}(4321)$? What integer is it larger than, what integer …</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_inverts_exp.html">Logarithms invert exponentials</a> <q>The function $\log_b(\cdot)$ inverts the function $b^{(\cdot)}.$ In other words, $\log_b(n) = x$ imp…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/logical_dt.html">Logical decision theories</a> <q>Root page for topics on logical decision theory, with multiple intros for different audiences.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/lobs_theorem.html">Löb's theorem</a> <q>Löb's theorem</q> - <a class="page-link" href="../page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="../page/math0.html">Math 0</a> <q>Are you not actively bad at math, nor traumatized about math?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/math1.html">Math 1</a> <q>Is math sometimes fun for you, and are you not anxious if you see a math puzzle you don't know how to solve?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/math2.html">Math 2</a> <q>Do you work with math on a fairly routine basis?  Do you have little trouble grasping abstract structures and ideas?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/math3.html">Math 3</a> <q>Can you read the sort of things that professional mathematicians read, aka LaTeX formulas with a minimum of explanation?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/math.html">Mathematics</a> <q>Mathematics is the study of numbers and other ideal objects that can be described by axioms.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/meta_utility.html">Meta-utility function</a> <q>Preference frameworks built out of simple utility functions, but where, e.g., the 'correct' utility function for a possible world depends on whether a button is pressed.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/metaethics.html">Metaethics</a> <q>Metaethics asks &quot;What kind of stuff is goodness made of?&quot; (or &quot;How would we compute goodness?&quot;) rather than &quot;Which particular policies or outcomes are good or not-good?&quot;</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/microlending.html">Microlending</a> <q>The practice of giving microloans, which are small loans that are issued by individuals.</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/mind_design_space_wide.html">Mind design space is wide</a> <q>Imagine all human beings as one tiny dot inside a much vaster sphere of possibilities for &quot;The space of minds in general.&quot;  It is wiser to make claims about *some* minds than *all* minds.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/moral_hazard.html">Moral hazards in AGI development</a> <q>&quot;Moral hazard&quot; is when owners of an advanced AGI give in to the temptation to do things with it that the rest of us would regard as 'bad', like, say, declaring themselves God-Emperor.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/multiplication_of_rational_numbers_math_0.html">Multiplication of rational numbers (Math 0)</a> <q>&quot;Multiplication&quot; is the idea of &quot;now do the same as you just did, but instead of doing it to one apple, do it to some other number&quot;.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/needs_accessible_summary_meta_tag.html">Needs accessible summary</a> <q>This page needs a summary for a less technical audience.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/needs_examples_meta_tag.html">Needs examples</a> <q>This page would benefit from more examples of the concept it teaches.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/needs_parent_meta_tag.html">Needs parent</a> <q>This page is not attached to an appropriate parent page. If you know where it should go, please help categorize it!</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/needs_requisites_meta_tag.html">Needs requisites</a> <q>This page has important requisites which are not listed. If you know what they are, you could help add them!</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/neural_genie_metaphor.html">Neutral genie metaphor</a> <q>Definition. A neutral-genie metaphor is an attempt to illustrate a possible formal problem via an in…</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/newcomblike.html">Newcomblike decision problems</a> <q>Decision problems in which your choice correlates with something other than its physical consequences (say, because somebody has predicted you very well) can do weird things to some decision theories.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/bostrom_superintelligence.html">Nick Bostrom's book Superintelligence</a> <q>The current best book-form introduction to AI alignment theory.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/normal_subgroup.html">Normal subgroup</a> <q>Normal subgroups are subgroups which are in some sense &quot;the same from all points of view&quot;.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/number.html">Number</a> <q>An abstract object that expresses quantity or value of some sort.</q> - <a class="page-link" href="../page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="../page/opinion_meta_tag.html">Opinion page</a> <q>Opinion pages represent one position on a topic (often from a single author), and are not necessarily balanced or a reflection of consensus.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/orbit_stabiliser_theorem_external_resources.html">Orbit-Stabiliser theorem: External Resources</a> <q>External resources on the Orbit-Stabiliser theorem.</q> - <a class="page-link" href="../page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="../page/order_of_rational_operations_math_0.html">Order of rational operations (Math 0)</a> <q>Our shorthand for all the operations on rationals is very useful, but full of brackets; this is how to get rid of some of the brackets.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/ordered_field.html">Ordered field</a> <q>An ordered ring with division.</q> - <a class="page-link" href="../page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="../page/otherizer.html">Other-izing (wanted: new optimization idiom)</a> <q>Maximization isn't possible for bounded agents, and satisficing doesn't seem like enough.  What other kind of 'izing' might be good for realistic, bounded agents?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/polynomial_time_complexity_class.html">P (Polynomial Time Complexity Class)</a> <q>P is the class of problems which can be solved by algorithms whose run time is bounded by a polynomial.</q> - <a class="page-link" href="../page/EricLeese.html">Eric Leese</a></li><li><a class="page-link" href="../page/P_vs_NP.html">P vs NP</a> <q>Is creativity purely mechanical?</q> - <a class="page-link" href="../page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="../page/arguments_against_P_NP.html">P vs NP: Arguments against P=NP</a> <q>Why we believe P and NP are different</q> - <a class="page-link" href="../page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="../page/bayes_update_details.html">Path: Insights from Bayesian updating</a> <q>A learning-path placeholder page for insights derived from the Bayesian rule for updating beliefs.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/perfect_rolling_sphere.html">Perfect rolling sphere</a> <q>If you don't understand something, start by assuming it's a perfect rolling sphere.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/philosophy.html">Philosophy</a> <q>A stub parent node to contain standard concepts, belonging to subfields of academic philosophy, that are being used elsewhere on Arbital.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/pigovian_tax.html">Pigovian tax</a> <q>Taxation of negative externalities so that their producers have an incentive to cheaply reduce them</q> - <a class="page-link" href="../page/SilasBarta.html">Silas Barta</a></li><li><a class="page-link" href="../page/placeholder_meta_tag.html">Placeholder</a> <q>This is an empty page created for structural reasons (parent, requisite, or teaches).</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/possible_math_pages.html">Possible math pages</a> <q>A list of things which we may want math pages on</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/prime_element_ring_theory.html">Prime element of a ring</a> <q>Despite the name, &quot;prime&quot; in ring theory refers not to elements which are &quot;multiplicatively irreducible&quot; but to those such that if they divide a product then they divide some term of the product.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/prime_number.html">Prime number</a> <q>The prime numbers are the &quot;building blocks&quot; of the counting numbers.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/bayesian_prior.html">Prior</a> <q>A state of prior knowledge, before seeing information on a new problem.  Potentially complicated.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/probability_distribution_countable.html">Probability distribution (countable sample space)</a> <q>A function assigning a probability to each point in the sample space.</q> - <a class="page-link" href="../page/TsviBT.html">Tsvi BT</a></li><li><a class="page-link" href="../page/bayes_probability_notation.html">Probability notation for Bayes' rule</a> <q>The probability notation used in Bayesian reasoning</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/probability_theory.html">Probability theory</a> <q>The logic of science; coherence relations on quantitative degrees of belief.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/product_category_theory.html">Product (Category Theory)</a> <q>How a product is characterized rather than how it's constructed</q> - <a class="page-link" href="../page/MarkChimes.html">Mark Chimes</a></li><li><a class="page-link" href="../page/5dg.html">Quality meta tags</a> <q>Meta tags which determine the page's quality.</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/user_querying.html">Querying the AGI user</a> <q>Postulating that an advanced agent will check something with its user, probably comes with some standard issues and gotchas (e.g., prioritizing what to query, not manipulating the user, etc etc).</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/rationality.html">Rationality</a> <q>The subject domain for [ epistemic] and [ instrumental] rationality.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/real_analysis.html">Real analysis</a> <q>The study of real numbers and real-valued functions.</q> - <a class="page-link" href="../page/KevinClancy.html">Kevin Clancy</a></li><li><a class="page-link" href="../page/real_number_as_dedekind_cut.html">Real number (as Dedekind cut)</a> <q>A way to construct the real numbers that follows the intuition of filling in the gaps.</q> - <a class="page-link" href="../page/JoeZeng.html">Joe Zeng</a></li><li><a class="page-link" href="../page/reflective_consistency.html">Reflective consistency</a> <q>A decision system is reflectively consistent if it can approve of itself, or approve the construction of similar decision systems (as well as perhaps approving other decision systems too).</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/reflective_stability.html">Reflective stability</a> <q>Wanting to think the way you currently think, building other agents and self-modifications that think the same way.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/representability_theorem_for_computable_functions.html">Representability theorem for computable functions</a> <q>A [ logical theory] $T$ is said to satisfy the **representability theorem for computable functions**…</q> - <a class="page-link" href="../page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a></li><li><a class="page-link" href="../page/safe_plan_identification.html">Safe plan identification and verification</a> <q>On a particular task or problem, the issue of how to communicate to the AGI what you want it to do and all the things you don't want it to do.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/sample_space_probability.html">Sample space</a> <q>The set of possible things that could happen in a part of the world that you are uncertain about.</q> - <a class="page-link" href="../page/TsviBT.html">Tsvi BT</a></li><li><a class="page-link" href="../page/set_product.html">Set product</a> <q>A fundamental way of combining sets is to take their product, making a set that contains all tuples of elements from the originals.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/shannon.html">Shannon</a> <q>The shannon (Sh) is a unit of Information. One shannon is the difference in [info\_entropy entropy] …</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/show_broken.html">Show me what you've broken</a> <q>To demonstrate competence at computer security, or AI alignment, think in terms of breaking proposals and finding technically demonstrable flaws in them.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/shutdown_problem.html">Shutdown problem</a> <q>How to build an AGI that lets you shut it down, despite the obvious fact that this will interfere with whatever the AGI's goals are.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/shutdown_utility_function.html">Shutdown utility function</a> <q>A special case of a low-impact utility function where you just want the AGI to switch itself off harmlessly (and not create subagents to make absolutely sure it stays off, etcetera).</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/simple_group.html">Simple group</a> <q>The simple groups form the &quot;building blocks&quot; of group theory, analogously to the prime numbers in number theory.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/group_stabiliser.html">Stabiliser (of a group action)</a> <q>If a group acts on a set, it is useful to consider which elements of the group don't move a certain element of the set.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/AGI_typology.html">Strategic AGI typology</a> <q>What broad types of advanced AIs, corresponding to which strategic scenarios, might it be possible or wise to create?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/bayes_strength_of_evidence.html">Strength of Bayesian evidence</a> <q>From a Bayesian standpoint, the strength of evidence can be identified with its likelihood ratio.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/subgroup.html">Subgroup</a> <q>A group that lives inside a bigger group.</q> - <a class="page-link" href="../page/DylanHendrickson.html">Dylan Hendrickson</a></li><li><a class="page-link" href="../page/vector_subspace.html">Subspace</a> <q>A subspace $U=(F_U, V_U)$ of a Vector space $W=(F_W, V_W)$ is a vector space where $F_U = F_W$ and $…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/vector_space_sum.html">Sum of vector spaces</a> <q>The sum of two vector spaces $U$ and $W,$ written $U + W,$ is a vector space where the set of vector…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/task_identification.html">Task identification problem</a> <q>If you have a task-based AGI (Genie) then how do you pinpoint exactly what you want it to do (and not do)?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/alternating_group_is_simple.html">The alternating groups on more than four letters are simple</a> <q>The alternating groups are the most accessible examples of simple groups, and this fact also tells us that the symmetric groups are &quot;complicated&quot; in some sense.</q> - <a class="page-link" href="../page/PatrickStevens.html">Patrick Stevens</a></li><li><a class="page-link" href="../page/ideal_math_page.html">The ideal Arbital math page</a> <q>Think of the best math textbook you've ever read -- why was it good?</q> - <a class="page-link" href="../page/EricRogstad.html">Eric Rogstad</a></li><li><a class="page-link" href="../page/advanced_agent_theory.html">Theory of (advanced) agents</a> <q>One of the research subproblems of building powerful nice AIs, is the theory of (sufficiently advanced) minds in general.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/tiling_agents.html">Tiling agents theory</a> <q>The theory of self-modifying agents that build successors that are very similar to themselves, like repeating tiles on a tesselated plane.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/total_alignment.html">Total alignment</a> <q>We say that an advanced AI is &quot;totally aligned&quot; when it knows *exactly* which outcomes and plans are beneficial, with no further user input.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/transitive_relation.html">Transitive relation</a> <q>If a is related to b and b is related to c, then a is related to c.</q> - <a class="page-link" href="../page/DylanHendrickson.html">Dylan Hendrickson</a></li><li><a class="page-link" href="../page/trit.html">Trit</a> <q>Trinary digit</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/two_independent_events.html">Two independent events</a> <q>What do [a pair of dice], [a pair of coins], and [a pair of people on opposite sides of the planet] all have in common?</q> - <a class="page-link" href="../page/TsviBT.html">Tsvi BT</a></li><li><a class="page-link" href="../page/type_theory.html">Type theory</a> <q>Modern foundations for formal mathematics.</q> - <a class="page-link" href="../page/JackGallagher.html">Jack Gallagher</a></li><li><a class="page-link" href="../page/unassessed_meta_tag.html">Unassessed</a> <q>This page's quality has not been assessed.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li><li><a class="page-link" href="../page/understandability_principle.html">Understandability principle</a> <q>The more you understand what the heck is going on inside your AI, the safer you are.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/updateless_dt.html">Updateless decision theories</a> <q>Decision theories that maximize their policies (mappings from sense inputs to actions), rather than using their sense inputs to update their beliefs and then selecting actions.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/useless_variable_decomposition.html">Useless variable decomposition</a> <q>A variable decomposition can be true but useless if it is a poor guide to intervention due to automa…</q> - <a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></li><li><a class="page-link" href="../page/user_manipulation.html">User manipulation</a> <q>If not otherwise averted, many of an AGI's desired outcomes are likely to interact with users and hence imply an incentive to manipulate users.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/30b.html">User maximization</a> <q>A sub-principle of avoiding user manipulation - if you see an argmax over X or 'optimize X' instruction and X includes a user interaction, you've just told the AI to optimize the user.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/value_alignment_problem.html">Value alignment problem</a> <q>You want to build an advanced AI with the right values... but how?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/vector_space.html">Vector space</a> <q>A vector space is a field $F$ paired with a Group $V$ and a function $\cdot : F \times V \to V$ (cal…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/Vingean_reflection.html">Vingean reflection</a> <q>The problem of thinking about your future self when it's smarter than you.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/Vingean_uncertainty.html">Vingean uncertainty</a> <q>You can't predict the exact actions of an agent smarter than you - so is there anything you _can_ say about them?</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/calibrated_probabilities.html">Well-calibrated probabilities</a> <q>Even if you're fairly ignorant, you can still strive to ensure that when you say &quot;70% probability&quot;, it's true 70% of the time.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/work_in_progress_meta_tag.html">Work in progress</a> <q>This page is being actively worked on by an editor. Check with them before making major changes.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li><li><a class="page-link" href="../page/string_concatenation.html">concat (function)</a> <q>The string concatenation function `concat` puts two strings together, i.e., `concat(&quot;one&quot;,&quot;two&quot;)=&quot;on…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li></ul></p></footer></body></html>