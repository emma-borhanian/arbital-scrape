<!DOCTYPE html><html><head><meta charset="utf-8"><title>Coordinative AI development hypothetical</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG" async></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Coordinative AI development hypothetical</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/4j.json.html">4j.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/4j">https://arbital.com/p/4j</a></p><p class="creator">by
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a> Apr 8 2015 
updated
 Dec 16 2015</p></div><p class="clickbait">What would safe AI development look like if we didn't have to worry about anything else?</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Coordinative AI development hypothetical</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li><a href="value_achievement_dilemma.html">Value achievement dilemma</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="ai_alignment.html">AI alignment</a></li><li>…</li></ul></nav></nav></header><hr><main><p>A simplified/easier hypothetical form of the [ known algorithm nonrecursive] path within the <a href="value_achievement_dilemma.html">Value achievement dilemma</a>.  Suppose there was an effective world government with effective monitoring of all computers; or that for whatever other imaginary reason rogue AI development projects were simply not a problem. What would the ideal research trajectory for that world look like?</p>
<h3 id="usefulness">Usefulness:</h3>
<ul>
<li>Highlight / flag where safety shortcuts are being taken because we live in the non-ideal case.</li>
<li>Let us think through what a maximally safe development pathway would look like, and why, without stopping every 30 seconds to think about how we won't have time.  This may uncover valuable research paths that could, on a second glance, be done more quickly.</li>
<li>Think through a simpler case of a research-program-generator that has fewer desiderata and hence less cognitive distractions.</li>
</ul></main><hr><footer><p class="all-creators"><h2>All Creators</h2><span class="page-comma-list"><a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a>,
 <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a>,
 <a class="page-link" href="../page/JanosKramar.html">Janos Kramar</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/AndrewMcKnight.html">Andrew McKnight</a></span></p></footer></body></html>