<!DOCTYPE html><html><head><meta charset="utf-8"><title>Likelihood function</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG" async></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Likelihood function</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/likelihood_function.json.html">likelihood_function.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/likelihood_function">https://arbital.com/p/likelihood_function</a></p><p class="creator">by
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a> Jul 7 2016 
updated
 Aug 2 2016</p></div><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Likelihood function</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="math.html">Mathematics</a></li><li><a href="probability_theory.html">Probability theory</a></li><li><a href="bayes_reasoning.html">Bayesian reasoning</a></li><li><a href="bayesian_likelihood.html">Likelihood</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="rationality.html">Rationality</a></li><li><a href="probability_theory.html">Probability theory</a></li><li><a href="bayes_reasoning.html">Bayesian reasoning</a></li><li><a href="bayesian_likelihood.html">Likelihood</a></li><li>…</li></ul></nav></nav></header><hr><main><p>Let's say you have a piece of evidence $~$e$~$ and a set of hypotheses $~$\mathcal H.$~$ Each $~$H_i \in \mathcal H$~$ assigns some <a href="bayesian_likelihood.html">likelihood</a> to $~$e.$~$ The function $~$\mathcal L_{e}(H_i)$~$ that reports this likelihood for each $~$H_i \in \mathcal H$~$ is known as a "likelihood function."</p>
<p>For example, let's say that the evidence is $~$e_c$~$ = "Mr. Boddy was killed with a candlestick," and the hypotheses are $~$H_S$~$ = "Miss Scarlett did it," $~$H_M$~$ = "Colonel Mustard did it," and $~$H_P$~$ = "Mrs. Peacock did it." Furthermore, if Miss Scarlett was the murderer, she's 20% likely to have used a candlestick. By contrast, if Colonel Mustard did it, he's 10% likely to have used a candlestick, and if Mrs. Peacock did it, she's only 1% likely to have used a candlestick. In this case, the likelihood function is</p>
<p>$$~$\mathcal L_{e_c}(h) = 
\begin{cases}
0.2 &amp; \text{if $h = H_S$} \\
0.1 &amp; \text{if $h = H_M$} \\
0.01 &amp; \text{if $h = H_P$} \\
\end{cases}
$~$$</p>
<p>For an example using a continuous function, consider a possibly-biased coin whose bias $~$b$~$ to come up heads on any particular coinflip might be anywhere between $~$0$~$ and $~$1$~$.  Suppose we observe the coin to come up heads, tails, and tails. We will denote this evidence $~$e_{HTT}.$~$ The likelihood function over each hypothesis $~$H_b$~$ =  "the coin is biased to come up heads $~$b$~$ portion of the time" for $~$b \in [0, 1]$~$ is:</p>
<p>$$~$\mathcal L_{e_{HTT}}(H_b) = b\cdot (1-b)\cdot (1-b).$~$$</p>
<p>There's no reason to <a href="normalize_probabilities.html">normalize</a> likelihood functions so that they sum to 1 &mdash; they aren't probability distributions, they're functions expressing each hypothesis' propensity to yield the observed evidence. For example, if the evidence was really obvious ($~$e_s$~$ = "the sun rose this morning,") it might be the case that almost all hypotheses have a very high likelihood, in which case the sum of the likelihood function will be much more than 1.</p>
<p>Likelihood functions carry <em>absolute</em> likelihood information, and therefore, they contain information that <a href="relative_likelihood.html">relative likelihoods</a> do not. Namely, absolute likelihoods can be used to check a hypothesis for <a href="strictly_confused.html">strict confusion</a>.</p></main><hr><footer><p class="tagged"><h2>Tagged</h2><span class="page-comma-list"><a class="page-link" href="../page/c_class_meta_tag.html">C-Class</a></span></p><p class="all-creators"><h2>All Creators</h2><span class="page-comma-list"><a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a>,
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a>,
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a>,
 <a class="page-link" href="../page/SzymonWilczyski.html">Szymon Wilczyński</a></span></p><p class="reverse-related"><h2>Reverse Related</h2><ul class="page-list"><li><a class="page-link" href="../page/c_class_meta_tag.html">C-Class</a> <q>This page has substantial content, but may not thoroughly cover the topic, may not meet style and prose standards, or may not explain the concept in a way the target audience will reliably understand.</q> - <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></li></ul></p></footer></body></html>