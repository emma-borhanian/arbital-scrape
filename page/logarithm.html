<!DOCTYPE html><html><head><meta charset="utf-8"><title>Logarithm</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG" async></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Logarithm</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/logarithm.json.html">logarithm.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/logarithm">https://arbital.com/p/logarithm</a></p><p class="creator">by
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a> May 16 2016 
updated
 Jun 20 2016</p></div><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Logarithm</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="math.html">Mathematics</a></li><li>…</li></ul></nav></nav></header><hr><main><p>[summary: The logarithm base $~$b$~$ of a number $~$n,$~$ written $~$\log_b(n),$~$ is the answer to the question "how many times do you have to multiply 1 by $~$b$~$ to get $~$n$~$?" For example, $~$\log_{10}(1000)=3,$~$ because $~$10 \cdot 10 \cdot 10 = 1000,$~$ and $~$\log_2(16)=4$~$ because $~$2 \cdot 2 \cdot 2 \cdot 2 = 16.$~$]</p>
<p>[summary(Technical): $~$\log_b(n)$~$ is defined to be the number $~$x$~$ such that $~$b^x = n.$~$ Thus, logarithm functions satisfy the following properties, among others:</p>
<ul>
<li>$~$\log_b(1) = 0$~$</li>
<li>$~$\log_b(b) = 1$~$</li>
<li>$~$\log_b(x\cdot y) = log_b(x) + \log_b(y)$~$</li>
<li>$~$\log_b(\frac{x}{y}) = \log_b(x) - \log_b(y)$~$</li>
<li>$~$\log_b(x^n) = n\log_b(x)$~$</li>
<li>$~$\log_b(\sqrt[n]{x}) = \frac{\log_b(x)}{n}$~$</li>
<li>$~$\log_b(n) = \frac{\log_a(n)}{\log_a(b)}$~$]</li>
</ul>
<p>[summary(Inverse exponentials): Logarithms are the inverse of [exponential exponentials]. That is, for any base $~$b$~$ and number $~$n,$~$ $~$\log_b(b^n) = n$~$ and $~$b^{\log_b(n)} = n.$~$]</p>
<p>[summary(Measure of data): A message that singles out one thing from a set of $~$n$~$ carries $~$\log(n)$~$ units of data, where the unit of information depends on the base of the logarithm. For example, a message singling out one thing from 1024 carries about three <a href="decit.html">decits</a> of data (because $~$\log_{10}(1024) \approx 3$~$), or exactly ten <a href="data_bit.html">bits</a> of data (because $~$\log_2(1024)=10$~$). For details, see <a href="data_bit.html">Bit (of data)</a>.]</p>
<p>[summary(Generalized lengths):  A quick way of approximating the logarithm base 10 is to look at the length of a number: 103 is a 3-digit number but it's <em>almost</em> a 2-digit number, so its logarithm (base ten) is a little higher than 2 (it's about 2.01). 981 is also a three-digit number, and it's using nearly all three of those digits, so its logarithm (base ten) is just barely lower than 3 (it's about 2.99). In this way, logarithms generalize the notion of "length," and in particular, $~$\log_b(n)$~$ measures the generalized length of the number $~$n$~$ when it's written in $~$b$~$-ary notation.]</p>
<p>The logarithm base $~$b$~$ of a number $~$n,$~$ written $~$\log_b(n),$~$ is the answer to the question "how many times do you have to multiply 1 by $~$b$~$ to get $~$n$~$?" For example, $~$\log_{10}(100)=2,$~$ and $~$\log_{10}(316) \approx 2.5,$~$ because $~$316 \approx$~$ $~$10 \cdot 10 \cdot \sqrt{10},$~$ and [ multiplying by $~$\sqrt{10}$~$ corresponds to multiplying by 10 "half a time"].</p>
<p>In other words, $~$\log_b(x)$~$ counts the number of $~$b$~$-factors in $~$x$~$. For example, $~$\log_2(100)$~$ counts the number of "doublings" in the number 100, and $~$6 &lt; \log_2(100) &lt; 7$~$ because scaling an object up by a factor of 100 requires more than 6 (but less than 7) doublings. For an introduction to logarithms, see the <a href="log_guide.html">Arbital logarithm tutorial</a>. For an advanced introduction, see the [advanced_log_tutorial advanced logarithm tutorial].</p>
<p>Formally, $~$\log_b(n)$~$ is defined to be the number $~$x$~$ such that $~$b^x = n,$~$ where $~$b$~$ and $~$n$~$ are numbers. $~$b$~$ is called the "base" of the logarithm, and has a relationship to the [number_base base of a number system]. For a discussion of common and useful bases for logarithms, see the page on [logarithm_bases logarithm bases]. $~$x$~$ is unique if by "number" we mean [4bc $~$\mathbb R$~$], but may not be unique if by "number" we mean [complex_number $~$\mathbb C$~$]. For details, see the page on [complex_logarithm complex logarithms].</p>
<h1 id="basicproperties">Basic properties</h1>
<p>Logarithms satisfy a number of desirable properties, including:</p>
<ul>
<li>$~$\log_b(1) = 0$~$ for any $~$b$~$</li>
<li>$~$\log_b(b) = 1$~$ for any $~$b$~$</li>
<li>$~$\log_b(x\cdot y) = log_b(x) + \log_b(y)$~$</li>
<li>$~$\log_b(x^n) = n\log_b(x)$~$</li>
<li>$~$\log_a(n) = \frac{\log_b(n)}{\log_b(a)}$~$</li>
</ul>
<p>For an expanded list of properties, explanations of what they mean, and the reasons for why they hold, see <a href="log_identities.html">Logarithmic identities</a>.</p>
<h1 id="interpretations">Interpretations</h1>
<ul>
<li><p>Logarithms can be interpreted as a generalization of the notion of the [number_length length of a number]: 103 and 981 are both three digits long, but, intuitively, 103 is only barely using three digits, whereas 981 is pushing its three digits to the limit. Logarithms quantify this intuition: the [common_logarithm common logarithm] of 103 is approximately 2.01, and the common log of 981 is approximately 2.99. Logarithms give rise to a notion of exactly how many digits a number is "actually" making use of, and give us a notion of "fractional digits." For more on this interpretation (and why it is 316, not 500, that is two and a half digits long), see <a href="log_as_length.html">Log as generalized length</a>.</p></li>
<li><p>Logarithms can be interpreted as a measure of how much data it takes to carry a message. Imagine that you and I are both facing a collection of 100 different objects, and I'm thinking of one of them in particular. If I want to tell you which one I'm thinking of, how many digits do I need to transmit to you? The answer is $~$\log_{10}(100)=2,$~$ assuming that by "digit" we mean "some method of encoding one of the symbols 0-9 in a physical medium." Measuring data in this way is the cornerstone of <a href="information_theory.html">information theory</a>.</p></li>
<li><p>Logarithms are the inverse of exponentials. The function $~$\log_b(\cdot)$~$ inverts the function $~$b^{\ \cdot}.$~$ In other words, $~$\log_b(n) = x$~$ implies that $~$b^x = n,$~$ so $~$\log_b(b^x)=x$~$ and $~$b^{\log_b(n)}=n.$~$ Thus, logarithms give us tools for analyzing anything that grows exponentially. If a population of bacteria doubles each day, then logarithms measure days in terms of bacteria &mdash; that is, they can tell you how long it will take for the population to reach a certain size. For more on this idea, see <a href="log_inverts_exp.html">Logarithms invert exponentials</a>.</p></li>
</ul>
<h1 id="applications">Applications</h1>
<p>Logarithms are ubiquitous in many fields, including mathematics, physics, computer science, cognitive science, and artificial intelligence, to name a few. For example:</p>
<ul>
<li><p>In mathematics, the most natural logarithmic base is [mathematics_e $~$e$~$] ([log_e_is_natural Why?]) and the log base $~$e$~$ of $~$x$~$ is written $~$\ln(x)$~$, pronounced "[natural_logarithm natural log] of x." The natural logarithm of a number gives one notion of the "intrinsic length" of a number, a concept that proves useful when reasoning about other properties of that number. For example, the quantity of prime numbers smaller than $~$x$~$ is approximately $~$\frac{x}{\ln(x)},$~$ this is the [prime_number_theorem prime number theorem].</p></li>
<li><p>Logarithms also give us tools for measuring the runtime (or memory usage) of algorithms. When an algorithm uses a [divide_and_conquer divide and conquer] approach, the amount of time (or memory) used by the algorithm increases logarithmically as the input size grows linearly. For example, the amount of time that it takes to perform a [binary_search binary search] through $~$n$~$ possibilities is $~$\log_2(n),$~$ which means that the search takes one unit longer to run every time the set of things to search through doubles in size.</p></li>
<li><p>Logarithms give us tools for studying the tools we use to represent numbers. For example, humans tend to use ten different symbols to represent numbers (0, 1, 2, 3, 4, 5, 6, 7, 8, and 9), while computers tend to use two digits (0 and 1). Are some representations better or worse than others? What are the pros and cons of using more or fewer symbols? For more on these questions, see [number_base Number bases].</p></li>
<li><p>The human brain encodes various perceptions logarithmically. For example, the perceived tone of a sound goes up by one octave every time the frequency of air vibrations doubles. Your perception of tone is proportional to the logarithm (base 2) of the frequency at which the air is vibrating. See also <a href="https://en.wikipedia.org/wiki/Hick%27s_law">Hick&#39;s law</a>.</p></li>
</ul></main><hr><section class="comments"><h2>Comments</h2><div class="comment"><p><a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a></p><p><blockquote class="comment-context">The logarithm base $~$b$~$ of a number $~$n,$~$ written $~$\\log\_b(n),$~$ is the answer to the question "how many times do you have to multiply 1 by $~$b$~$ to get $~$n$~$?" For example, $~$\\log\_{10}(100)\=2,$~$ and $~$\\log\_{10}(316) \\approx 2.5,$~$ because $~$316 \\approx$~$ $~$10 \\cdot 10 \\cdot \\sqrt{10},$~$ an<mark>d multiplying by $~$\\sqrt{10}$~$ corresponds to multiplying by 10 "half a time"\.</mark></blockquote>
<p>Having a long redlink which does not point anywhere seems weird? Does the page it should point to now exist?</p></p><div class="comment"><p><a class="page-link" href="../page/NateSoares.html">Nate Soares</a></p><p><p>No (and it won't, until someone starts writing good explanations of radicals). I think it's fine to have redlinks to nowhere, when it's not clear yet which page will explain the concept.</p></p></div></div></section><footer><p class="all-creators"><h2>All Creators</h2><span class="page-comma-list"><a class="page-link" href="../page/EricRogstad.html">Eric Rogstad</a>,
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a>,
 <a class="page-link" href="../page/EricBruylant.html">Eric Bruylant</a>,
 <a class="page-link" href="../page/JaimeSevillaMolina.html">Jaime Sevilla Molina</a>,
 <a class="page-link" href="../page/MarkChimes.html">Mark Chimes</a>,
 <a class="page-link" href="../page/Marsnuntiusmariigmailcom.html">Mars (person)</a>,
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a>,
 <a class="page-link" href="../page/StephanieKoo.html">Stephanie Koo</a></span></p><p class="children"><h2>Children</h2><ul class="page-tree"><li><a class="page-link" href="../page/digit_exchange_rates.html">Exchange rates between digits</a> <q>In terms of data storage, if a coin is worth $1, a digit wheel is worth more than $3.32, but less than $3.33. Why?</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/fractional_digits.html">Fractional digits</a> <q>When $b$ and $x$ are integers, $\log_b(x)$ has a few good interpretations. It's roughly the length o…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_guide.html">Introductory guide to logarithms</a> <q>Welcome to the Arbital introduction to logarithms! In modern education, logarithms are often mention…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/logspace.html">Life in logspace</a> <q>The log lattice hints at the reason that engineers, scientists, and AI researchers find logarithms s…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_as_length.html">Log as generalized length</a> <q>To estimate the log (base 10) of a number, count how many digits it has.</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_as_comm_cost.html">Log as the change in the cost of communicating</a> <q>When interpreting logarithms as a generalization of the notion of &quot;length&quot; and as digit exchange rat…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_base_infinity.html">Log base infinity</a> <q>There is no log base infinity, but if there were, it would send everything to zero</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_base_1.html">Logarithm base 1</a> <q>There is no log base 1.</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_tutorial_overview.html">Logarithm tutorial overview</a> <q>The logarithm tutorial covers the following six subjects:

1. What are logarithms?
2. Logarithms as…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_examples.html">Logarithm: Examples</a> <q>$\log_{10}(100)=2.$ $\log_2(4)=2.$ $\log_2(3)\approx 1.58.$ (TODO)</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_exercises.html">Logarithm: Exercises</a> <q>Without using a calculator: What is $\log_{10}(4321)$? What integer is it larger than, what integer …</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_identities.html">Logarithmic identities</a> <q>- [ Inversion of exponentials]: $b^{\log_b(n)} = \log_b(b^n) = n.$
- [ Log of 1 is 0]: $\log_b(1) …</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_inverts_exp.html">Logarithms invert exponentials</a> <q>The function $\log_b(\cdot)$ inverts the function $b^{(\cdot)}.$ In other words, $\log_b(n) = x$ imp…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_properties.html">Properties of the logarithm</a> <q>- $\log_b(x \cdot y) = \log_b(x) + \log_b(y)$ for any $b$, this is the defining characteristic of …</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_tutorial_end.html">The End (of the basic log tutorial)</a> <q>That concludes our introductory tutorial on logarithms! You have made it to the end.

Throughout thi…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_characteristic.html">The characteristic of the logarithm</a> <q>Any time you find an output that adds whenever the input multiplies, you're probably looking at a (…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_lattice.html">The log lattice</a> <q>Log as the change in the cost of communicating and other pages give physical interpretations of what…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/only_one_log.html">There is only one logarithm</a> <q>All logarithm functions are the same, up to a multiplicative constant.</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log_definition.html">What is a logarithm?</a> <q>Logarithms are a group of functions that take a number as input and produce another number. There i…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/why_is_log_like_length.html">Why is log like length?</a> <q>If a number $x$ is $n$ digits long (in Decimal notation), then its logarithm (base 10) is between $n…</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li><li><a class="page-link" href="../page/log2_of_3_never_ends.html">Why is the decimal expansion of log2(3) infinite?</a> <q>Because 2 and 3 are relatively prime.</q> - <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></li></ul></p></footer></body></html>