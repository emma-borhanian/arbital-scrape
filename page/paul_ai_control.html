<!DOCTYPE html><html><head><meta charset="utf-8"><title>Paul Christiano's AI control blog</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG" async></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Paul Christiano's AI control blog</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/paul_ai_control.json.html">paul_ai_control.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/paul_ai_control">https://arbital.com/p/paul_ai_control</a></p><p class="creator">by
 <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a> Jan 30 2016 
updated
 Feb 3 2016</p></div><p class="clickbait">Speculations on the design of safe, efficient AI systems.</p><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Paul Christiano's AI control blog</li></ul></nav></nav></header><hr><main><p>This is a blog by <a href="PaulChristiano.html">Paul Christiano</a>.</p>
<p>Speculations on the design of safe, efficient AI systems. Supported by a grant from the Future of Life Institute.</p>
<p>Original source: <a href="https://medium.com/ai-control">https://medium.com/ai-control</a></p></main><hr><footer><p class="tagged"><h2>Tagged</h2><span class="page-comma-list"><a class="page-link" href="../page/ai_alignment.html">AI alignment</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/AlexeiAndreev.html">Alexei Andreev</a></span></p><p class="reverse-related"><h2>Reverse Related</h2><ul class="page-list"><li><a class="page-link" href="../page/ai_alignment.html">AI alignment</a> <q>The great civilizational problem of creating artificially intelligent computer systems such that running them is a good idea.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul></p><p class="children"><h2>Children</h2><ul class="page-tree"><li><a class="page-link" href="../page/possible_stance_ai_control_research.html">A possible stance for AI control research</a> <q>I think that AI control research should focus on finding [scalable](https://arbital.com/pages/492374…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/abstract_approval_direction.html">Abstract approval-direction</a> <q>Consider the following design for an agent, which I first described [here](https://arbital.com/p/1t7…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a><ul class="page-tree"><li><a class="page-link" href="../page/Learning_representations.html">Learning representations</a> <q>Many AI systems form internal representations of their current environment or of particular data. Pr…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li></ul></li><li><a class="page-link" href="../page/act_based_agents.html">Act based agents </a> <q>I’ve recently discussed three kinds of learning systems:

- [Approval-directed agents](https://arbit…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a><ul class="page-tree"><li><a class="page-link" href="../page/imitation_agent.html">Imitation-based agent</a> <q>An AI meant to imitate the behavior of a reference human as closely as possible.</q> - <a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></li></ul></li><li><a class="page-link" href="../page/adversarial_collaboration.html">Adversarial collaboration </a> <q>Suppose that I have hired a group of employees who are much smarter than I am. For some tasks it’s…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/against_mimicry.html">Against mimicry</a> <q>One simple and apparently safe AI system is a “copycat:” an agent that predicts what its user woul…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/apprenticeship_learning_mimicry.html">Apprenticeship learning and mimicry</a> <q>This post compares my [recent proposal](https://arbital.com/p/1vp/mimicry_meeting_halfway) with [Ab…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/approval_directed_agents.html">Approval directed agents</a> <q>Research in AI is steadily progressing towards more flexible, powerful, and autonomous goal-directe…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/approval_directed_bootstrapping.html">Approval-directed bootstrapping</a> <q>Approval-directed behavior works best when the overseer is very smart. Where can we find a smart o…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/automated_assistants.html">Automated assistants </a> <q>In my [last post](https://arbital.com/p/1th?title=implementing-our-considered-judgment), I describ…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/challenges_safe_ai_rl.html">Challenges for safe AI from RL</a> <q>In this post, I’ll describe and discuss a few big problems for the proposal from [my last post](htt…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/Delegating_mixed_crowd.html">Delegating to a mixed crowd</a> <q>### 

Suppose I have ten programs, each a human-level agent. I suspect that at least one or two of…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/efficient_feedback.html">Efficient feedback</a> <q>In some machine learning domains, such as image classification, we can produce a bunch of labelled t…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/handingling_adversarial_errors.html">Handling adversarial errors</a> <q>Even a very powerful learning system can’t do everything perfectly at first — it requires time to l…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a><ul class="page-tree"><li><a class="page-link" href="../page/handling_error_with_arguments.html">Handling errors with arguments</a> <q>My [recent proposal](https://arbital.com/p/1v7?title=steps-towards-safe-ai-from-online-learning) f…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li></ul></li><li><a class="page-link" href="../page/how_common_is_imitation.html">How common is imitation?</a> <q>How often do we train machine learning systems to imitate human behavior?

Some researchers explicit…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/human_arguments_ai_control.html">Human arguments and AI control</a> <q>### Explanation and AI control

Consider the definition:

&gt; An action is good to the extent that I w…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/human_counterfactual_loop.html">Human in counterfactual loop</a> <q>Consider an autonomous system which is buying or selling assets, operating heavy machinery, or mak…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/Human_consulting_HCH.html">Humans consulting HCH</a> <q>Consider a human who has access to a question-answering machine. Suppose the machine answers questio…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/implementing_considered_judgement.html">Implementing our considered judgment</a> <q>Suppose I had a very powerful prediction algorithm. How might I use this algorithm to build a smar…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/implicit_consequentialism.html">Implicit consequentialism</a> <q>Consider a machine that does exactly what its user [would tell it to do](https://arbital.com/p/1tj?t…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/in_defense_maximization.html">In defense of maximization</a> <q>I’ve been thinking about [AI systems that take actions their users would most approve of](https://…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/Indirect_decision_theory.html">Indirect decision theory</a> <q>In which I argue that understanding decision theory can be delegated to AI.

### Indirect normativit…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/learn_policies_goals.html">Learn policies or goals?</a> <q>I’ve [recently proposed](https://arbital.com/p/1t7/approval_directed_agents) training agents to ma…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/learning_logic.html">Learning and logic</a> <q>In most machine learning tasks, the learner maximizes a concrete, empirical performance measure: i…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/mimicry_meeting_halfway.html">Mimicry and meeting halfway</a> <q>I’ve talked recently about two different model-free decision procedures:

- At each step, pick the …</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/modeling_ai_control_with_humans.html">Modeling AI control with humans</a> <q>I’ve been trying to build an aligned AI out of reward-maximizing modules. A successful scheme could …</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/simulations_inductive_definitions.html">Of simulations and inductive definitions</a> <q>_(Warning: weird.)_

Consider a simple AI system, named A, that carries out a task by predicting wha…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/heterogenous_objectives.html">On heterogeneous objectives</a> <q>Eliezer Yudkowsky [has said](https://www.facebook.com/yudkowsky/posts/10153748345169228):

&gt; If you …</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/optimization_goals.html">Optimization and goals</a> <q>If we want to write a program that _doesn’t_ pursue a goal, we can have two kinds of trouble:

1. We…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/optimizing_with_comparisons.html">Optimizing with comparisons</a> <q>I could [elicit a user’s approval](https://arbital.com/p/1w5) of an action _a_ by having them supply…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/safe_ai_episode_rl.html">Problem: safe AI from episodic RL</a> <q>In [a previous post](https://arbital.com/p/1tv?title=the-steering-problem), I posed the steering pr…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a><ul class="page-tree"><li><a class="page-link" href="../page/steps_towards_safe_ai_online_learning.html">Steps towards safe AI from online learning</a> <q>### Steps towards safe AI from online learning

Suppose that we have a good algorithm for episodic r…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li></ul></li><li><a class="page-link" href="../page/reinforcement_learning_linguistic_convention.html">Reinforcement learning and linguistic convention</a> <q>Existing machine learning techniques are most effective when we can provide concrete feedback — such…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/reward_engineering.html">Reward engineering</a> <q>This post gestures at a handful of research questions with a loose thematic connection.

### The id…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a><ul class="page-tree"><li><a class="page-link" href="../page/technical_socail_approach_ai_safety.html">Technical and social approaches to AI safety</a> <q>I often divide solutions to the AI control problem into two parts: technical and social. I think a…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li></ul></li><li><a class="page-link" href="../page/safe_ai_from_question_answering.html">Safe AI from question-answering</a> <q>_(Warning: minimal new content. Just a clearer framing.)_

Suppose that I have a question-answering…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/Scalable_ai_control.html">Scalable AI control</a> <q>By AI control, I mean the problem of getting AI systems to do what we want them to do, to the best…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/stable_self_improvement.html">Stable self-improvement as an AI safety problem</a> <q>“Stable self-improvement” seems to be a primary focus of MIRI’s work. As I understand it, the proble…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/synthesizing_training_data.html">Synthesizing training data</a> <q>[Counterfactual oversight](https://arbital.com/p/1tj?title=human-in-counterfactual-loop) requires th…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/absentee_billionaire.html">The absentee billionaire</a> <q>Once each day, Hugh wakes for 10 minutes. During these 10 minutes, he spends 10 million dollars. The…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/Easy_goal_inference_problem_still_hard.html">The easy goal inference problem is still hard</a> <q>Goal inference and inverse reinforcement learning
------------------------------------------------…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a><ul class="page-tree"><li><a class="page-link" href="../page/1vc.html">Online guarantees and AI control</a> <q>I’m interested in claims of the form: “If we had an AI that could do X well, then we could build a…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li></ul></li><li><a class="page-link" href="../page/state_of_steering_problem.html">The state of the steering problem</a> <q>The [steering problem](https://arbital.com/p/1tv?title=the-steering-problem) asks: given some powe…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/steering_problem.html">The steering problem</a> <q>Most AI research focuses on reproducing human abilities: to learn, infer, and reason; to perceive,…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li><li><a class="page-link" href="../page/unsupervised_learning_ai_control.html">Unsupervised learning and AI control</a> <q>Reinforcement learning systems optimize for an objective defined by external feedback — anything fro…</q> - <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a></li></ul></p></footer></body></html>