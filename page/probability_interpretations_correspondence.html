<!DOCTYPE html><html><head><meta charset="utf-8"><title>Correspondence visualizations for different interpretations of &quot;probability&quot;</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG" async></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Correspondence visualizations for different interpretations of &quot;probability&quot;</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/probability_interpretations_correspondence.json.html">probability_interpretations_correspondence.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/probability_interpretations_correspondence">https://arbital.com/p/probability_interpretations_correspondence</a></p><p class="creator">by
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a> Jun 30 2016 
updated
 Jul 10 2016</p></div><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Correspondence visualizations for different interpretations of &quot;probability&quot;</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="math.html">Mathematics</a></li><li><a href="probability_theory.html">Probability theory</a></li><li><a href="probability.html">Probability</a></li><li><a href="probability_interpretations.html">Interpretations of &quot;probability&quot;</a></li><li>…</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="rationality.html">Rationality</a></li><li><a href="probability_theory.html">Probability theory</a></li><li><a href="probability.html">Probability</a></li><li><a href="probability_interpretations.html">Interpretations of &quot;probability&quot;</a></li><li>…</li></ul></nav></nav></header><hr><main><p>[summary: Let's say you have a model which says a particular coin is 70% likely to be heads. How should we assess that model?</p>
<ul>
<li>According to the [propensity propensity] interpretation, the coin has a fundamental intrinsic comes-up-headsness property, and the model is correct if that property is set to 0.7. (This theory is widely considered discredited, and is an example of the <a href="mind_projection.html">Mind projection fallacy</a>).</li>
<li>According to the [frequentist_probability frequentist] interpretation, the model is saying that there are a whole bunch of different places where some similar model is saying the same thing as this one (i.e., "the coin is 70% heads"), and all models in that reference class are true if, in 70% of those different places, the coin is heads.</li>
<li>According to the <a href="subjective_probability.html">subjectivist</a> interpretation, the model is saying that the one dang coin is 70 dang percent likely to be heads, and the model is either 70% accurate (if the coin is in fact heads) or 30% accurate (if it's tails).</li>
</ul>
<p>In other words, the propensity and frequency interpretations try to find ways to say that the model is definitively "true" or "false" (one by postulating that uncertainty is an ontologically basic part of the world, the other by identifying a collection of similar events), whereas the subjective interpretation extends the notion of "correctness" to allow for shades of gray.]</p>
<p><a href="probability_interpretations.html">Recall</a> that there are three common interpretations of what it means to say that a coin has a 50% probability of landing heads:</p>
<ul>
<li><strong>The propensity interpretation:</strong> Some probabilities are just out there in the world. It's a brute fact about coins that they come up heads half the time; we'll call this the coin's physical "propensity towards heads." When we say the coin has a 50% probability of being heads, we're talking directly about this propensity.</li>
<li><strong>The frequentist interpretation:</strong>  When we say the coin has a 50% probability of being heads after this flip, we mean that there's a class of events similar to this coin flip, and across that class, coins come up heads about half the time. That is, the <em>frequency</em> of the coin coming up heads is 50% inside the event class (which might be "all other times this particular coin has been tossed" or "all times that a similar coin has been tossed" etc).</li>
<li><strong>The subjective interpretation:</strong> Uncertainty is in the mind, not the environment. If I flip a coin and slap it against my wrist, it's already landed either heads or tails. The fact that I don't know whether it landed heads or tails is a fact about me, not a fact about the coin. The claim "I think this coin is heads with probability 50%" is an <em>expression of my own ignorance,</em> which means that I'd bet at 1 : 1 odds (or better) that the coin came up heads.</li>
</ul>
<p>One way to visualize the difference between these approaches is by visualizing what they say about when a model of the world should count as a good model. If a person's model of the world is definite, then it's easy enough to tell whether or not their model is good or bad: We just check what it says against the facts.  For example, if a person's model of the world says "the tree is 3m tall", then this model is [correspondence_theory_of_truth correct] if (and only if) the tree is 3 meters tall.</p>
<p><img src="http://i.imgur.com/5YriFTj.jpg" alt="ordinary truth" /></p>
<p>Definite claims in the model are called "true" when they correspond to reality, and "false" when they don't. If you want to navigate using a map, you had better ensure that the lines drawn on the map correspond to the territory.</p>
<p>But how do you draw a correspondence between a map and a territory when the map is probabilistic? If your model says that a biased coin has a 70% chance of coming up heads, what's the correspondence between your model and reality? If the coin is actually heads, was the model's claim true? 70% true? What would that mean?</p>
<p><img src="http://i.imgur.com/EjAto4b.jpg" alt="probability truth?" /></p>
<p>The advocate of <strong>propensity</strong> theory says that it's just a brute fact about the world that the world contains ontologically basic uncertainty. A model which says the coin is 70% likely to land heads is true if and only the actual physical propensity of the coin is 0.7 in favor of heads.</p>
<p><img src="http://i.imgur.com/0vQamhR.jpg" alt="propensity correspondence" /></p>
<p>This interpretation is useful when the laws of physics <em>do</em> say that there are multiple different observations you may make next (with different likelihoods), as is sometimes the case (e.g., in quantum physics). However, when the event is deterministic &mdash; e.g., when it's a coin that has been tossed and slapped down and is already either heads or tails &mdash; then this view is largely regarded as foolish, and an example of the <a href="mind_projection.html">Mind projection fallacy</a>: The coin is just a coin, and has no special internal structure (nor special physical status) that makes it <em>fundamentally</em> contain a little 0.7 somewhere inside it. It's already either heads or tails, and while it may <em>feel</em> like the coin is fundamentally uncertain, that's a feature of your brain, not a feature of the coin.</p>
<p>How, then, should we draw a correspondence between a probabilistic map and a deterministic territory (in which the coin is already definitely either heads or tails?)</p>
<p>A <strong>frequentist</strong> draws a correspondence between a single probability-statement in the model, and multiple events in reality. If the map says "that coin over there is 70% likely to be heads", and the actual territory contains 10 places where 10 maps say something similar, and in 7 of those 10 cases the coin is heads, then a frequentist says that the claim is true.</p>
<p><img src="https://i.imgur.com/RaePEL7.png" alt="frequentist correspondence" /></p>
<p>Thus, the frequentist preserves black-and-white correspondence: The model is either right or wrong, the 70% claim is either true or false. When the map says "That coin is 30% likely to be tails," that (according to a frequentist) means "look at all the cases similar to this case where my map says the coin is 30% likely to be tails; across all those places in the territory, 3/10ths of them have a tails-coin in them." That claim is definitive, given the set of "similar cases."</p>
<p>By contrast, a <strong>subjectivist</strong> generalizes the idea of "correctness" to allow for shades of gray. They say, "My uncertainty about the coin is a fact about <em>me,</em> not a fact about the coin; I don't need to point to other 'similar cases' in order to express uncertainty about <em>this</em> case. I know that the world right in front of me is either a heads-world or a tails-world, and I have a [-probability_distribution] puts 70% probability on heads." They then draw a correspondence between their probability distribution and the world in front of them, and declare that the more probability their model assigns to the correct answer, the better their model is.</p>
<p><img src="http://i.imgur.com/OWczeTe.jpg" alt="bayesian correspondence" /></p>
<p>If the world <em>is</em> a heads-world, and the probabilistic map assigned 70% probability to "heads," then the subjectivist calls that map "70% accurate." If, across all cases where their map says something has 70% probability, the territory is actually that  way 7/10ths of the time, then the Bayesian calls the map "[-well_calibrated]". They then seek methods to make their maps more accurate, and better calibrated. They don't see a need to interpret probabilistic maps as making definitive claims; they're happy to interpret them as making estimations that can be graded on a sliding scale of accuracy.</p>
<h2 id="debate">Debate</h2>
<p>In short, the frequentist interpretation tries to find a way to say the model is definitively "true" or "false" (by identifying a collection of similar events), whereas the subjectivist interpretation extends the notion of "correctness" to allow for shades of gray.</p>
<p>Frequentists sometimes object to the subjectivist interpretation, saying that frequentist correspondence is the only type that has any hope of being truly objective. Under Bayesian correspondence, who can say whether the map should say 70% or 75%, given that the probabilistic claim is not objectively true or false either way? They claim that these subjective assessments of "partial accuracy" may be intuitively satisfying, but they have no place in science. Scientific reports ought to be restricted to frequentist statements, which are definitively either true or false, in order to increase the objectivity of science.</p>
<p>Subjectivists reply that the frequentist approach is hardly objective, as it depends entirely on the choice of "similar cases". In practice, people can (and do!) <a href="https://en.wikipedia.org/wiki/Data_dredging">abuse frequentist statistics</a> by choosing the class of similar cases that makes their result look as impressive as possible (a technique known as "p-hacking"). Furthermore, the manipulation of subjective probabilities is subject to the <a href="bayes_rule.html">iron laws</a> of probability theory (which are the [ only way to avoid inconsistencies and pathologies] when managing your uncertainty about the world), so it's not like subjective probabilities are the wild west or something. Also, science has things to say about situations even when there isn't a huge class of objective frequencies we can observe, and science should let us collect and analyze evidence even then.</p>
<p>For more on this debate, see <a href="likelihood_vs_pvalue.html">Likelihood functions, p-values, and the replication crisis</a>.</p></main><hr><section class="comments"><h2>Comments</h2><div class="comment"><p><a class="page-link" href="../page/EricRogstad.html">Eric Rogstad</a></p><p><p>From the summary:</p>
<blockquote>
  <p>the model is saying that there are a whole bunch of different places where some model is saying</p>
</blockquote>
<p>The model is saying that some model is saying? Is this how this sentence was meant to read, or is there one model too many in there?</p></p><div class="comment"><p><a class="page-link" href="../page/EricRogstad.html">Eric Rogstad</a></p><p><p>Can we just replace the following:</p>
<blockquote>
  <p>According to the frequentist interpretation, the model is saying that there are a whole bunch of different places where some model is saying "the coin is 70% likely to be heads," and the model is true if, in 70% of those different places, the coin is heads.</p>
</blockquote>
<p>with this:</p>
<blockquote>
  <p>According to the frequentist interpretation, there are a whole bunch of different places where the model is saying "the coin is 70% likely to be heads," and the model is true if, in 70% of those different places, the coin is heads.</p>
</blockquote>
<p>?</p></p></div><div class="comment"><p><a class="page-link" href="../page/NateSoares.html">Nate Soares</a></p><p><p>No. edited for clarity, see if that helps.</p></p></div><div class="comment"><p><a class="page-link" href="../page/EricRogstad.html">Eric Rogstad</a></p><p><p>Hmm…</p>
<p>1) It seems weird to say that the model claims that there are a bunch of other models/events. It's saying that within some class, a certain result happens a certain fraction of the time, so it only relies on there being multiple events <em>implicitly</em>. </p>
<p>2) It doesn't seem necessary to claim that there are a "whole bunch" of other models/events -- there only have to be as many as the denominator of the probability stated as a reduced fraction, right?</p>
<p>3) I'm confused about the claim that there are other <em>models</em>. The rest of the text on the page seems to require that there is a class of <em>events</em> for the frequentist interpretation. If I flip a coin a bunch of times, under the frequentist interpretation, do I have a different model for each flip?</p></p></div></div></section><footer><p class="all-creators"><h2>All Creators</h2><span class="page-comma-list"><a class="page-link" href="../page/EricRogstad.html">Eric Rogstad</a>,
 <a class="page-link" href="../page/NateSoares.html">Nate Soares</a></span></p><p class="likes"><h2>Likes</h2><span class="page-comma-list"><a class="page-link" href="../page/NateSoares.html">Nate Soares</a>,
 <a class="page-link" href="../page/SzymonWilczyski.html">Szymon Wilczyński</a></span></p></footer></body></html>