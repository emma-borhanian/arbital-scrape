<!DOCTYPE html><html><head><meta charset="utf-8"><title>Implicit consequentialism</title><link rel="stylesheet" type="text/css" href="../common.css"><link rel="stylesheet" type="text/css" href="../page-style.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  SVG: {EqnChunk: 50, EqnChunkFactor: 1.5, EqChunkDelay: 10, useFontCache: false, linebreaks: {automatic: true}},
  tex2jax: {
    inlineMath: [['$~$', '$~$']],
    displayMath: [['$$~$', '$~$$']],
    processEscapes: true,
    preview: 'none',
  },
  showProcessingMessages: false,
  messageStyle: 'none',
  // http://docs.mathjax.org/en/latest/config-files.html#the-tex-ams-svg-configuration-file
  jax: ["input/TeX","output/SVG", "output/PreviewHTML"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
  TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }
});</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_SVG" async></script><script type="text/javascript" src="../arbital-demo-bundle.js"></script><script type="text/javascript">window.addEventListener('DOMContentLoaded', e=>window.loadAllDemos())
</script></head><body><header><h1 class="title">Implicit consequentialism</h1><div class="page-info"><p class="metadata-link"><a href="../metadata/implicit_consequentialism.json.html">implicit_consequentialism.json</a></p><p class="arbital-url"><a href="https://arbital.com/p/implicit_consequentialism">https://arbital.com/p/implicit_consequentialism</a></p><p class="creator">by
 <a class="page-link" href="../page/PaulChristiano.html">Paul Christiano</a> Feb 3 2016 
updated
 Mar 4 2016</p></div><nav class="breadcrumbs"><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="../index.html">Index</a></li><li>Implicit consequentialism</li></ul></nav><nav class="breadcrumb" aria-label="Breadcrumb"><ul><li><a href="paul_ai_control.html">Paul Christiano's AI control blog</a></li><li>…</li></ul></nav></nav></header><hr><main><p>Consider a machine that does exactly what its user&nbsp;<a href="human_counterfactual_loop.html?title=human-in-counterfactual-loop">would tell it to do</a>. If the user is a consequentialist, then so is the machine.</p>
<p>But building this machine does not introduce any&nbsp;<em>new</em>&nbsp;goals into the world at all. All of its consequentialism flows through the user’s head — it merely amplifies the goal-directed reasoning that already happens there. There is no room to err in specifying its goals, because its goals are not specified.</p>
<p>This is the best case for&nbsp;<a href="act_based_agents.html">act-based approaches</a>&nbsp;to AI control.</p>
<p><strong>But</strong>: this system may be optimizing internally, and is itself optimized.</p>
<p>We aim for&nbsp;<em>all</em>&nbsp;of this optimization to be a reflection and amplification of the user’s preferences.</p>
<p><strong>But</strong>: the user’s reasoning is not perfect, and they may want AI to go beyond their capabilities.</p>
<p>We aim for humans to collaborate effectively with AI systems, forming teams that share human preferences and whose foresight exceeds the individual systems they are overseeing.</p>
<p>This project doesn’t seem easy, but I feel optimistic.</p></main><hr><section class="comments"><h2>Comments</h2><div class="comment"><p><a class="page-link" href="../page/EliezerYudkowsky.html">Eliezer Yudkowsky</a></p><p><p>Darn it, I wanted to use this term to distinguish "not-explictly-consequentialistically optimizing for $~$Y$~$ still optimizes for $~$X$~$ when $~$X$~$ is being varied and is causally relevant to $~$Y$~$" from "having an explicit model of $~$X$~$ being relevant to $~$Y$~$ and therefore explicitly forming goals about $~$X$~$ and searching for strategies that affect $~$X.$~$"  (E.g., natural selection does implicit consequentialism, humans do explicit consequentialism.)  I'm not sure if I can think of an equally good replacement term for the thing I wanted to say.  Would "proxy consequentialism" work for the thing you wanted to say?</p></p></div></section><footer></footer></body></html>