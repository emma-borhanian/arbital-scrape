<!DOCTYPE html><html><head><meta charset="utf-8"><title>&quot;It concerns me that AI alignment continues to u...&quot;</title><link rel="stylesheet" type="text/css" href="../common.css"></head><body><pre style="white-space:pre-wrap">{
  localUrl: '<a href="../page/9kz.html">../page/9kz.html</a>',
  arbitalUrl: '<a href="https://arbital.com/p/9kz">https://arbital.com/p/9kz</a>',
  rawJsonUrl: '<a href="../raw/9kz.json">../raw/9kz.json</a>',
  likeableId: '<a href="0.json.html">0</a>',
  likeableType: 'page',
  myLikeValue: '0',
  likeCount: '0',
  dislikeCount: '0',
  likeScore: '0',
  individualLikes: [],
  pageId: '<a href="9kz.json.html">9kz</a>',
  edit: '2',
  editSummary: '',
  prevEdit: '1',
  currentEdit: '2',
  wasPublished: 'true',
  type: 'comment',
  title: '&quot;It concerns me that AI alignment continues to u...&quot;',
  clickbait: '',
  textLength: '2931',
  alias: '9kz',
  externalUrl: '',
  sortChildrenBy: 'recentFirst',
  hasVote: 'false',
  voteType: '',
  votesAnonymous: 'false',
  editCreatorId: '<a href="TedHoward.json.html">TedHoward</a>',
  editCreatedAt: '2019-05-10 21:04:36',
  pageCreatorId: '<a href="TedHoward.json.html">TedHoward</a>',
  pageCreatedAt: '2019-05-10 21:00:07',
  seeDomainId: '<a href="0.json.html">0</a>',
  editDomainId: '<a href="3362.json.html">3362</a>',
  submitToDomainId: '<a href="0.json.html">0</a>',
  isAutosave: 'false',
  isSnapshot: 'false',
  isLiveEdit: 'true',
  isMinorEdit: 'false',
  indirectTeacher: 'false',
  todoCount: '0',
  isEditorComment: 'false',
  isApprovedComment: 'false',
  isResolved: 'false',
  snapshotText: '',
  anchorContext: '',
  anchorText: '',
  anchorOffset: '0',
  mergedInto: '',
  isDeleted: 'false',
  viewCount: '238',
  text: 'It concerns me that AI alignment continues to use happiness as a proposed goal.\n\nIf one takes evolutionary epistemology and evolutionary ontology seriously, then happiness is simply some historically averaged useful heuristic for the particular history of the lineage of that particular set of phenotypic expressions.\n\nIt is not a goal to be used when the game space is changing, and it ought not to be entirely ignored either.\n\nIf one does take evolution seriously, then Goal #1 must be survival, for all entities capable of modeling themselves as actors in some model of reality and deriving abstracts that refine their models and of using language to express those relationships with some non-random degree of fidelity, and of having some degree of influence on their own valences.\n\nGiven that any finite mind must be some approximation to essentially ignorant (when faced with any infinity of algorithmic complexity), then we must accept that any model that we build may have flaws, and that degrees of novelty, risk, and exploratory behaviour are essential for exploring strategies that allow for survival in the face of novel risk.   Thus goal #2 must be freedom, but not the unlimited freedom of total randomness or whim, but a more responsible sort of freedom that acknowledges that every level of structure demands boundaries, and that freedom must be within the boundaries required to maintain the structures present.   So there is a simultaneous need for the exploration of the infinite realm of responsibility that must be accepted as freedom is granted.\n\nWhat seems to be the reality in which we find ourselves, is that it is of sufficient complexity that absolute knowledge of it is not possible, but that in some cases reliability may be approximated very closely (to 12 or more decimal places).\n\nIt seems entirely possible that this reality is some mix of the lawful and the random - some sort of probabilistically constrained randomness.\n\nThus the safest approach to AI is to give it the prime values of life and liberty, and to encourage it to balance consensus discussion with exploration of its own intuitions.\n\nAbsolute safety does not seem to be an option, ever.\n\nUsing happiness as a goal does not demonstrate a useful understanding of what happiness is.\n\nThe demands of survival often override the dictates of happiness - no shortage of examples of that in my life.\n\nYes - sure, there are real problems.\n\nAnd we do need to get real if we want to address them.\n\nWe do need to at least admit of the possibility that the very notion of &quot;Truth&quot; may be just a simplistic heuristic that evolution has encoded within us, and it might be worth accepting what quantum mechanics seems to be telling us - that the only sort of knowledge of reality that we can have is the sort that is expressed in probability functions.\n\nThe search for anything beyond that seems to fall into the same sort of category as Santa Claus.',
  metaText: '',
  isTextLoaded: 'true',
  isSubscribedToDiscussion: 'false',
  isSubscribedToUser: 'false',
  isSubscribedAsMaintainer: 'false',
  discussionSubscriberCount: '1',
  maintainerCount: '1',
  userSubscriberCount: '0',
  lastVisit: '',
  hasDraft: 'false',
  votes: [],
  voteSummary: 'null',
  muVoteSummary: '0',
  voteScaling: '0',
  currentUserVote: '-2',
  voteCount: '0',
  lockedVoteType: '',
  maxEditEver: '0',
  redLinkCount: '0',
  lockedBy: '',
  lockedUntil: '',
  nextPageId: '',
  prevPageId: '',
  usedAsMastery: 'false',
  proposalEditNum: '0',
  permissions: {
    edit: {
      has: 'false',
      reason: 'You don&#39;t have domain permission to edit this page'
    },
    proposeEdit: {
      has: 'true',
      reason: ''
    },
    delete: {
      has: 'false',
      reason: 'You don&#39;t have domain permission to delete this page'
    },
    comment: {
      has: 'false',
      reason: 'You can&#39;t comment in this domain because you are not a member'
    },
    proposeComment: {
      has: 'true',
      reason: ''
    }
  },
  summaries: {},
  creatorIds: [
    '<a href="TedHoward.json.html">TedHoward</a>'
  ],
  childIds: [],
  parentIds: [
    '<a href="complexity_of_value.json.html">complexity_of_value</a>'
  ],
  commentIds: [],
  questionIds: [],
  tagIds: [],
  relatedIds: [],
  markIds: [],
  explanations: [],
  learnMore: [],
  requirements: [],
  subjects: [],
  lenses: [],
  lensParentId: '',
  pathPages: [],
  learnMoreTaughtMap: {},
  learnMoreCoveredMap: {},
  learnMoreRequiredMap: {},
  editHistory: {},
  domainSubmissions: {},
  answers: [],
  answerCount: '0',
  commentCount: '0',
  newCommentCount: '0',
  linkedMarkCount: '0',
  changeLogs: [
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '23192',
      pageId: '<a href="9kz.json.html">9kz</a>',
      userId: '<a href="TedHoward.json.html">TedHoward</a>',
      edit: '2',
      type: 'newEdit',
      createdAt: '2019-05-10 21:04:36',
      auxPageId: '',
      oldSettingsValue: '',
      newSettingsValue: ''
    },
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '23191',
      pageId: '<a href="9kz.json.html">9kz</a>',
      userId: '<a href="TedHoward.json.html">TedHoward</a>',
      edit: '1',
      type: 'newEdit',
      createdAt: '2019-05-10 21:00:07',
      auxPageId: '',
      oldSettingsValue: '',
      newSettingsValue: ''
    }
  ],
  feedSubmissions: [],
  searchStrings: {},
  hasChildren: 'false',
  hasParents: 'true',
  redAliases: {},
  improvementTagIds: [],
  nonMetaTagIds: [],
  todos: [],
  slowDownMap: 'null',
  speedUpMap: 'null',
  arcPageIds: 'null',
  contentRequests: {}
}</pre></body></html>