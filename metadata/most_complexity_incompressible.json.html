<!DOCTYPE html><html><head><meta charset="utf-8"><title>Most complex things are not very compressible</title><link rel="stylesheet" type="text/css" href="../common.css"></head><body><pre style="white-space:pre-wrap">{
  localUrl: '<a href="../page/most_complexity_incompressible.html">../page/most_complexity_incompressible.html</a>',
  arbitalUrl: '<a href="https://arbital.com/p/most_complexity_incompressible">https://arbital.com/p/most_complexity_incompressible</a>',
  rawJsonUrl: '<a href="../raw/4v5.json">../raw/4v5.json</a>',
  likeableId: '<a href="2860.json.html">2860</a>',
  likeableType: 'page',
  myLikeValue: '0',
  likeCount: '3',
  dislikeCount: '0',
  likeScore: '3',
  individualLikes: [
    '<a href="EricBruylant.json.html">EricBruylant</a>',
    '<a href="JoeZeng.json.html">JoeZeng</a>',
    '<a href="EricRogstad.json.html">EricRogstad</a>'
  ],
  pageId: '<a href="most_complexity_incompressible.json.html">most_complexity_incompressible</a>',
  edit: '1',
  editSummary: '',
  prevEdit: '0',
  currentEdit: '1',
  wasPublished: 'true',
  type: 'wiki',
  title: 'Most complex things are not very compressible',
  clickbait: 'We can&#39;t *prove* it&#39;s impossible, but it would be *extremely surprising* to discover a 500-state Turing machine that output the exact text of &quot;Romeo and Juliet&quot;.',
  textLength: '2748',
  alias: 'most_complexity_incompressible',
  externalUrl: '',
  sortChildrenBy: 'likes',
  hasVote: 'false',
  voteType: '',
  votesAnonymous: 'false',
  editCreatorId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
  editCreatedAt: '2016-06-27 02:06:10',
  pageCreatorId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
  pageCreatedAt: '2016-06-27 02:06:10',
  seeDomainId: '<a href="0.json.html">0</a>',
  editDomainId: '<a href="AlexeiAndreev.json.html">AlexeiAndreev</a>',
  submitToDomainId: '<a href="0.json.html">0</a>',
  isAutosave: 'false',
  isSnapshot: 'false',
  isLiveEdit: 'true',
  isMinorEdit: 'false',
  indirectTeacher: 'false',
  todoCount: '0',
  isEditorComment: 'false',
  isApprovedComment: 'true',
  isResolved: 'false',
  snapshotText: '',
  anchorContext: '',
  anchorText: '',
  anchorOffset: '0',
  mergedInto: '',
  isDeleted: 'false',
  viewCount: '114',
  text: 'Although the [46h halting problem] means we can&#39;t *prove* it doesn&#39;t happen, it would nonetheless be *extremely surprising* if some 100-state Turing machine turned out to print the exact text of Shakespeare&#39;s *Romeo and Juliet.*  Unless something was specifically generated by a simple algorithm, the Vast supermajority of data structures that *look* like they have high [5v algorithmic complexity] actually *do* have high algorithmic complexity.  Since there are at most $2^{101}$ programs that can be specified with at most 100 bits (in any particular language), we can&#39;t fit all the 1000-bit data structures into all the 100-bit programs.  While *Romeo and Juliet* is certainly highly compressible, relative to most random bitstrings of the same length, it would be shocking for it to compress *all the way down* to a 100-state Turing machine.  There just aren&#39;t enough 100-state Turing machines for one of their outputs to be *Romeo and Juliet*.  Similarly, if you start with a 10 kilobyte text file, and 7zip compresses it down to 2 kilobytes, no amount of time spent trying to further compress the file using other compression programs will ever get that file down to 1 byte.  For any given compressor there&#39;s at most 256 starting files that can ever be compressed down to 1 byte, and your 10-kilobyte text file almost certainly isn&#39;t one of them.\n\nThis takes on defensive importance with respect to refuting the probability-theoretic fallacy, &quot;Oh, sure, Occam&#39;s Razor seems to say that this proposition is complicated.  But how can you be sure that this apparently complex proposition wouldn&#39;t turn out to be generated by some very simple mechanism?&quot;  If we consider a [1rd partition] of 10,000 possible propositions, collectively having a 0.01% probability on average, then all the arguments in the world for why various propositions might have unexpectedly high probability, must still add up to an average probability of 0.01%.  It can&#39;t be the case that after considering that proposition 1 might have secretly high probability, and considering that proposition 2 might have secretly high probability, and so on, we end up assigning 5% probability to each proposition, because that would be a total probability of 500.  If we assign prior probabilities using an algorithmic-complexity Occam prior as in [11w Solomonoff induction], then the observation that &quot;most apparently complex things can&#39;t be further compressed into an amazingly simple Turing machine&quot;, is the same observation as that &quot;most apparently Occam-penalized propositions can&#39;t turn out to be simpler than they look&quot; or &quot;most apparently subjectively improbable things can&#39;t turn out to have unseen clever arguments that would validly make them more subjectively probable&quot;.',
  metaText: '',
  isTextLoaded: 'true',
  isSubscribedToDiscussion: 'false',
  isSubscribedToUser: 'false',
  isSubscribedAsMaintainer: 'false',
  discussionSubscriberCount: '1',
  maintainerCount: '1',
  userSubscriberCount: '0',
  lastVisit: '',
  hasDraft: 'false',
  votes: [],
  voteSummary: 'null',
  muVoteSummary: '0',
  voteScaling: '0',
  currentUserVote: '-2',
  voteCount: '0',
  lockedVoteType: '',
  maxEditEver: '0',
  redLinkCount: '0',
  lockedBy: '',
  lockedUntil: '',
  nextPageId: '',
  prevPageId: '',
  usedAsMastery: 'false',
  proposalEditNum: '0',
  permissions: {
    edit: {
      has: 'false',
      reason: 'You don&#39;t have domain permission to edit this page'
    },
    proposeEdit: {
      has: 'true',
      reason: ''
    },
    delete: {
      has: 'false',
      reason: 'You don&#39;t have domain permission to delete this page'
    },
    comment: {
      has: 'false',
      reason: 'You can&#39;t comment in this domain because you are not a member'
    },
    proposeComment: {
      has: 'true',
      reason: ''
    }
  },
  summaries: {},
  creatorIds: [
    '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>'
  ],
  childIds: [],
  parentIds: [
    '<a href="Kolmogorov_complexity.json.html">Kolmogorov_complexity</a>'
  ],
  commentIds: [
    '<a href="4vf.json.html">4vf</a>',
    '<a href="5cr.json.html">5cr</a>'
  ],
  questionIds: [],
  tagIds: [
    '<a href="start_meta_tag.json.html">start_meta_tag</a>'
  ],
  relatedIds: [],
  markIds: [],
  explanations: [],
  learnMore: [],
  requirements: [],
  subjects: [],
  lenses: [],
  lensParentId: '',
  pathPages: [],
  learnMoreTaughtMap: {},
  learnMoreCoveredMap: {},
  learnMoreRequiredMap: {},
  editHistory: {},
  domainSubmissions: {},
  answers: [],
  answerCount: '0',
  commentCount: '0',
  newCommentCount: '0',
  linkedMarkCount: '0',
  changeLogs: [
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '14632',
      pageId: '<a href="most_complexity_incompressible.json.html">most_complexity_incompressible</a>',
      userId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
      edit: '0',
      type: 'newParent',
      createdAt: '2016-06-27 02:06:11',
      auxPageId: '<a href="Kolmogorov_complexity.json.html">Kolmogorov_complexity</a>',
      oldSettingsValue: '',
      newSettingsValue: ''
    },
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '14633',
      pageId: '<a href="most_complexity_incompressible.json.html">most_complexity_incompressible</a>',
      userId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
      edit: '0',
      type: 'newTag',
      createdAt: '2016-06-27 02:06:11',
      auxPageId: '<a href="start_meta_tag.json.html">start_meta_tag</a>',
      oldSettingsValue: '',
      newSettingsValue: ''
    },
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '14630',
      pageId: '<a href="most_complexity_incompressible.json.html">most_complexity_incompressible</a>',
      userId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
      edit: '1',
      type: 'newEdit',
      createdAt: '2016-06-27 02:06:10',
      auxPageId: '',
      oldSettingsValue: '',
      newSettingsValue: ''
    }
  ],
  feedSubmissions: [],
  searchStrings: {},
  hasChildren: 'false',
  hasParents: 'true',
  redAliases: {},
  improvementTagIds: [],
  nonMetaTagIds: [],
  todos: [],
  slowDownMap: 'null',
  speedUpMap: 'null',
  arcPageIds: 'null',
  contentRequests: {}
}</pre></body></html>