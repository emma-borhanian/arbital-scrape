<!DOCTYPE html><html><head><meta charset="utf-8"><title>&quot;&gt; &quot;you're allowed to increase P(BadDriver) a li...&quot;</title><link rel="stylesheet" type="text/css" href="../common.css"></head><body><pre style="white-space:pre-wrap">{
  localUrl: '<a href="../page/986.html">../page/986.html</a>',
  arbitalUrl: '<a href="https://arbital.com/p/986">https://arbital.com/p/986</a>',
  rawJsonUrl: '<a href="../raw/986.json">../raw/986.json</a>',
  likeableId: '<a href="0.json.html">0</a>',
  likeableType: 'page',
  myLikeValue: '0',
  likeCount: '0',
  dislikeCount: '0',
  likeScore: '0',
  individualLikes: [],
  pageId: '<a href="986.json.html">986</a>',
  edit: '1',
  editSummary: '',
  prevEdit: '0',
  currentEdit: '1',
  wasPublished: 'true',
  type: 'comment',
  title: '&quot;&gt; &quot;you&#39;re allowed to increase P(BadDriver) a li...&quot;',
  clickbait: '',
  textLength: '640',
  alias: '986',
  externalUrl: '',
  sortChildrenBy: 'recentFirst',
  hasVote: 'false',
  voteType: '',
  votesAnonymous: 'false',
  editCreatorId: '<a href="DewiMorgan.json.html">DewiMorgan</a>',
  editCreatedAt: '2018-09-25 16:35:19',
  pageCreatorId: '<a href="DewiMorgan.json.html">DewiMorgan</a>',
  pageCreatedAt: '2018-09-25 16:35:19',
  seeDomainId: '<a href="0.json.html">0</a>',
  editDomainId: '<a href="3183.json.html">3183</a>',
  submitToDomainId: '<a href="0.json.html">0</a>',
  isAutosave: 'false',
  isSnapshot: 'false',
  isLiveEdit: 'true',
  isMinorEdit: 'false',
  indirectTeacher: 'false',
  todoCount: '0',
  isEditorComment: 'false',
  isApprovedComment: 'false',
  isResolved: 'false',
  snapshotText: '',
  anchorContext: 'If you get in a car accident, and don&#39;t want to relinquish the hypothesis that you&#39;re a great driver, then you can find all sorts of reasons \\(&quot;the road was slippery\\! my car freaked out\\!&quot;\\) why $\\mathbb P(e \\mid GoodDriver)$ is not too low\\. But $\\mathbb P(e \\mid BadDriver)$ is also part of the update equation, and the &quot;bad driver&quot; hypothesis better predicts the evidence\\. Thus, your first impulse, when deciding how to update your beliefs in the face of a car accident, should not be &quot;But my preferred hypothesis allows for this evidence\\!&quot; It should instead be &quot;Points to the &#39;bad driver&#39; hypothesis for predicting this evidence better than the alternatives\\!&quot;  \\(And remember, you&#39;re allowed to increase $\\mathbb P(BadDriver)$ a little bit, while still thinking that it&#39;s less than 50% probable\\.\\)',
  anchorText: 'you&#39;re allowed to increase $\\mathbb P(BadDriver)$ a little bit,',
  anchorOffset: '685',
  mergedInto: '',
  isDeleted: 'false',
  viewCount: '1122',
  text: '&gt; &quot;you&#39;re allowed to increase P(BadDriver) a little bit,&quot;\n\nNo, you&#39;re really not.\n\nYou&#39;re only allowed to *replace* P(BadDriver) with P(BadDriver|HadOneAccident).\n\nIf you have a second accident, you replace that in turn with P(BadDriver|HadOneAccident^HadASecondAccident), which if you are rational you might reexamine and update to P(BadDriver|HadTwoAccidents^HadQuiteALotOfNearMissesIfWeAreBeingHonest)\n\nBut my point is, when applying each new piece of evidence, you have to remember the conditions that caused you to get your current probability, or you end up with naive Bayes and after seeing a few new bookcases you believe in aliens.',
  metaText: '',
  isTextLoaded: 'true',
  isSubscribedToDiscussion: 'false',
  isSubscribedToUser: 'false',
  isSubscribedAsMaintainer: 'false',
  discussionSubscriberCount: '1',
  maintainerCount: '1',
  userSubscriberCount: '0',
  lastVisit: '',
  hasDraft: 'false',
  votes: [],
  voteSummary: 'null',
  muVoteSummary: '0',
  voteScaling: '0',
  currentUserVote: '-2',
  voteCount: '0',
  lockedVoteType: '',
  maxEditEver: '0',
  redLinkCount: '0',
  lockedBy: '',
  lockedUntil: '',
  nextPageId: '',
  prevPageId: '',
  usedAsMastery: 'false',
  proposalEditNum: '0',
  permissions: {
    edit: {
      has: 'false',
      reason: 'You don&#39;t have domain permission to edit this page'
    },
    proposeEdit: {
      has: 'true',
      reason: ''
    },
    delete: {
      has: 'false',
      reason: 'You don&#39;t have domain permission to delete this page'
    },
    comment: {
      has: 'false',
      reason: 'You can&#39;t comment in this domain because you are not a member'
    },
    proposeComment: {
      has: 'true',
      reason: ''
    }
  },
  summaries: {},
  creatorIds: [
    '<a href="DewiMorgan.json.html">DewiMorgan</a>'
  ],
  childIds: [],
  parentIds: [
    '<a href="bayes_rule_probability.json.html">bayes_rule_probability</a>'
  ],
  commentIds: [],
  questionIds: [],
  tagIds: [],
  relatedIds: [],
  markIds: [],
  explanations: [],
  learnMore: [],
  requirements: [],
  subjects: [],
  lenses: [],
  lensParentId: '',
  pathPages: [],
  learnMoreTaughtMap: {},
  learnMoreCoveredMap: {},
  learnMoreRequiredMap: {},
  editHistory: {},
  domainSubmissions: {},
  answers: [],
  answerCount: '0',
  commentCount: '0',
  newCommentCount: '0',
  linkedMarkCount: '0',
  changeLogs: [
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '23084',
      pageId: '<a href="986.json.html">986</a>',
      userId: '<a href="DewiMorgan.json.html">DewiMorgan</a>',
      edit: '1',
      type: 'newEdit',
      createdAt: '2018-09-25 16:35:19',
      auxPageId: '',
      oldSettingsValue: '',
      newSettingsValue: ''
    }
  ],
  feedSubmissions: [],
  searchStrings: {},
  hasChildren: 'false',
  hasParents: 'true',
  redAliases: {},
  improvementTagIds: [],
  nonMetaTagIds: [],
  todos: [],
  slowDownMap: 'null',
  speedUpMap: 'null',
  arcPageIds: 'null',
  contentRequests: {}
}</pre></body></html>