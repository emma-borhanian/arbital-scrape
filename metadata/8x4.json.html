<!DOCTYPE html><html><head><meta charset="utf-8"><title>&quot;This strikes me as pretty shaky reasoning. You'...&quot;</title><link rel="stylesheet" type="text/css" href="../common.css"></head><body><pre style="white-space:pre-wrap">{
  localUrl: '<a href="../page/8x4.html">../page/8x4.html</a>',
  arbitalUrl: '<a href="https://arbital.com/p/8x4">https://arbital.com/p/8x4</a>',
  rawJsonUrl: '<a href="../raw/8x4.json">../raw/8x4.json</a>',
  likeableId: '<a href="0.json.html">0</a>',
  likeableType: 'page',
  myLikeValue: '0',
  likeCount: '0',
  dislikeCount: '0',
  likeScore: '0',
  individualLikes: [],
  pageId: '<a href="8x4.json.html">8x4</a>',
  edit: '1',
  editSummary: '',
  prevEdit: '0',
  currentEdit: '1',
  wasPublished: 'true',
  type: 'comment',
  title: '&quot;This strikes me as pretty shaky reasoning. You&#39;...&quot;',
  clickbait: '',
  textLength: '419',
  alias: '8x4',
  externalUrl: '',
  sortChildrenBy: 'recentFirst',
  hasVote: 'false',
  voteType: '',
  votesAnonymous: 'false',
  editCreatorId: '<a href="KevinVanHorn.json.html">KevinVanHorn</a>',
  editCreatedAt: '2017-12-27 21:48:03',
  pageCreatorId: '<a href="KevinVanHorn.json.html">KevinVanHorn</a>',
  pageCreatedAt: '2017-12-27 21:48:03',
  seeDomainId: '<a href="0.json.html">0</a>',
  editDomainId: '<a href="2916.json.html">2916</a>',
  submitToDomainId: '<a href="0.json.html">0</a>',
  isAutosave: 'false',
  isSnapshot: 'false',
  isLiveEdit: 'true',
  isMinorEdit: 'false',
  indirectTeacher: 'false',
  todoCount: '0',
  isEditorComment: 'false',
  isApprovedComment: 'false',
  isResolved: 'false',
  snapshotText: '',
  anchorContext: 'Elections are one of the cases where LDT makes a big difference in what appears rational or normative, compared to classical CDT\\.  Populations voting in elections are large enough that there may be many other people with decision algorithms similar to yours \\- not everyone, but a logically correlated cohort large enough that it might matter\\.  You can reasonably believe that everyone in your cohort will probably decide to vote \\(or not vote\\) in something like unison, and ask whether the probable benefit of the whole cohort voting is worth the cost of the whole cohort voting\\.',
  anchorText: 'Populations voting in elections are large enough that there may be many other people with decision algorithms similar to yours \\- not everyone, but a logically correlated cohort large enough that it might matter\\.  You can reasonably believe that everyone in your cohort will probably decide to vote \\(or not vote\\) in something like unison, and ask whether the probable benefit of the whole cohort voting is worth the cost of the whole cohort voting\\.',
  anchorOffset: '132',
  mergedInto: '',
  isDeleted: 'false',
  viewCount: '283',
  text: 'This strikes me as pretty shaky reasoning. You&#39;ve been talking about cases where you have access to the actual decision-making code of the agents you&#39;re interacting with, and they have access to yours, and therefore can prove some sort of optimality of a decision-making algorithm. When it comes to voting, none of that applies. We don&#39;t even have access to our own decision-making algorithm, much less those of others.',
  metaText: '',
  isTextLoaded: 'true',
  isSubscribedToDiscussion: 'false',
  isSubscribedToUser: 'false',
  isSubscribedAsMaintainer: 'false',
  discussionSubscriberCount: '1',
  maintainerCount: '1',
  userSubscriberCount: '0',
  lastVisit: '',
  hasDraft: 'false',
  votes: [],
  voteSummary: 'null',
  muVoteSummary: '0',
  voteScaling: '0',
  currentUserVote: '-2',
  voteCount: '0',
  lockedVoteType: '',
  maxEditEver: '0',
  redLinkCount: '0',
  lockedBy: '',
  lockedUntil: '',
  nextPageId: '',
  prevPageId: '',
  usedAsMastery: 'false',
  proposalEditNum: '0',
  permissions: {
    edit: {
      has: 'false',
      reason: 'You don&#39;t have domain permission to edit this page'
    },
    proposeEdit: {
      has: 'true',
      reason: ''
    },
    delete: {
      has: 'false',
      reason: 'You don&#39;t have domain permission to delete this page'
    },
    comment: {
      has: 'false',
      reason: 'You can&#39;t comment in this domain because you are not a member'
    },
    proposeComment: {
      has: 'true',
      reason: ''
    }
  },
  summaries: {},
  creatorIds: [
    '<a href="KevinVanHorn.json.html">KevinVanHorn</a>'
  ],
  childIds: [],
  parentIds: [
    '<a href="ldt_intro_compsci.json.html">ldt_intro_compsci</a>'
  ],
  commentIds: [],
  questionIds: [],
  tagIds: [],
  relatedIds: [],
  markIds: [],
  explanations: [],
  learnMore: [],
  requirements: [],
  subjects: [],
  lenses: [],
  lensParentId: '',
  pathPages: [],
  learnMoreTaughtMap: {},
  learnMoreCoveredMap: {},
  learnMoreRequiredMap: {},
  editHistory: {},
  domainSubmissions: {},
  answers: [],
  answerCount: '0',
  commentCount: '0',
  newCommentCount: '0',
  linkedMarkCount: '0',
  changeLogs: [
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '22949',
      pageId: '<a href="8x4.json.html">8x4</a>',
      userId: '<a href="KevinVanHorn.json.html">KevinVanHorn</a>',
      edit: '1',
      type: 'newEdit',
      createdAt: '2017-12-27 21:48:03',
      auxPageId: '',
      oldSettingsValue: '',
      newSettingsValue: ''
    }
  ],
  feedSubmissions: [],
  searchStrings: {},
  hasChildren: 'false',
  hasParents: 'true',
  redAliases: {},
  improvementTagIds: [],
  nonMetaTagIds: [],
  todos: [],
  slowDownMap: 'null',
  speedUpMap: 'null',
  arcPageIds: 'null',
  contentRequests: {}
}</pre></body></html>