<!DOCTYPE html><html><head><meta charset="utf-8"><title>Multiple stage fallacy</title><link rel="stylesheet" type="text/css" href="../common.css"></head><body><pre style="white-space:pre-wrap">{
  localUrl: '<a href="../page/multiple_stage_fallacy.html">../page/multiple_stage_fallacy.html</a>',
  arbitalUrl: '<a href="https://arbital.com/p/multiple_stage_fallacy">https://arbital.com/p/multiple_stage_fallacy</a>',
  rawJsonUrl: '<a href="../raw/4m2.json">../raw/4m2.json</a>',
  likeableId: '<a href="0.json.html">0</a>',
  likeableType: 'page',
  myLikeValue: '0',
  likeCount: '0',
  dislikeCount: '0',
  likeScore: '0',
  individualLikes: [],
  pageId: '<a href="multiple_stage_fallacy.json.html">multiple_stage_fallacy</a>',
  edit: '4',
  editSummary: '',
  prevEdit: '3',
  currentEdit: '4',
  wasPublished: 'true',
  type: 'wiki',
  title: 'Multiple stage fallacy',
  clickbait: 'You can make an arbitrary proposition sound very improbable by observing how it seemingly requires X, Y, and Z.  This didn&#39;t work for Nate Silver forecasting the Trump nomination.',
  textLength: '6718',
  alias: 'multiple_stage_fallacy',
  externalUrl: '',
  sortChildrenBy: 'likes',
  hasVote: 'false',
  voteType: '',
  votesAnonymous: 'false',
  editCreatorId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
  editCreatedAt: '2016-06-19 23:54:17',
  pageCreatorId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
  pageCreatedAt: '2016-06-19 23:45:46',
  seeDomainId: '<a href="0.json.html">0</a>',
  editDomainId: '<a href="123.json.html">123</a>',
  submitToDomainId: '<a href="0.json.html">0</a>',
  isAutosave: 'false',
  isSnapshot: 'false',
  isLiveEdit: 'true',
  isMinorEdit: 'false',
  indirectTeacher: 'false',
  todoCount: '0',
  isEditorComment: 'false',
  isApprovedComment: 'true',
  isResolved: 'false',
  snapshotText: '',
  anchorContext: '',
  anchorText: '',
  anchorOffset: '0',
  mergedInto: '',
  isDeleted: 'false',
  viewCount: '61',
  text: '[summary:  The purported &quot;Multiple-Stage Fallacy&quot; is when you list multiple &#39;stages&#39; that need to happen on the way to some final outcome, assign probabilities to each &#39;stage&#39;, multiply the probabilities together, and end up with a small final answer.  The alleged problem is that you can do this to almost *any* proposition by staring at it hard enough, including propositions that turn out to be true.\n\nAn alleged example would be that in August 2015, renowned forecaster Nate Silver wrote &quot;[Trump&#39;s Six Stages of Doom](http://fivethirtyeight.com/features/donald-trumps-six-stages-of-doom/)&quot; in which he gave Donald Trump a 2% chance of getting the Republican *nomination* (not the presidency), based on six stages each with at most a 50% probability of being passed.  In late March, Trump had passed the first four stages Nate listed, and prediction markets gave Trump a 75% chance of clinching the Republican nomination.  By Nate Silver&#39;s logic, Trump&#39;s probability of passing the remaining stages should have been $0.50 \\cdot 0.50 = 0.25.$\n\nThe three main purported problems with the Multiple-Stage Fallacy are that:\n\n- To get the final estimate, you logically need to multiply [1rj conditional probabilities], not unconditional probabilities.  Getting your mind to give good conditional probabilities isn&#39;t easy; Nate Silver might have failed to imagine how much he&#39;d *actually* update after *actually* seeing Trump pass the first four stages.\n- Often, people fail to consider disjunctive alternatives, or ways that not all the stages may need passing.\n- People tend to assign middle-tending probabilities.   So if you list enough stages, you can drive the apparent probability of anything down to zero, *even if you seem to be soliciting probabilities from the reader.*]\n\nIn August 2015, renowned statistician and predictor Nate Silver wrote &quot;[Trump&#39;s Six Stages of Doom](http://fivethirtyeight.com/features/donald-trumps-six-stages-of-doom/)&quot; in which he gave Donald Trump a 2% chance of getting the Republican *nomination* (not the presidency).  Silver reasoned that Trump would need to pass through six stages to get the nomination, &quot;Free-for-all&quot;, &quot;Heightened scrutiny&quot;, &quot;Iowa and New Hampshire&quot;, &quot;Winnowing&quot;, &quot;Delegate accumulation&quot;, and &quot;Endgame.&quot;  Nate Silver argued that Trump had at best a 50% chance of passing each stage, implying a final nomination probability of at most 2%.\n\nIn late March, Trump had passed the first four stages, while prediction markets gave him a 75% chance of clinching the Republican nomination.  By Nate Silver&#39;s logic, Trump&#39;s probability of passing the remaining stages should have been $0.50 \\cdot 0.50 = 0.25$ *conditional* on Trump passing the first four stages.\n\nNate Silver might not have been wrong to assign Trump a low advance probability of being nominated.  Many people were surprised by Trump&#39;s nomination.  But it seems more likely that Silver committed an error when he said, specifically, that if we&#39;d observed Trump to pass the first four stages, this would probably be taking place in a world where Trump had a 50% probability of passing the two remaining stages.\n\nThe purported &quot;Multiple-Stage Fallacy&quot; is when you list multiple &#39;stages&#39; that need to happen on the way to some final outcome, assign probabilities to each &#39;stage&#39;, multiply the probabilities together, and end up with a small final answer.  The alleged problem is that you can do this to almost any kind of proposition by staring at it hard enough, including things that actually happen.\n\nOn a probability-theoretic level, the three problems at work in the usual Multiple-Stage Fallacy are as follows:\n\n- You need to multiply *conditional* probabilities rather than the absolute probabilities. When you&#39;re considering a later stage, you need to assume that the world was such that every prior stage went through. Nate Silver was [43h probably] trying to simulate his prior model of Trump accumulating enough delegates in March through June, not imagining his *updated* beliefs about Trump and the world after seeing Trump be victorious up to March.\n  - Even if you&#39;re aware in principle that you need to use conditional probabilities - Nate Silver certainly knew about them - it&#39;s hard to update far *enough* when you imagine the pure hypothetical possibility that Trump wins stages 1-4 for some reason - compared to how much you actually update when you actually see Trump winning! (Some sort of reverse hindsight bias or something? We don&#39;t realize how much we&#39;d need to update our current model if we were already that surprised?)\n- Often, people neglect to consider disjunctive alternatives - there may be more than one way to reach a stage, so that not *all* the listed things need to happen. Trump accumulated enough delegates in Nate&#39;s fifth stage that there was no &quot;Endgame&quot; convention fight in the supposed sixth stage.\n- People have tendencies to assign middle-tending probabilities. So if you list enough stages, you can drive the apparent probability of anything down to zero, *even if you seem to be soliciting probabilities from the reader.*\n - If you&#39;re a [motivated skeptic](https://wiki.lesswrong.com/wiki/Motivated_skepticism), you will be tempted to list more &#39;stages&#39;.\n\nThe Multiple-Stage Fallacy is particularly dangerous for people who&#39;ve read studies on the dangers of probabilistic overconfidence.  In late March, the 75% prediction-market probabilities must have corresponded to, e.g., something like an 80% chance of getting enough delegates and a 90% chance of passing the convention conditional on getting enough delegates.  Imagine how overconfident this might have sounded without the prediction market to establish a definite probability - &quot;Oh, don&#39;t you know that what people assign 90% confidence doesn&#39;t usually happen 90% of the time?&quot;\n\nInstances of the Multiple-Stage Fallacy may also sound more persuasive to readers who&#39;ve read about the [Conjunction Fallacy](http://lesswrong.com/lw/ji/conjunction_fallacy/).\n\nYudkowsky [argues](https://www.facebook.com/yudkowsky/posts/10154036150109228):\n\n&gt; If you&#39;re not willing to make &quot;overconfident&quot; probability assignments like those, then you can drive the apparent probability of anything down to zero by breaking it down into enough &#39;stages&#39;. In fact, even if someone hasn&#39;t heard about overconfidence, people&#39;s probability assignments often trend toward the middle, so you can drive down their &quot;personally assigned&quot; probability of anything just by breaking it down into more stages...\n\n&gt; From beginning to end, I&#39;ve never used this style of reasoning and I don&#39;t recommend that you do so either. \\[Since\\] even Nate Silver couldn&#39;t get away with it, I think we just shouldn&#39;t try. It&#39;s a doomed methodology.\n',
  metaText: '',
  isTextLoaded: 'true',
  isSubscribedToDiscussion: 'false',
  isSubscribedToUser: 'false',
  isSubscribedAsMaintainer: 'false',
  discussionSubscriberCount: '1',
  maintainerCount: '1',
  userSubscriberCount: '0',
  lastVisit: '',
  hasDraft: 'false',
  votes: [],
  voteSummary: 'null',
  muVoteSummary: '0',
  voteScaling: '0',
  currentUserVote: '-2',
  voteCount: '0',
  lockedVoteType: '',
  maxEditEver: '0',
  redLinkCount: '0',
  lockedBy: '',
  lockedUntil: '',
  nextPageId: '',
  prevPageId: '',
  usedAsMastery: 'false',
  proposalEditNum: '0',
  permissions: {
    edit: {
      has: 'false',
      reason: 'You don&#39;t have domain permission to edit this page'
    },
    proposeEdit: {
      has: 'true',
      reason: ''
    },
    delete: {
      has: 'false',
      reason: 'You don&#39;t have domain permission to delete this page'
    },
    comment: {
      has: 'false',
      reason: 'You can&#39;t comment in this domain because you are not a member'
    },
    proposeComment: {
      has: 'true',
      reason: ''
    }
  },
  summaries: {},
  creatorIds: [
    '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>'
  ],
  childIds: [],
  parentIds: [
    '<a href="fallacy.json.html">fallacy</a>'
  ],
  commentIds: [],
  questionIds: [],
  tagIds: [],
  relatedIds: [],
  markIds: [],
  explanations: [],
  learnMore: [],
  requirements: [],
  subjects: [],
  lenses: [],
  lensParentId: '',
  pathPages: [],
  learnMoreTaughtMap: {},
  learnMoreCoveredMap: {},
  learnMoreRequiredMap: {},
  editHistory: {},
  domainSubmissions: {},
  answers: [],
  answerCount: '0',
  commentCount: '0',
  newCommentCount: '0',
  linkedMarkCount: '0',
  changeLogs: [
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '14036',
      pageId: '<a href="multiple_stage_fallacy.json.html">multiple_stage_fallacy</a>',
      userId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
      edit: '4',
      type: 'newEdit',
      createdAt: '2016-06-19 23:54:17',
      auxPageId: '',
      oldSettingsValue: '',
      newSettingsValue: ''
    },
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '14035',
      pageId: '<a href="multiple_stage_fallacy.json.html">multiple_stage_fallacy</a>',
      userId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
      edit: '3',
      type: 'newEdit',
      createdAt: '2016-06-19 23:47:29',
      auxPageId: '',
      oldSettingsValue: '',
      newSettingsValue: ''
    },
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '14034',
      pageId: '<a href="multiple_stage_fallacy.json.html">multiple_stage_fallacy</a>',
      userId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
      edit: '2',
      type: 'newEdit',
      createdAt: '2016-06-19 23:46:43',
      auxPageId: '',
      oldSettingsValue: '',
      newSettingsValue: ''
    },
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '14033',
      pageId: '<a href="multiple_stage_fallacy.json.html">multiple_stage_fallacy</a>',
      userId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
      edit: '0',
      type: 'newParent',
      createdAt: '2016-06-19 23:45:47',
      auxPageId: '<a href="fallacy.json.html">fallacy</a>',
      oldSettingsValue: '',
      newSettingsValue: ''
    },
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '14031',
      pageId: '<a href="multiple_stage_fallacy.json.html">multiple_stage_fallacy</a>',
      userId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
      edit: '1',
      type: 'newEdit',
      createdAt: '2016-06-19 23:45:46',
      auxPageId: '',
      oldSettingsValue: '',
      newSettingsValue: ''
    }
  ],
  feedSubmissions: [],
  searchStrings: {},
  hasChildren: 'false',
  hasParents: 'true',
  redAliases: {},
  improvementTagIds: [],
  nonMetaTagIds: [],
  todos: [],
  slowDownMap: 'null',
  speedUpMap: 'null',
  arcPageIds: 'null',
  contentRequests: {}
}</pre></body></html>