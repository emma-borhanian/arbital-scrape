<!DOCTYPE html><html><head><meta charset="utf-8"><title>&quot;One natural standard: it sh...&quot;</title><link rel="stylesheet" type="text/css" href="../common.css"></head><body><pre style="white-space:pre-wrap">{
  localUrl: '<a href="../page/37b.html">../page/37b.html</a>',
  arbitalUrl: '<a href="https://arbital.com/p/37b">https://arbital.com/p/37b</a>',
  rawJsonUrl: '<a href="../raw/37b.json">../raw/37b.json</a>',
  likeableId: '<a href="2154.json.html">2154</a>',
  likeableType: 'page',
  myLikeValue: '0',
  likeCount: '1',
  dislikeCount: '0',
  likeScore: '1',
  individualLikes: [
    '<a href="EricRogstad.json.html">EricRogstad</a>'
  ],
  pageId: '<a href="37b.json.html">37b</a>',
  edit: '1',
  editSummary: '',
  prevEdit: '0',
  currentEdit: '1',
  wasPublished: 'true',
  type: 'comment',
  title: '&quot;One natural standard: it sh...&quot;',
  clickbait: '',
  textLength: '1274',
  alias: '37b',
  externalUrl: '',
  sortChildrenBy: 'recentFirst',
  hasVote: 'false',
  voteType: '',
  votesAnonymous: 'false',
  editCreatorId: '<a href="PaulChristiano.json.html">PaulChristiano</a>',
  editCreatedAt: '2016-04-15 22:15:33',
  pageCreatorId: '<a href="PaulChristiano.json.html">PaulChristiano</a>',
  pageCreatedAt: '2016-04-15 22:15:33',
  seeDomainId: '<a href="0.json.html">0</a>',
  editDomainId: '<a href="EliezerYudkowsky.json.html">EliezerYudkowsky</a>',
  submitToDomainId: '<a href="0.json.html">0</a>',
  isAutosave: 'false',
  isSnapshot: 'false',
  isLiveEdit: 'true',
  isMinorEdit: 'false',
  indirectTeacher: 'false',
  todoCount: '0',
  isEditorComment: 'false',
  isApprovedComment: 'true',
  isResolved: 'false',
  snapshotText: '',
  anchorContext: '',
  anchorText: '',
  anchorOffset: '0',
  mergedInto: '',
  isDeleted: 'false',
  viewCount: '168',
  text: 'One natural standard: it should be hard to distinguish an adequate model from the system-to-be-modeled, based on input/output behavior alone.\n\nHow hard? Ideally we&#39;d have an &quot;equally competent&quot; modeler and distinguisher, and ask the modeler to try to fool the distinguisher. This is a popular approach to generative modeling, and something I&#39;ve talked about in the context of AI control (as has Jessica).\n\nThis definition runs into many subtleties, but I think it is a natural starting point for a discussion. In particular, we are already way beyond concerns like &quot;the brain is almost certainly a chaotic system and hence we can&#39;t hope to produce exactly the same result as a biological brain.&quot;\n\nThe key property we want from the distinguisher is that it can learn to detect relevant differences between the model and the real system. This seems like it might be the kind of problem that I would classify as &quot;probably easy if the agent is powerful and the difference is really important&quot; and you would classify as &quot;way too hard to count on.&quot;\n\nYou could also ask the model to output various intermediate results or to simulate requested measurements on the simulated brain, and give this extra information to the distinguisher. (Though I don&#39;t think this would really help.)',
  metaText: '',
  isTextLoaded: 'true',
  isSubscribedToDiscussion: 'false',
  isSubscribedToUser: 'false',
  isSubscribedAsMaintainer: 'false',
  discussionSubscriberCount: '2',
  maintainerCount: '1',
  userSubscriberCount: '0',
  lastVisit: '',
  hasDraft: 'false',
  votes: [],
  voteSummary: 'null',
  muVoteSummary: '0',
  voteScaling: '0',
  currentUserVote: '-2',
  voteCount: '0',
  lockedVoteType: '',
  maxEditEver: '0',
  redLinkCount: '0',
  lockedBy: '',
  lockedUntil: '',
  nextPageId: '',
  prevPageId: '',
  usedAsMastery: 'false',
  proposalEditNum: '0',
  permissions: {
    edit: {
      has: 'false',
      reason: 'You don&#39;t have domain permission to edit this page'
    },
    proposeEdit: {
      has: 'true',
      reason: ''
    },
    delete: {
      has: 'false',
      reason: 'You don&#39;t have domain permission to delete this page'
    },
    comment: {
      has: 'false',
      reason: 'You can&#39;t comment in this domain because you are not a member'
    },
    proposeComment: {
      has: 'true',
      reason: ''
    }
  },
  summaries: {},
  creatorIds: [
    '<a href="PaulChristiano.json.html">PaulChristiano</a>'
  ],
  childIds: [],
  parentIds: [
    '<a href="faithful_simulation.json.html">faithful_simulation</a>'
  ],
  commentIds: [
    '<a href="38p.json.html">38p</a>',
    '<a href="38w.json.html">38w</a>'
  ],
  questionIds: [],
  tagIds: [],
  relatedIds: [],
  markIds: [],
  explanations: [],
  learnMore: [],
  requirements: [],
  subjects: [],
  lenses: [],
  lensParentId: '',
  pathPages: [],
  learnMoreTaughtMap: {},
  learnMoreCoveredMap: {},
  learnMoreRequiredMap: {},
  editHistory: {},
  domainSubmissions: {},
  answers: [],
  answerCount: '0',
  commentCount: '0',
  newCommentCount: '0',
  linkedMarkCount: '0',
  changeLogs: [
    {
      likeableId: '<a href="0.json.html">0</a>',
      likeableType: 'changeLog',
      myLikeValue: '0',
      likeCount: '0',
      dislikeCount: '0',
      likeScore: '0',
      individualLikes: [],
      id: '9315',
      pageId: '<a href="37b.json.html">37b</a>',
      userId: '<a href="PaulChristiano.json.html">PaulChristiano</a>',
      edit: '1',
      type: 'newEdit',
      createdAt: '2016-04-15 22:15:33',
      auxPageId: '',
      oldSettingsValue: '',
      newSettingsValue: ''
    }
  ],
  feedSubmissions: [],
  searchStrings: {},
  hasChildren: 'false',
  hasParents: 'true',
  redAliases: {},
  improvementTagIds: [],
  nonMetaTagIds: [],
  todos: [],
  slowDownMap: 'null',
  speedUpMap: 'null',
  arcPageIds: 'null',
  contentRequests: {}
}</pre></body></html>